\documentclass[draftcls,onecolumn,12pt]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{framed}
\usepackage[linesnumbered,lined, algoruled]{algorithm2e}
\usepackage{algorithmic,float}
\usepackage{amsmath}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bm,array}
\usepackage{soul,color}
%\usepackage{epstopdf}
\usepackage[acronym,shortcuts]{glossaries}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{comment}
\usepackage{setspace}
\usepackage[inline]{enumitem}
\usepackage{booktabs}

\makeglossaries
%%% Glossaries/Acronyms
\DeclareMathOperator\erf{erf}
\newacronym{ae}{AE}{auto encoder}
\newacronym{auc}{AUC}{area under the curve}
\newacronym{ap}{AP}{access point}
\newacronym{ce}{CE}{cross entropy}
\newacronym{cdf}{CDF}{cumulative distribution function}
\newacronym{eda}{EDA}{estimated distance approach}
\newacronym{fa}{FA}{false alarm}
\newacronym{gnss}{GNSS}{global navigation satellite systems}
\newacronym{irlv}{IRLV}{in-region location verification}
\newacronym{kl}{K-L}{Kullback-Leibler}
\newacronym{ls}{LS}{least-squares}
\newacronym{llr}{LLR}{log likelihood-ratio}
\newacronym{los}{LOS}{line of sight}
\newacronym{glrt}{GLRT}{generalized likelihood ratio test}
\newacronym{gsm}{GSM}{global system for mobile communications}
\newacronym{lssvm}{LS-SVM}{least squares SVM}
\newacronym{md}{MD}{mis-detection}
\newacronym{ml}{ML}{machine learning}
\newacronym{mlp}{MLP}{multy-layer perceptron}
\newacronym{mmse}{MMSE}{minimum mean square error}
\newacronym{mse}{MSE}{mean squared error}
\newacronym[\glslongpluralkey={neural networks}]{nn}{NN}{neural network}
\newacronym{np}{N-P}{Neyman-Pearson}
\newacronym{oclssvm}{OCLSSVM}{one-class least-square \ac{svm}}
\newacronym{pdf}{PDF}{probability density function}
\newacronym{pso}{PSO}{particle swarm optimization}
\newacronym{roc}{ROC}{receiver operating characteristic}
\newacronym{roi}{ROI}{region of interest}
\newacronym{rss}{RSS}{received signal strength}
\newacronym[\glslongpluralkey={support vector machines}]{svm}{SVM}{support vector machine}
\newacronym{ue}{UE}{user equipment}
\expandafter\def\expandafter\quote\expandafter{\quote\setstretch{1}~\\}
% Revisions macro
\usepackage[normalem]{ulem}
\usepackage[user]{zref}
\newcommand{\sot}[1]{}

\newcounter{revc}
\makeatletter \zref@newprop{revcontent}{} \zref@addprop{main}{revcontent}
\zref@newprop{revsec}{} \zref@addprop{main}{revsec}

\newcommand{\revi}[2]{%
\zref@setcurrent{revsec}{\thesection}%
\zref@setcurrent{revcontent}{#2}%
\refstepcounter{revc}%
\label{#1}
\zlabel{#1}%
\uline{#2} }

\newcommand{\revinu}[2]{%
\zref@setcurrent{revsec}{\thesection}%
\zref@setcurrent{revcontent}{#2}%
\refstepcounter{revc}%
\zlabel{#1}%
\label{#1}
#2 }

\newcommand{\revr}[2]{%
\zref@setcurrent{revsec}{\thesection}%
\zref@setcurrent{revcontent}{#2}%
\refstepcounter{revc}%
\zlabel{#1}%
\label{#1} \sot{#2}} \makeatother
\newcommand{\revp}[1]{\zref[revcontent]{#1}}
\newcommand{\zsecref}[1]{\zref[revsec]{#1}}



\newcommand{\ie}{i.e., }
\newcommand{\wrt}{with respect to }
\newcommand{\Exp}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\ai}{\bm{a}^{(i)}}
\newcommand{\A}[1]{\mathcal{A}_#1}

\DeclareMathOperator{\sign}{sign}
\newcommand{\E}{E}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}

\title{Machine Learning For In-Region Location Verification In Wireless Networks}
\author{Alessandro Brighente, Francesco Formaggio, Giorgio Maria Di Nunzio, \\ and  Stefano Tomasin }
\date{\today}


%\usepackage[autostyle]{csquotes}
\usepackage[backend=biber,style=ieee]{biblatex}
\bibliography{bibliography}


\begin{document}


\maketitle

\sloppy

\begin{abstract}
\Ac{irlv} aims at verifying whether a user is inside a \underline{region of interest (ROI)}, and in wireless networks it can exploit the features of the channel between the user to be verified and the set of trusted access points. As \ac{irlv} is an hypothesis testing problem we can resort to the \ac{np} theorem, when channel statistics are known. By removing the channel knowledge assumption we instead consider \ac{ml} solutions based on either \acp{nn} or \ac{svm} to learn channel features characteristics of the ROI. We show that \ac{ml} approaches are \ac{np}-optimal for sufficiently complex machines and long enough training. For finite training \ac{ml} turns out to be more accurate than then \ac{np} applied on estimated channel statistics. \revi{rev14}{When the channel feature data is available only for the normal scenario (and not for the attack) we resort to one-class classifications, namely through the auto-encoder and one-class \ac{svm}. However,  we prove that they are not equivalent to the  \acf{glrt}, that typically replaces \ac{np} when statistics under only one hypothesis are available. Lastly, we consider  the use of (one-class) classifiers to accelerate the success of a sequence of attacks made from various positions.} Numerical results are provided to support the results in a realistic cellular scenario, including shadowing and fading effects for the channel description.
\end{abstract}

\begin{IEEEkeywords}
Auto-encoder, in-region location verification, machine learning, neural network, support vector machine.
\end{IEEEkeywords}

\glsresetall
\clearpage
\section{Introduction}
\label{sec:intro}

Location information without verification gives ample opportunities to attack a service granting system since the location information can be easily manipulated either by tampering the hardware/software reporting the location or by spoofing the \ac{gnss} signal outside the user device. In this context, location verification systems aim at verifying the position of mobile devices in a mobile communication network. These systems can be used to implement location-based granting systems, e.g., location-based access control, media streaming, and social networking, and have applications in sensor networks \cite{Zeng-survey, 8376254, wei2013}, the Internet of Things \cite{7903611}, and geo-specific encryption solutions \cite{quaglia}. In the literature, there are approaches that leverage the features of the wireless channel over which communication occurs. For example, the approach proposed by \cite{li2010security} uses \ac{rss} to provide the measurement of the distance between the user and other network nodes.

\revi{rev2lit}{Location verification can be classified into various sub-problems. A first sub-problem is the {\it single location verification}, to verify if a user is in specific point. A solution is obtained by comparing some channel features of the user under test with those of trusted user that was in the same location in the past.}\revi{rev3cit}{In some works, this approach is used to verify if messages come from the same user, i.e. as a {\it user authentication} mechanism: in \protect{\cite{Baracca-12}} channel features are affected by noise with known  statistics, whereas in \protect{\cite{7398138}} statistics are unknown and a learning strategy is adopted (see also \protect{\cite{7270404}} for a survey).  A second sub-problem is the {\it \ac{irlv}}, to verify if a user is inside a \ac{roi} \cite{Zeng-survey}.}\revi{rev2lit2}{Solutions include distance bounding techniques with rapid exchanges of packets between the verifier and the prover \cite{Brands, singelee2005location}, while in {\cite{song2008secure} the same techniques are applied to vehicular ad-hoc networks}. Other solutions use radio-frequency and ultrasound signals {\cite{Sastry}} or anchor nodes and increasing transmit power by the sender {\cite{Vora}}. More recently, a delay-based verification technique leveraging geometric properties of triangles, which prevents an adversary from manipulating measured delays, has been proposed in {\cite{7145434}}. Some of the proposed techniques partially neglect wireless channel phenomena (such as shadowing and fading) that corrupt the distance estimates {\cite{Brands,Sastry,Vora}}. Other approaches assume specific channel statistics {\cite{quaglia}} that may be not accurate due to changing environment conditions, their dependency on unknown parameters, or the use of advanced signal processing techniques by the attacker.} 

If the statistics of the channels of links to devices both inside and outside the \ac{roi} are known to the network infrastructure, the optimal solution for \ac{irlv} is given by the \ac{np} theorem {\cite{Cover-book}} that provides the most powerful test for a given significance level. When the knowledge of the channel statistics is not available, a two-step solution would be to a) estimate the channel statistics and b) apply the \ac{np} theorem on the estimated statistics. However, as we also confirm in this paper, this approach may not be accurate. Alternatively, \ac{ml} techniques can be used to exploit the available training data and to optimize directly the decision process rather than going through the two-step solution. For example, in \cite{xiao-2018} no assumption is made on the channel model and logistic regression has been proposed as an alternative to hypothesis testing. In \cite{tian2015robust}, the objective is to locate the user inside a building and a multi-class classification problem is solved via \ac{svm}. Nevertheless, neither \cite{xiao-2018}  nor \cite{tian2015robust} compare the performance of their \ac{ml} approaches with the theoretical optimum \ac{np} criterion.

In this paper, we remove the channel knowledge assumption and study two \ac{ml} solutions based on \acp{nn} and \ac{svm} to learn channel features of the \ac{roi}. We investigate two loss functions for the \ac{mlp} design, namely the \ac{ce} and the \ac{mse} for \acp{nn}, and  \ac{ls} for \ac{svm}. We show that these two approaches are \ac{np}-optimal for sufficiently complex machines as well as sufficiently large training data. Moreover, for a limited training dataset, the \ac{ml} approach turns out to be more accurate than \ac{np} applied on estimated channel statistics. 

\revi{attack1}{In the location verification literature there are two classes of threats, either the attacker sends forged messages to the verification system \cite{singelee2005location} \cite{song2008secure} \cite{Sastry} or he tampers with the signal power making it coherent with the fake claimed position \cite{Vora} \cite{yan2016location} \cite{li2010security}. The first class of attacks targets verification systems which require bits transmission, while countermeasures for the second class are based on channel features like \ac{rss}. In this paper we focus on the second class, as our protocol does not require the decoding of verification messages or nonces.
}

Two specific security issues are then addressed. Firstly, the attacker can select the location for the attack and its statistics \hl{non mi e' chiaro its statistics a cosa faccia riferimento} can be modified. We explore the one-class classification problem both under the knowledge of legitimate channel statistics and by a \ac{ml} approach, and we conclude that conventional \ac{ml} solutions based on both the \ac{ae} and one-class \ac{svm} do not coincide with the \ac{glrt}, even under asymptotic training  conditions. \revi{rev11a}{The obtained asymptotic results are applicable also to elaborate ML solution, such as deep learning NNs, that can still be seen as parametric functions, although more complex than conventional NNs.}Secondly, advanced attacks based on the use of \ac{ml} techniques to select the positions of attack by the attacker are considered. Numerical results are provided to support the results in a realistic network scenario, including shadowing and fading effects for the channel. We show that in a simple scenario a simple \ac{nn} and a relatively small training dataset already provide close-to-optimal performance; then, we assess the one-class \ac{irlv} approach as well as the advanced attack strategy based on \ac{ml}. \revi{WiFi}{Indeed, while at the moment most literature has focused on WiFi or IoT applications for \ac{irlv}, positioning is a relevant feature for 5G and beyond cellular systems, and as reference example we consider a cellular scenario in this paper.}

\uline{The contributions of this paper are summarized hereby:}
\begin{enumerate}
    \item \uline{we propose a physical layer-based \ac{irlv} solution based on \ac{ml} techniques: the proposed solutions are suitable to operate with noisy estimates and when the statistics of noise and other impairments affecting the estimates are not known, thus obtaining a model-less solution;}
    \item \uline{we show that the performance (in terms of \ac{fa} and \ac{md} probabilities) of two-class classification \ac{ml} techniques for \ac{irlv} approaches (in asymptotic training and complexity conditions) that of the ac{np} test, which is most powerful for a given significance level;}
    \item \uline{we explore some novel attack strategy against \ac{irlv}, still based on \ac{ml} techniques, now based on training sets collected by the attacker ouside the \ac{roi}.}
\end{enumerate}
\revi{lit2}{In particular, about the first point we design an \ac{irlv} solution able to operate in a scenario with channel impairments such us shadowing and fading, which is new in the location verification literature. Indeed, in {\cite{Vora}} \ac{rss} measurements are explicitly treated interchangeably as distance measures neglecting all shadowing and fading phenomena. Similarly, in {\cite{Sastry}} it is generically assumed that agents are able to communicate and exchange packets without errors, as in all protocols requiring nonces transmission {\cite{singelee2005location}}, {\cite{song2008secure}}. In {\cite{yan2016location}} and {\cite{li2010security}} shadowing is taken into account, even though not fading. However, in {\cite{yan2016location}} shadowing is relative to a single user position, allowing the authors to derive the channel statistic and in {\cite{li2010security}} authors assume the knowledge of the path-loss model. Both these hypotheses are not required by our \ac{irlv} system. Moreover, in this paper we focus on \ac{irlv}, which is different from verifying a claimed specific location {\cite{singelee2005location} \cite{li2010security}} or authenticating a user with its location {\cite{yan2016location}}}.
% We will show that if we use the mechanism in {\cite{li2010security}} for specific location verification we achieve worse performance than our proposed \ac{irlv} system.

\revi{framework1}{The more realistic channel model we take into account is instrumental to show that exact likelihood ratio computation is not always feasible, while resorting to \ac{ml} techniques makes \ac{irlv} still possible. This suggests that the same idea can be applied in different contexts. Namely one could use different channel features (like in \cite{fang2018learning} for user authentication), or exploit other sensor measurements depending on the application. In this paper we focus on wireless communication scenario in which standard communication sensors are available, but we believe that the extension to a more general framework is straightforward.}

The rest of the paper is organized as follows. Section II introduces the system model for the \ac{irlv} problem, detailing the channel model and summarizing the \ac{np} theorem under the knowledge of channel statistics. Section III describes the considered \ac{ml} approaches for \ac{irlv}, namely the \ac{mlp} \ac{nn} and the \ac{svm}, with their design approaches based on \ac{mse} or \ac{ce} for the \ac{nn}, and on  \ac{ls} for \ac{svm}. In Section IV, we propose the one-class classification approach where only the channel statistics for locations inside the \ac{roi} are used for training. Both the the \ac{ae} \ac{nn} and the \ac{oclssvm} are considered and their performance is compared with the \ac{glrt} test. Advanced attack strategies based on the use of \ac{ml} by the attacker are proposed in Section V. Numerical results comparing the various techniques are shown and discussed in Section VI. Lastly, the main conclusions are outlined in Section VII.

The following notation is used throughout the paper: bold letters $\bm{x}$ refer to vectors, whereas capital bold letters $\bm{H}$ refer to matrices, $\mathbb{E}[x]$ denotes the expectation of random variable $x$, $(\cdot)^T$ denotes the transpose, $\mathbb P[A]$ denotes the probability of event $A$, and $\ln(x)$ denotes the natural base logarithm of $x$.

\section{System Model}

\begin{figure}
    \centering
    \includegraphics[width=0.6\columnwidth]{irlv.jpg}
    \caption{The considered \ac{irlv} scenario.}
    \label{fig1}
\end{figure}

In Fig. \ref{fig1}, we consider a cellular system with $N_{\rm AP}$ \acp{ap} covering the area $\mathcal{A}$ over a plane. We propose a \ac{irlv} system to determine if a \ac{ue} is transmitting from within an {\em authorized} \ac{roi} $\mathcal{A}_0$ inside  $\mathcal{A}$. we define the complementary region to the \ac{roi} as $\mathcal{A}_1=\mathcal{A} \setminus \mathcal{A}_0$. The authentication process exploits the location dependency of the features of the channel between the \ac{ue} and the \acp{ap}. \revi{revPHASE}{As an exmple of \ac{irlv} based on physical channel features, we consider here a narrowband transmission and choose as feature the power attenuation. This is in line with various works in the literature \protect{\cite{boh}}. Indeed, other features can also be exploited, such as the phase or the wideband impulse response: the proposed ML techniques readily applied also to this cases as we do not make special assumptions on the channel model for their design and analysis.}

The exploitation of the channel features is obtained by letting the \ac{ue} transmit a signal with fixed power $P_{\rm tx}$, known at the \acp{ap}, from which the \acp{ap} can estimate the received power and obtain a measure of the attenuation incurred by the channel. We assume that the attenuation estimation is perfect, i.e., not affected by noise or interference: this can be achieved by using a sufficiently long signal.



\subsection{Channel Model}\label{sec:chMod}

When the \ac{ue} transmits with power $P_{\rm tx}$, the received power at the $n^{\rm th}$ \ac{ap} is
\begin{equation}\label{eq: rec pow}
    P_{\rm rc}^{(n)}= \frac{P_{\rm tx}}{a^{(n)}},
\end{equation}
where $a^{(n)}$ is the attenuation incurred over the channel between the \ac{ue} and the \ac{ap} $n$. The attenuation coefficient includes the effects of path-loss, shadowing and fading. In particular, by assuming Rayleigh model for fading we have 
\begin{equation}
    \sqrt{a^{(n)}} \sim \mathcal{N}\left(0,\sigma_{a,n}^2\right),
\end{equation}
where $(\sigma_{a,n}^2)_{\rm dB} =  {P_{\rm PL}^{(n)}}  + s$ accounts for the path-loss and shadowing components, $(P_{\rm PL}^{(n)})_{\rm dB}$ is the path-loss coefficient in dB, and $s \sim \mathcal{N}(0,\sigma_{s,{\rm dB}}^2)$ is the shadowing component. Moreover, the shadowing components of \acp{ue} located at different positions are correlated.

%Both path-loss and shadowing models are  derived from \cite{3gpp}. 
The channel model for path-loss and shadowing is derived from \cite{3gpp}. In particular, let us denote as $\bm{x}_{\rm AP}^{(n)} =(X_{\rm AP}^{(n)},Y_{\rm AP}^{(n)})$ the position of  \ac{ap} $n= 1, \ldots, N_{\rm AP}$. For a \ac{ue} located at $\bm{x}_{\rm UE}=(X_u,Y_u)$, its distance from \ac{ap} $n$ is $L(\bm{x}_{\rm UE},\bm{x}_{\rm AP}^{(n)}) = \sqrt{(X_{\rm AP}^{(n)}-X_u)^2+(Y_{\rm AP}^{(n)}-Y_u)^2}$. 

\revi{WiFi2}{Here we focus on a cellular communication scenario as a reference model for performance evaluation. However, the proposed \ac{irlv} technique can also be applied to wireless local area networks (WLANs) and IoT scenarios.} For the path-loss, we consider two scenarios: \ac{los} and non-\ac{los}. For a \ac{los} link, the path-loss in dB is modelled as
\begin{equation}\label{eq:los}
    P_{{\rm PL},{\rm LOS}}\left(L(\bm{x}_{\rm UE},\bm{x}_{\rm AP}^{(n)})\right) = 10 \nu \log_{10}\left(\frac{f 4\pi L(\bm{x}_{\rm UE},\bm{x}_{\rm AP}^{(n)})}{c}\right),
\end{equation}
where $\nu$ is the path-loss coefficient, $f$ is the carrier frequency and $c$ is the speed of light. 
For a  non-\ac{los} link, the path-loss coefficient in dB is defined as
\begin{equation}\label{eq:nlos}
    P_{{\rm PL}, {\rm NLOS}}\left(L(\bm{x}_{\rm UE},\bm{x}_{\rm AP}^{(n)})\right) = 40\log_{10}\left (\frac{L(\bm{x}_{\rm UE},\bm{x}_{\rm AP}^{(n)})}{10^3}\right ) + 21\log_{10}\left(\frac{f}{10^6}\right) + 80.
\end{equation}
\uline{According to \cite{3gpp} shadowing parameters of two \acp{ue}  at  positions $\bm{x}_i$ and $\bm{x}_j$   have correlation $\sigma_{s,{\rm dB}}^2e^{-\frac{L(\bm{x}_i,\bm{x}_j)}{d_c}}$, where $d_c$ is the shadowing decorrelation distance \underline{\cite[Chapter 2.7]{goldsmith2005}}.} 

Path-loss and shadowing are assumed to be time-invariant, while the fading component is independent at each attenuation estimate. 

\revi{avg_1}{Fading does not give information on the \ac{ue} location, thus is a disturbance in the \ac{irlv} process. However, fading is typically time-varying, and by performing multiple estimates of the attenuation in a short time we can assume that both path-loss and shadowing do not change (due a very small movement of the \ac{ue}), while going through independent fading realizations. In particular, when $k_f$ estimates with independent fading realizations are available, the \ac{ap} $n$ can average them obtaining the new attenuation estimate}
\begin{equation}
\label{eq:avg}
a^{(n)}_{\Sigma} = \frac{1}{k_f}\sum_{j=1}^{k_f} a^{(n)}.
\end{equation} 
 

\subsection{\ac{irlv} With Known Channel Statistics}\label{sec:auth}

The \ac{irlv} problem can be seen as a hypothesis testing between the two hypotheses (events):
\begin{itemize}
    \item $\mathcal{H}_0$: the \ac{ue} is transmitting from area $\mathcal{A}_0$;
    \item $\mathcal{H}_1$: the \ac{ue} is transmitting from area $\mathcal{A}_1$.
\end{itemize}
This is also denoted as a two-class classification problem. Given vector $\bm{a} = [a^{(1)}, \ldots, a^{(N_{\rm AP})}]$ collecting the attenuation estimates at all the \acp{ap}, we aim  at determining the most likely hypothesis in order to perform \ac{irlv}. While a few measurements of path-loss would allow, by triangulation, to establish the exact position of the \ac{ue}, both shadowing and fading make the \ac{irlv} more problematic and in general prone to errors. 


Let $\mathcal H \in  \{\mathcal{H}_0, \mathcal{H}_1\}$ be the effective location of the \ac{ue}, and $\hat{\mathcal H} \in  \{\mathcal{H}_0, \mathcal{H}_1\}$ the decision taken at the \acp{ap}. We have two possible errors: \acp{fa}, which occur when the \ac{ue}  is classified as outside the \ac{roi}, while being inside it, and \acp{md}, which occur when the \ac{ue}  is classified as inside the \ac{roi}, while being outside of it. We indicate the probability of \ac{fa} as $P_{\rm FA} =P(\hat{\mathcal H} = \mathcal H_1 | \mathcal H = \mathcal H_0)$ and the  probability of \ac{md} as $P_{\rm MD}=P(\hat{\mathcal H} = \mathcal H_0 | \mathcal H = \mathcal H_1)$. 
%
Let $p(\bm{a}|\mathcal{H}_i)$ be the probability of observing the vector $\bm{a}$ given that $\mathcal{H} = \mathcal{H}_i$. The \ac{llr} for the considered hypothesis is defined as 
\begin{equation}\label{eq:lr}
    {\mathcal M}(\bm{a})=\ln \frac{p(\bm{a}|\mathcal{H}_0)}{p(\bm{a}|\mathcal{H}_1)}.
\end{equation}
According to the \ac{np} theorem, the most powerful test is obtained by comparing $\mathcal{M}(\bm{a})$ with a threshold value $\Lambda$, i.e., obtaining the test function
\begin{equation}
\label{eq:oneClassDec}
f^*(\bm{a}) =
\begin{cases}
-1 &\text{if } {\mathcal M}(\bm{a}) \geq \Lambda, \\
1 & \text{if } {\mathcal M}(\bm{a}) < \Lambda.
\end{cases}
\end{equation}
\revi{lambda}{The value $\Lambda$ is a parameter which grants a certain significance level, meaning the probability of rejecting the null hypothesis when it is true ($P_{\rm FA}$). The parameter $\Lambda$ shall hence be chosen according to the \ac{fa} performance that we require by the system and its value must be computed by trial and error. The \ac{np} test hence guarantees that, by implementing hypothesis testing as in (\ref{eq:oneClassDec}), for the selected $P_{\rm FA}$ value, the resulting $P_{\rm MD}$ is minimum and hence optimal.}

\subsection{Example of \ac{np} Test}\label{sec:los}
\begin{figure}
    \centering
    \includegraphics[width=0.5\columnwidth]{simpleScen.jpg}
    \caption{Simplified scenario with a single \ac{ap} located at the center of a circular \ac{roi}.}
    \label{fig:simpScen}
\end{figure}
\revi{simpleScen}{We provide here an example of an application of the \ac{np} theorem to the simple scenario of Fig. \ref{fig:simpScen}, where area $\mathcal{A}$ is a circle with radius $R_{\rm out}$ ans \ac{roi} $\mathcal{A}_{0}$ is an ring concentric to the overall area with larger radius $R_{\rm in}$ and smaller radius $R_{\rm min}$. A single \ac{ap} ($N_{\rm AP} =1$) is located at the \ac{roi} center and a \ac{ue} is transmitting from distance $d$. We consider two models: a) \emph{fading scenario}, which includes path-loss and fading, and b) \emph{uncorrelated shadowing scenario} which includes path loss and spatially-uncorrelated shadowing. In both cases we consider the \ac{los} scenario for path-loss.}
\revi{simpleScen2}{In order to compute $p(a|\mathcal{H}_i)$ we first observe that the probability of incurring in an attenuation $a$ for a user located inside the \ac{roi} is given by the total probability law}
\begin{equation}\label{eq:prc}
p(a|\mathcal{H}_0) = \int_{0}^{R_{\rm in}} p\left( \frac{P_{\rm tx}}{a} | d = d_0\right)p(d_0| d_0 \in \mathcal{A}_0) \, {\tt d}d_0,    
\end{equation}
\revi{simpleScen2_1}{where $p(d_0| d_0 \in \mathcal{A}_0)$ is the probability of the \ac{ue} transmitting from distance $d_0$ inside the \ac{roi}. Assuming that \ac{ue} position is uniformly distributed in the whole area we have} 
\begin{equation}\label{eq:a0}
p(d_0| d_0 \in \mathcal{A}_0) =
\begin{cases}
\frac{2 d_0}{R_{\rm in} ^ 2-R_{\rm min}^2} \, \, d_0 \in [R_{\rm min}, R_{\rm in}], \\
0 \, \, d_0 > R_{\rm in}
\end{cases}
\end{equation}
\revi{simpleScen2_2}{whereas}
\begin{equation}\label{eq:a1}
p(d_0| d_0 \in \mathcal{A}_1) =
\begin{cases}
0 \, \, d_0 \leq R_{\rm in},\\
\frac{2 d_0}{R ^ 2- R_{\rm in} ^2} \, \, d_0 \in (R_{\rm in},R].
\end{cases}
\end{equation}
\subsubsection{Fading scenario}
\revi{simpleScen3} {Assuming spatially-uncorrelated Rayleigh fading the received power at the \ac{ap} given a user located at distance $d$ is exponentially distributed with mean $P_{{\rm PL},{\rm LOS}}(d)$ given by (\ref{eq:los}). Hence from (\ref{eq:a0}) we have}

\begin{equation}\label{eq:fading}
    p(a|\mathcal{H}_0) = 
    \frac{2}{R_{\rm in}^2-R_{\rm min}^2}\int_{R_{\rm min}}^{R_{in}} 10^{P_{{\rm PL},{\rm LOS}}(d_0)/10} \exp\left(-10^{P_{{\rm PL},{\rm LOS}}(d_0)/10} \frac{P_{\rm tx}}{a}\right)d_0 \, {\tt d}d_0,
\end{equation}
\revi{simpleScen3_1}{whereas from (\ref{eq:a1}) we have}
\begin{equation}\label{eq:fading2}
    p(a|\mathcal{H}_1) = 
    \frac{2}{R^2-R_{\rm in}^2}\int_{R_{\rm in}}^R 10^{P_{{\rm PL},{\rm LOS}}(d_0)/10} \exp\left(-10^{P_{{\rm PL},{\rm LOS}}(d_0)/10} \frac{P_{\rm tx}}{a}\right)d_0 \, {\tt d}d_0,
\end{equation}
\revi{simpleScen3_2}{By computing integrals for path-loss coefficient $\nu = 2$ the \ac{llr} is} 
\begin{equation}\label{eq:llr1}
   \mathcal{M}(a) =
   \ln\left(\frac{R^2-R_{\rm min}^2}{R_{\rm in}^2-R_{\rm in}^2}\frac{\mathcal{V}(R_{\rm min},a)-\mathcal{V}(R_{\rm in},a)}{\mathcal{V}(R_{\rm in},a)-\mathcal{V}(R,a)}\right),
\end{equation}
\revi{simpleScen3_2_1}{where}
\begin{equation}
\mathcal{V}(d_0,a) = \exp\left(-\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0 d_0}{c}\right)^2\right) \left(\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0 d_0}{c}\right)^2+1\right) .   
\end{equation}

\revi{simpleScen3_3}{For $\nu=3$ we have instead}
\begin{multline}\label{eq:llr2}
 \mathcal{M}(a) =
 \ln\left(\frac{R^2-R_{\rm in}^2}{R_{\rm in}^2-R_{\rm min}^2}\frac{\Gamma\left(\frac{5}{3},\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R_{\rm min}^3\right)-\Gamma\left(\frac{5}{3},\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R_{\rm in}^3\right)}{\Gamma\left(\frac{5}{3},\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R_{\rm in}^3\right)-\Gamma\left(\frac{5}{3},\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R^3\right)}\right),
\end{multline}
\revi{simpleScen3_4}{where $\Gamma(\gamma,b)= \int_{b}^{\infty}t^{\gamma-1}e^{-t} dt$ is the incomplete gamma function.}    

\subsubsection{Uncorrelated shadowing scenario}
\revi{simpleScen4}{Assuming spatially-uncorrelated shadowing the received power is distributed in the logarithmic domain as a Gaussian random variable with mean value given by the path-loss (\ref{eq:los}) and variance $\sigma_s^2$. Considering (\ref{eq:prc}) the probability of incurring an attenuation $a$ in hypothesis $\mathcal{H}_0$ is given by}
\begin{equation}\label{eq:sh}
   p(a|\mathcal{H}_0) = 
    \frac{2}{R_{\rm in}^2-R_{\rm min}^2}\int_{R_{\rm min}}^{R_{\rm in}} \exp\left(-\frac{1}{2}\frac{\left(\frac{P_{\rm tx}}{a}+10\nu\log_{10}\left(\frac{4 \pi f_0 d_0}{c}\right)\right)^2}{\sigma_s^2}\right) d_0 \, {\tt d} d_0, 
\end{equation}
\revi{simpleScen4_1}{whereas in hypothesis $\mathcal{H}_1$}
\begin{equation}\label{eq:sh1}
    p(a|\mathcal{H}_1) = 
    \frac{2}{R^2-R_{\rm in}^2}\int_{R_{\rm in}}^R \exp\left(-\frac{1}{2}\frac{\left(\frac{P_{\rm tx}}{a}+10\nu\log_{10}\left(\frac{4 \pi f_0 d_0}{c}\right)\right)^2}{\sigma_s^2}\right) d_0 \, {\tt d} d_0 .
\end{equation}
\revi{simpleScen4_2}{By solving the integrals in (\ref{eq:sh}) and (\ref{eq:sh1}) we obtain the \ac{llr}}
\begin{equation}\label{eq:llr3}
    \mathcal{M}(a) = \ln\left(\frac{R^2}{R_{\rm in}^2} \frac{\mathcal{T}(R_{\rm in})-\mathcal{T}(R_{\rm min})}{\mathcal{T}(R)-\mathcal{T}(R_{\rm in})}\right),
\end{equation}
\revi{simpleScen4_3}{where }
\begin{equation}
    \mathcal{T}(d_0) = \erf\left( \frac{\frac{100 \nu^2}{\sigma_s^2}\ln(d_0)-\ln^2(10)+\frac{\frac{P_{\rm tx}}{a} 10 \nu \ln(10)}{2\sigma_s^2}}{\sqrt{1/2\sigma_s^2}10\nu\ln(10)}\right),
\end{equation}
\revi{simpleScen4_4}{ and $\erf(x)= \frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} dt$ is the error function.}

\revi{llrComp}{We notice however that the obtained functions are easily computed for a single \ac{ap} and spatially uncorrelated fading and shadowing. In more complicated scenarios including spatially correlated channels and multiple \acp{ap} the probabilities of incurring in a certain attenuation in the two hypotheses would not have a simple solution, making the implementation of \ac{np} test problematic. We thus propose to implement the \ac{irlv} hypothesis testing by \ac{ml} approaches, which do not require the a-priori knowledge of the probability density functions.}

\subsection{Estimated Distance Approach} \label{seccomp}
\revi{literature_1}{In order to compare our approach with existing \ac{irlv} solutions, we consider the  \ac{mmse} approach for estimating the distance  \cite{li2010security}. We denote this solution \ac{eda}. From the measured attenuation, first the distance of the \ac{ue} from the \ac{ap} is estimated by inverting the path-loss models. Then the \ac{ue} position is estimated by solving 
}
	\begin{align}
 \hat{\bm x}_{\rm UE} =  \underset{\bm x}{\arg \min} \sum_{n=1}^{N_{\rm AP}} \left(L(\bm{x},\bm{x}_{\rm AP}^{(n)}) - L(\bm{x}_{\rm UE},\bm{x}_{\rm AP}^{(n)}) \right)^2,\label{probmindist}
\end{align}
\revi{literature_2}{Let $\mathcal B_0$ be the set of points of the border of $\mathcal A_0$. Then measure the  distance of the UE from the  border of $\mathcal{A}_0$ as $d = \min_{\bm{x} \in \mathcal{B}_0} \pm||\hat{\bm x}_{\rm UE} - \bm{x}||$,  where the sign is negative if $\hat{\bm x}_{\rm UE} \in \mathcal A_0$, and positive otherwise. Lastly, $d$ is compared with a suitable threshold $d_0$, chosen in order to achieve desired FA or MD probability, and the test can be written as
}

\begin{equation}
\hat{\mathcal{H}}_{\rm MMSE} = 
\begin{cases}
\mathcal{H}_0 \quad \text{if } d < d_0 \\
\mathcal{H}_1 \quad {\rm otherwise}.
\end{cases}
\end{equation}

\revi{literature_3}{Note that the MSE (\ref{probmindist}) is not the optimal performance metric, since the position error is not Gaussian. Moreover, this approach requires the knowledge of the path-loss model (including the possibility to distinguish LOS and non-LOS scenarios), to convert attenuations into distances, which is quite unrealistic in a real deployment. Indeed, most of the literature simply assume the perfect knowledge of the \ac{ue}-\ac{ap} distance.}



\section{\Ac{irlv} by Machine Learning Approaches}\label{sec:irlvML}

The application of the \ac{np} theorem requires the knowledge of the conditional channel statistics $p(\bm{a}|\mathcal{H}_i)$ at the \acp{ap}, which can be hard to obtain also because a-priori assumptions on their expressions may be quite unrealistic. Therefore, we propose to use a \ac{ml} approach operating in two phases:
\begin{itemize}
    \item {\em Learning phase}: the \ac{ap} collects attenuation vectors from a trusted \ac{ue} moving both inside and outside the \ac{roi}, while the \ac{ue} reports its position to the \acp{ap}. In this way, the \acp{ap} can learn the behaviour of the attenuation in both regions $\mathcal A_0$ and $\mathcal A_1$.
    \item {\em Exploitation phase}: the \ac{ap} verifies the location of an un-trusted \ac{ue} by the attenuation's estimate using the data acquired in the learning phase. 
\end{itemize}

\revi{supervised}{As in the learning phase the trusted \ac{ue} reports to the \ac{ap} its position, we can assign true labels to all the collected attenuation vectors in this phase and therefore train the \ac{ml}-based \ac{irlv} system with examples of classified data. In the \ac{ml} framework this type of learning is referred to as \emph{supervised learning}.}

The learning phase works as follows: for each training attenuation vector $\ai$,  $i=1, \ldots, S$, collected during the learning phase, there is an associated identification value $t_i$, $i=1, \ldots, S$, where $t_i= -1$ if the trusted \ac{ue} is in region $\mathcal{A}_0$ and $t_i = 1$ if the trusted \ac{ue} is in region $\mathcal{A}_1$. Vector $\bm{t}=[t_1, \ldots, t_S]$ collects the labels of all the  attenuation vectors in the training phase. Given these data, the \ac{ap} learns a function  $\hat{t} = f(\bm{a})\in \{-1, 1\}$ that provides a decision $\hat{\mathcal H}$ for each attenuation vector $\bm{a}$. Then, in the exploitation phase, the \ac{irlv} algorithm computes $\hat{t} = f(\bm{a})$ for a new attenuation vectors and takes a decision between the two hypotheses. Note that our solution does not explicitly evaluate the \ac{pdf} and the \ac{llr}, but rather it directly implements the test function.

\revi{framework2}{We stress the fact that now the channel model of Section \ref{sec:chMod} has the purpose of simulating a realistic communication scenario, while the analysis that follows is general, as no specific channel statistic is assumed.}

In the rest of this Section, we briefly review the \ac{mlp} \ac{nn} and the \ac{svm}, describe the learning process and show that in asymptotic conditions (infinite training attenuation vectors and sufficiently complex models) both \ac{mlp} and \ac{svm} functions approximate the \ac{llr} function.
  
\subsection{Neural Networks}\label{sec:nn}

A \ac{nn} is a $\mathbb{R}^N \to \mathbb{R}^O$ function mapping a set of $N$ real values into $O$ real values. A \ac{nn} processes the input in $Q$ stages, named layers, where the output of one layer is the input of the next layer. Layer $0$ with input $\bm{y}^{(0)}$ is denoted {\em input layer}, layer $Q-1$ with output $\bm{y}^{(Q)}$ is denoted {\em output layer}, while intermediate layers are denoted {\em hidden layers}. \underline{We denote as $N_L$ the number of hidden layers}.
%
Each layer $\ell=0, \ldots, Q-1$ has $N^{(\ell)}$ outputs obtained by processing the inputs with $N^{(\ell-1)}$ functions named neurons. The output of the $n^{\rm th}$ neuron of the $\ell^{\rm th}$ layer is
\begin{equation}\label{eq:nonLin}
y_n^{(\ell+1)} = \psi^{(\ell)}\left( \bm{w}_n^{(\ell)}\bm{y}^{(\ell)}+b_n^{(\ell)} \right),
\end{equation}
where the mapping between the input and the outpus is given by the {\em activation function} $\psi^{(\ell)}(\cdot)$. The argument of the activation function is a weighted linear combination, with weights $\bm{w}_n^{(\ell)}$, of the outputs $\bm{y}^{(\ell)}$ of the previous layer plus a bias $b_n^{(\ell)}$. We focus here on feedforward \acp{nn}, i.e., without loops between neurons' input and output, an architecture also known as \ac{mlp}. For a in-depth description of \acp{nn} refer for example to \underline{\cite[Chapter 6]{goodfellow}}. While the activation functions are typically fixed, the vectors $\bm{w}_n^{(\ell)}$ are adapted according to the perceptron learning algorithm in order to optimize the desired output. 
\revi{hyper1}{The activation function type is a variable which is not an output of the learning algorithm and must be chosen beforehand. We denote these values as "hyper-parameters", in contrast with "parameters" which are instead the result of the learning procedure.}

In our setting, the input of the \ac{nn} is the attenuation vector $\bm{a}$, $N=N_{\rm AP}$, and the output layer has a single neuron ($O=1$) providing as output the scalar $y^{(Q)}_1$. Let $\tilde{t}(\bm{a}) = y^{(Q-1)}_1$ be the output of the \ac{nn} corresponding to the attenuation vector input $\bm{a}$. A threshold $\lambda$ is used after computing the test function, i.e.
\begin{equation}
\label{testfunNN}
    f(\bm{a}) = \begin{cases}
    1 & \tilde{t}(\bm{a}) > \lambda, \\
    -1 & \tilde{t}(\bm{a}) \leq \lambda.
    \end{cases}
\end{equation}
such that, different values of $\lambda$ provide different values of \ac{fa} and \ac{md} probabilities for the resulting \ac{irlv} test.

 
\revi{lambdaNN}{As will be shown later the hypothesis testing performed by the \ac{nn} is the same implemented by the \ac{np} framework. Therefore the parameter $\lambda$ has the same meaning of the parameter $\Lambda$ and shall hence be suitably chosen in order to guarantee the required system performance in terms of \ac{fa} probability. As for the \ac{np} framework the \ac{fa} probability that can be obtained for a certain $\lambda$ must be assessed by trial and error.}  

\revi{ceNeeded}{Based on the loss function to be optimized during training , \acp{nn} can solve different problems. Based on our purpose in exploiting \acp{nn} we here consider two different loss function: \ac{mse} and \ac{ce}. }

\subsection{\ac{nn} MSE Design}
\label{sec: mse_train}
\revi{ceNeeded2}{As optimal hypothesis testing is implemented via the \ac{np} framework which exploits the knowledge of the \ac{llr} function we aim at learning this function from data. This problem is referred to as \emph{curve fitting} and it can be solved by training a \ac{nn} via \ac{mse} loss function \cite{bishop92}.}
According to the \ac{mse} design criterion \underline{\cite{bishop92}}, the \ac{mlp} parameters are estimated in order to minimize the \ac{mse} during the training phase:
\begin{equation}\label{eq:mseFunct}
\Gamma = \sum_{i=1}^S |\tilde{t}(\ai) - t_i|^2.
\end{equation}
This is achieved by using the stochastic gradient descent algorithm \underline{\cite[Chapter~3.1.3]{Bishop2006}}.

In order to prove the connection of \ac{mse} design criterion with the \ac{np} we first recall the following theorem \cite{Ruck-90}

\begin{theorem}
Let $\tilde{t}(\bm{a},\bm{W})$ be the function implemented by the \ac{nn} given the weights in matrix $\bm{W}$ and let $g_0(\bm{a})$ be the Bayes optimal discriminant function
\begin{equation}\label{eq:bayesDisc}
g_0(\bm{a}) = \mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a}) - \mathbb{P}(\mathcal{H}=\mathcal{H}_1|\bm{a}).
\end{equation} 
Then the \ac{mlp} trained by backpropagation via (\ref{eq:mseFunct}) minimizes the error
\begin{equation}
    \epsilon^2(\bm{W}) = \int_{\bm{a} \in \mathcal{A}} \left(\tilde{t}(\bm{a},\bm{W}) - g_0(\bm{a})\right)^2 {\tt d}\bm{a},
\end{equation}
where $\bm{a} \in \mathcal{A}$ is the set of attenuation vectors measured over area $\mathcal{A}$.
\label{teoruck}
\end{theorem}
\revi{teoruck2}{Hence Theorem \ref{teoruck} proves that in the presence of perfect training and for an infinite number of neurons the function implemented by the \ac{mlp} is the Bayes optimal discriminant function. Now we have the following corollary.}
\begin{corollary}
\label{th:nn_np}
The \ac{mlp} designed according to the \ac{mse} criterion with an infinite set of training points ($S \rightarrow \infty$) and a threshold (\ref{testfunNN}) converges to a test function equivalent to the \ac{np} test, thus it is the most powerful test.
\end{corollary}
\begin{proof}
From the Bayes rule we have 
\begin{equation}
g_0(\bm{a}) = \frac{p(\bm{a}|\mathcal H_0){\mathbb P}(\mathcal{H}=\mathcal H_0) - p(\bm{a}|\mathcal H_1){\mathbb P}(\mathcal{H}=\mathcal H_1)}{p(\bm{a}|\mathcal H_0){\mathbb P}(\mathcal{H}=\mathcal H_0) + p(\bm{a}|\mathcal H_1){\mathbb P}(\mathcal{H}=\mathcal H_1)}.
\end{equation}
Now, function (\ref{testfunNN}) imposes a threshold $\lambda$ on $g_0(\bm{a})$ and reorganizing terms we obtain $f(\bm{a}) = -1$ when
\begin{equation}
\frac{p(\bm{a}|\mathcal H_0)}{p(\bm{a}|\mathcal H_1)}> \frac{1 + \lambda}{1-\lambda} \, \frac{{\mathbb P}(\mathcal{H}=\mathcal H_1)}{{\mathbb P}(\mathcal{H}=\mathcal H_0)}  = \lambda^*,
\end{equation}
which is equivalent to the \ac{np} criterion except for a fixed scaling of the threshold.
\end{proof}
\revi{rev11b}{Note that this results is quite general and can be applied to NNs with any number of layers and neurons, and any parameter adaptation approach, as long as the target design function is the MSE criterion. Thus, Theorem 1 is suited also to describe the asymptotic behaviour of elaborate solutions, such as deep learning NNs.}

\subsection{\ac{nn} CE Design}
\label{sec: ce_train}

\revi{ceNeeded3}{When considering binary classification the aim is to assign labels $0$ or $1$ to input vectors, so that we can distinguish the class to which they belong. In this case the usual choice for the loss function is the \ac{ce} between the output of the \ac{nn} and the true labels of the \ac{nn} }\underline{\cite[Chapter~5.2]{Bishop2006}}.
\begin{equation}\label{eq:ce}
\chi = -\sum_{i=1}^{S} t_i\ln(\tilde{t}(\ai))+(1-t_i)\ln( 1-\tilde{t}(\ai)).
\end{equation}

We now prove the connection of \ac{ce} design criterion with the \ac{np} theorem.
\begin{theorem}
\label{th:nn_np2}
The \ac{mlp}  designed according to the  \ac{ce} criterion with an infinite set of training points ($S \rightarrow \infty$) and a threshold (\ref{testfunNN}) converges to a test function equivalent to the \ac{np} test, thus it is the most powerful test.
\end{theorem}
\begin{proof}
The probability of being in hypothesis $\mathcal{H}_1$ given the attenuation vector $\bm{a}$ satisfies
\begin{equation}
    \mathbb{P}(\mathcal{H} = \mathcal{H}_1|\bm{a} ) = 1- \mathbb{P}(\mathcal{H} = \mathcal{H}_0|\bm{a} ).
\end{equation}
When training is performed with a \ac{ce} loss function, the output of the \ac{mlp} is the minimum \ac{mse} approximation of the probability $\mathbb{P}(\mathcal{H}_0|\bm{a}^{(i)})$ of being in hypothesis $\mathcal{H}_0$ given the attenuation vector $\bm{a}$ \underline{\cite[Chapter~5.2]{Bishop2006}}, i.e.,
\begin{equation}
    \tilde{t}(\bm{a}) \approx \mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a})\,,
\end{equation} 
where the approximation is in the \ac{mse} sense. 

Now, by using the threshold function (\ref{testfunNN}) we have 
\begin{equation}
    \mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a}) \approx  \tilde{t}(\bm{a}) \gtrsim \lambda,
\end{equation}
which can be rewritten as
\begin{equation}
    2\mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a} )-1 \gtrsim \hat{\lambda}
\end{equation}
\begin{equation}
    \mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a} )-(1-\mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a} )) \gtrsim \hat{\lambda}
\end{equation}
\begin{equation}
\label{lasteq}
    \mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a} )-\mathbb{P}(\mathcal{H}=\mathcal{H}_1|\bm{a} ) \gtrsim \hat{\lambda}.
\end{equation}
By using (\ref{testfunNN}) on the output of the \ac{nn} designed with the \ac{ce} criterion, we obtain at convergence a function (\ref{lasteq}) which coincides (except for a different threshold value) with the function performed by the \ac{nn} trained with the \ac{mse} criterion, as shown in (\ref{eq:bayesDisc}). Therefore, from Theorem 1 we conclude that also the \ac{ce} design criterion provides a test function equivalent the \ac{np} test function.
\end{proof}

\subsection{Support Vector Machine}\label{sec:svm}
A \ac{svm} \underline{\cite[Chapter~7]{Bishop2006}} is a supervised learning model that can be used for classification and regression. We focus here on binary classification to solve the \ac{irlv} problem. The \ac{svm} solution comprises the $\tilde{t}(\bm{a}): \mathbb{R}^{N_{\rm AP}} \to \mathbb{R}$  function 
\begin{equation}
\label{eq:svm}
\tilde{t}(\bm{a}) = \bm{w}^T \phi (\bm{a}) + b,
\end{equation}
where $\phi: \mathbb{R}^{N_{\rm AP}} \to \mathbb{R}^K$ is a feature-space transformation function, $\bm{w} \in \mathbb{R}^K$ is the weight vector and $b$ is a bias parameter. The test function is again provided by (\ref{testfunNN}) where now $\tilde{t}(\bm{a})$ is given by (\ref{eq:svm}). Note that in the conventional \ac{svm} formulation we have $\lambda = 0$, while here $\lambda$ is chosen according to the desired \ac{fa} and \ac{md} probabilities.

While the feature-space transformation function is typically fixed \underline{\cite[Chapter~7]{Bishop2006}}, \revi{hyper2}{\ie it is a hyper-parameter}, vector $\bm{w}$ must be properly learned from the data to perform the desired hypothesis testing. 

We consider the \ac{lssvm} approach \cite{Suykens1999} for the optimization of the \ac{svm} parameters.  Learning for \ac{lssvm} is performed by solving the following optimization problem
\begin{subequations}
	\label{eq:lssvm}
	\begin{equation}
	\label{eq:lssvmOrig}
	\underset{\bm{w},b }{\text{min}} \quad \omega(\bm{w},b) \triangleq \frac{1}{2} \bm{w}^T \bm{w} + C \frac{1}{2} \sum_{i=1}^S e_i ^2 
	\end{equation}
	\begin{equation}
	\label{eq:stpart}
	e_i =   t_i[\bm{w}^T \phi (\bm{a}^{(i)}) + b]-1   \quad i = 1 ,\dots,S\,,
	\end{equation}
\end{subequations}
where $C$ is a hyper-parameter. 
\revi{hyper3}{Hyper-parameters in \ac{lssvm}, like $C$ and the scale of radial basis kernels {\cite[Chapter 6]{Bishop2006}} can be optimized on training data using a separate procedure, e.g., see \cite{guo2008novel}.}
In conventional \ac{svm}, variables $e_i$ are constrained to be non-negative and appear in the objective function without squaring. Inequalities in the constraints translates into a quadratic programming problem, while equalities constraints in \ac{lssvm} yield a linear system of equations in the optimization values. In \cite{Yevs}, it is shown that \ac{svm} and \ac{lssvm} are equivalent under mild conditions.

From  constraints  \eqref{eq:lssvm} and the fact that $t_i = \pm 1$ we have
\begin{equation}
\label{eq:els}
e_i^2 = (1 - t_i\tilde{t}(\bm{a}^{(i)}) )^2 = (t_i - \tilde{t}(\bm{a}^{(i)}))^2,
\end{equation}
that is the squared error between the soft output of the \ac{lssvm} $\tilde{t}(\bm{a}^{(i)})$ and the correct training label $t_i$.

We now prove the equivalence between the \ac{lssvm} and \ac{np} classifiers. Let us first consider the following lemma that establishes the convergence of the learning phase of \ac{svm}, as $S\rightarrow \infty$.

\begin{lemma}
	\label{lem:lem1}
	For a large number of training samples $\bm{a}^{(i)}$ taken with a given static probability distribution from a finite alphabet $\mathcal C$, i.e., for $S \rightarrow \infty$, the vector $\bm{w}$ of the \ac{lssvm} converges in probability to a vector of finite norm $||\bm{w}||_2 = \bm{w}^T\bm{w}$.
\end{lemma}

\begin{proof}
See the Appendix.
\end{proof}
 
We can now prove the following theorem establishing the optimality of the \ac{svm} solution, as it provides the most powerful \ac{np} test for a given \ac{fa} probability.

\begin{theorem}
	\label{th:lsnp}
	\revi{revGO}{Consider a \ac{lssvm} converged to the global minimum of $\omega(\bm{w},b)$ and using an infinite number of training points $\bm{a}^{(i)}$ drawn from the finite alphabet $\mathcal C$.} Then the test function obtained by training the \ac{lssvm} and by thresholding the soft output \eqref{eq:svm} converges to  the \ac{np} test, thus is the most powerful test.
\end{theorem}
\begin{proof}
	From \eqref{eq:lssvmOrig} consider
	\begin{equation}
	\label{eq:lssvmDim1}
	\lim_{S \to +\infty} \frac{1}{S} \omega(\bm{w},b) =\frac{C}{2} \lim_{S \to +\infty}\frac{1}{S}  \sum_{i=1}^S e^2_i	=\frac{C}{2}\E_t(\bm{w},b),
	\end{equation}
	where $\E_t(\bm{w},b) = \Exp{\left(t_i - \tilde{t}(\bm{a}^{(i)})\right)^2} $ is the expected value computed \wrt the training points $\bm{a}^{(i)}$, as $S$ goes to infinity. 	The first equality in \eqref{eq:lssvmDim1} comes from Lemma 1: since $\bm{w}$ converges to a finite norm, we can write
	\begin{equation}
	\lim_{S\to \infty} \frac{1}{S} \bm{w} \bm{w}^T 	= 0.
	\end{equation} 
	The last equality comes from the strong law of large numbers. In the limit, the optimization problem \eqref{eq:lssvm} is equivalent to
	\begin{equation}
	\label{eq:lsInf}
	\begin{aligned}
	& \underset{\bm{w},b}{\text{min}} & &  \E_t(\bm{w},b), & 
	\end{aligned}	
	\end{equation}
	where we dropped constraints  \eqref{eq:lssvm} by using \eqref{eq:els}. The optimization problem is the same as in the \ac{nn} case and from \cite{Ruck-90}, with the pair $(\bm{w}^*,b^*)$ minimizing \eqref{eq:lsInf} and parametrizing \eqref{eq:svm} we have
	\begin{equation}
	\tilde{t}(\bm{a}^{(i)})  \approx \mathbb{P}(\mathcal{H}_0|\bm{a}^{(i)}) - \mathbb{P}(\mathcal{H}_1|\bm{a}^{(i)}).
	\end{equation}
	Lastly, we exploit Corollary \ref{th:nn_np} to conclude the \ac{np}-optimality of the \ac{ls}-\ac{svm}.
\end{proof}

In summary, we have proven that both \ac{nn} (with \ac{ce} and \ac{mse} design) and \ac{svm} (with \ac{ls} design) converge to the \ac{np} test function as the training set size $S$ goes to infinity, thus establishing their asymptotic optimality and their relation to theory of power powerful hypothesis testing. 


\subsection{Computational Costs of \ac{ml} Approaches}
\label{sec:comp}
\revi{comp1}{
In this section, we briefly review the computational cost for i) training each model and ii) make a prediction on a new data point. Let $\eta$ be the number of epochs (how many times each training point will be used) of a \ac{nn} and $N_{SV}$ the number of support vectors of a \ac{svm}.}

\revi{comp2}{
For a basic fully connected feed-forward network, the backpropagation training algorithm is $\mathcal O(\eta \cdot S \cdot N_L \cdot N_{\rm AP}^3)$ when the number of hidden nodes of each hidden layer is proportional to the size of the input, while the prediction of a new unseen data point is $\mathcal O(N_L \cdot N_{\rm AP}^3)$. For a more detailed analysis which takes into account also the cost of the choice of the  activation function see {\cite{Bianchini2014}}.}

\revi{comp3}{For a \ac{svm}, the estimate of the vector $\bm{w}$ at training time requires the solution of a quadratic problem the complexity of which is between $O(S^2)$ and $O(S^3)$. At test time, the prediction is linear in the number of features and the number of support vector $\mathcal O(N_{\rm AP} \cdot N_{SV})$. Indeed, more efficient online training algorithms are available {\cite{BordesEtAl2005}}.}


%It is common practice in the literature \cite{Bishop2006,Suykens1999} to work with the dual formulation of the optimization problems \eqref{eq:svmS} to \eqref{eq:lssvm} by constructing the Lagrangian. 
%In the dual formulation objective functions and constraints are expressed as functions of the kernel 
%\begin{equation}
%	\psi(\bm{r}_i,\bm{r}_j) = \phi (\bm{r}_i)^T \phi(\bm{r}_j),	
%\end{equation}
%without explicitly defining the function $\phi(\cdot)$. 
%The output of $\phi(\cdot)$ can now be of infinite dimension, like with the radial kernel family
%\begin{equation}
%	\psi(\bm{r}_i,\bm{r}_j; \sigma) = \exp \left( \frac{|| \bm{r}_i - \bm{r}_j ||^2}{2\sigma^2} \right).
%\end{equation}
%In this case, Theorem \ref{th:lsnp} holds only if
%\begin{equation}
%	\lim_{S \to +\infty} \frac{1}{S} \bm{w}^T \bm{w} < +\infty.	
%\end{equation} 
%However, if we let $C \to +\infty$ in \eqref{eq:lssvm}

\section{\ac{irlv} By One-class Classification}
\label{sec:OneClass}
 

In practice, having training points available for both regions $\mathcal A_0$ and ${\mathcal A}_1$ may be difficult since $a$) region $\A{1}$ may be quite wide and not necessarily well defined (being simply the complementary region of $\mathcal A_0$) and $b$) the attacker may use multiple antennas and, by beamforming, can induce attenuation estimates that not necessarily correspond to points in the region $\A{1}$. Therefore, we consider in this section methods that rely only on the statistics and data collected from within the region $\mathcal A_0$. \revi{oneClass}{During the training phase hence we collect attenuation vectors measured from within area $\mathcal{A}_0$ and exploit this set of vectors to train a \ac{ml} classifier which will be able to distinguish between vectors belonging to both $\mathcal{A}_0$ and $\mathcal{A}_1$ during the testing phase.} This problem can also be denoted as one-class classification since we know only samples taken from one of the classes of the problem. 

In this context, when only the channel statistics from within $\mathcal A_0$ are known a-priori, the \ac{llr} \eqref{eq:lr} can not be used as discriminant function, as $p(\bm{a}|\mathcal{H}_1)$ is not known. In this case, we can resort to the \ac{glrt} \cite{Kay-book}, which, although not proven to be optimal, is a meaningful generalization of the \ac{np} test. Hence the test function becomes 
\begin{equation}
f^*(\bm{a}) =
\begin{cases}
-1 &\text{if } p(\bm{a}|\mathcal{H}_0) \geq \Lambda \\
1 & \text{if } p(\bm{a}|\mathcal{H}_0) < \Lambda.
\end{cases}
\end{equation}

In the following, we address the problem of  one-class classification  implemented via both \ac{nn} and \ac{svm}. In particular, the network collects only samples obtained from region $\A{0}$ during the  training phase. Two approaches are considered: the \ac{ae}, using a \ac{nn}, and the \ac{oclssvm}.
 

\subsection{Auto Encoder \ac{nn}}
\label{sec:auto}

When attenuation statistics conditioned to the two hypotheses are not available, we can apply \ac{ml} solutions, as for the case of two-class classification of Section III. 

\revi{deep ae}{In particular, we consider here the \ac{ae} \protect{\cite{Hinton-2006}}, i.e., a \ac{nn} that is trained to attempt to copy its input to its output. The AE is a nonlinear generalization of principal component analysis (PCA) implemented as a cascade of two multilayer NNs: an encoder NN, which transforms the high dimensional input data into a low-dimensional code and a decoder NN, which reconstructs the original data from the low-dimensional code. Both the encoder and decoder are feedforward \ac{nn} with respectively $N_e$ and $N_d$ layers and with different number of neurons. A single constraint is on the dimension of the output layer, which has to be equal to dimension of the input layer $N$. The number of layers and neurons in each layer of the \ac{ae} is a parameter that needs to be optimized by trial ad error. For an in depth description of the \ac{ae} please refer to \protect{\cite[Chapter 14]{goodfellow}}. An example of \ac{ae} architecture is shown in Fig. \ref{fig:aeArch}. Note that not all neurons are connected to each other (i.e., we do not have a fully connected \ac{nn}, in order to reduce complexity. Indeed, it has been shown that with large input that are locally correlated, it is useful to provide only local connections on parts of the input to still achieve close-to-optimal performance, yielding a faster and more accurate convergence. When implementing \acp{ae}, it is convenient to use a linear activation function when mapping the hidden layer to the output layer \protect{\cite[Chapter 14]{goodfellow}}.} Note that the output of the \ac{ae} is a vector of the same size of the \ac{ae} input, and the one-class classification is obtained by computing the reconstruction error between the input and the output of the \ac{ae} and comparing its absolute value with a chosen threshold.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\columnwidth]{AE.jpg}
    \caption{Example of \ac{ae} architecture with $5$ input (and output) values and 3 hidden layers.} 
    \label{fig:aeArch}
\end{figure}

For our \ac{irlv} problem, we train the \ac{ae} with attenuation vectors $\bm{a}^{(i)}$ taken only when the trusted \ac{ue} is in  \ac{roi} $\mathcal A_0$. Then, by letting $\bm{y}^{(L)}$ be the output vector of the \ac{ae} for the attenuation input $\bm{a}$, the \ac{mse} of the reconstruction is 
\begin{equation}\label{eq: rec err}
    \epsilon(\bm{a} ) = \frac{1}{N}\sum_{n=1}^{N}|a_n-y^{(L)}_n(\bm{a})|^2.
\end{equation}
Finally, the \ac{irlv} test function  is  
\begin{equation}
f(\bm{a}) =
\begin{cases}
1 &\text{if } \epsilon(\bm{a} ) \geq \Lambda, \\
-1 & \text{if } \epsilon(\bm{a} ) < \Lambda.
\end{cases}
\end{equation}

About the test power of the \ac{ae}, we observe that it can be seen as a quantization (or compression process) that quantizes an $N$-dimensional signal into an $M$-dimensional signal. In order to minimize the \ac{mse} of the reconstruction error, inputs with higher probability will have smaller quantization regions. Moreover, as the number of quantization points goes to infinity (since the quantization indices are in the continuous $M$-dimensional space) all points in the same quantization region will have approximately the same probability. However, quantization error for points within each region will be different for each point; in particular, equal to zero for the quantization point and greater than zero at the edges of the quantization region. Thus, we can conclude that the \ac{ae} can not provide as output the \ac{pdf} of the input even with infinite training and an infinite number of neurons, as required by the optimal decision rule (\ref{eq:oneClassDec}). On the other hand, input points with a smaller \ac{pdf} belong to larger quantization regions for which the reconstruction error is {\em on average} larger; therefore, the output provided by the \ac{ae} is on average monotonically decreasing with the \ac{pdf} of the input point. 

\begin{comment}
The performance of the obtained classifier are given by the following 
\begin{theorem}
    Consider a \ac{ae} with perfect training, i.e., a \ac{ae} with a sufficient number of neurons and a sufficient training. Then the classifier obtained by training the \ac{ae} and by thresholding the soft output $\tilde{\epsilon}(\bm{a}^{(n)}) = \sqrt{\frac{1}{N}\sum_{i=1}^{N}|a^{(n)}_i-\hat{a}^{(n)}_i|^2},$ is equivalent, in the \ac{mse} sense, to the optimal classifier \eqref{eq:oneClassDec}.
\end{theorem}
\begin{proof}
Let us consider the \ac{mse} approximation of $\tilde{\epsilon}(\bm{a}^{(n)})$ being $1/p(\bm{a}^{(n)}|\mathcal{H}_0)$ and hence consider the minimization problem over the weight vector $\bm{w}$
\begin{equation}
	\begin{aligned}
		&\underset{\bm{w}}{\text{min}}\,\, \Exp{ \left( \tilde{\epsilon}(\bm{a},\bm{w}) - \frac{1}{p(\bm{a}|\mathcal{H}_0)}\right) ^2} = \\
		&\underset{\bm{w}}{\text{min}} \int_{\bm{a} \in \mathbb{R}^n} \left[ \tilde{\epsilon}(\bm{a},\bm{w}) - \frac{1}{p(\bm{a}|\mathcal{H}_0)} \right] ^2 p(\bm{a}|\mathcal{H}_0) d\bm{a} = \\
		&\underset{\bm{w}}{\text{min}} \left\lbrace \int_{\bm{a} \in \mathbb{R}^n} \tilde{\epsilon}(\bm{a},\bm{w})^2 p(\bm{a}|\mathcal{H}_0) d\bm{a}
		-2\int_{\bm{a} \in \mathbb{R}^n} \tilde{\epsilon}(\bm{a},\bm{w}) d\bm{a}
		+ \int_{\bm{a} \in \mathbb{R}^n} \frac{1}{p(\bm{a}|\mathcal{H}_0)} d\bm{a} \right\rbrace.
	\end{aligned}	
\end{equation}
We notice that the second term in brackets is the sum of the reconstruction error of the attenuation vectors over $\mathbb{R}^{n}$. Since different regions of $\mathbb{R}^n$ are characterized by different features and since the \ac{ae} is able to reconstruct, with small reconstruction error, only those vectors with features similar to those of the training set we can assume that the summation of the reconstruction errors over all possible feature spaces goes to infinity. The second integral does not hence depend on $\bm{w}$ as for each value of $\bm{w}$ it goes to infinity. The last term in brackets does not depend on the weight vector $\bm{w}$ and hence the only term that depends on $\bm{w}$ is the first one, which is the objective function of the training optimization problem. Noticing that thresholding $\frac{1}{p(\bm{a}|\mathcal{H}_0)}$ with $\gamma$ is equivalent to thresholding $p(\bm{a}|\mathcal{H}_0)$ with $1/\gamma$ we conclude that training the \ac{ae} with $\epsilon$ loss function provides a classifier that approximates in the \ac{mse} sense the optimal one (\ref{eq:oneClassDec}).
\end{proof}
\end{comment}

\subsection{One-Class LS-SVM}

Similarly, we can resort to \ac{svm} to perform the one-class classification in \ac{irlv}. We focus in particular on the  \ac{oclssvm}, first introduced in \cite{choi2009} as an extension of the one-class \ac{svm} \cite{Scholkopf2001estimating}. 

The only difference with respect to the \ac{svm} introduced in Section III is that the training optimization problem is now
\begin{subequations}
	\label{eq:oneClassSvm}
	\begin{equation}
	\label{eq:oneClass1}
	\underset{\bm{w},b}{\min} \quad \omega(\bm{w}, b) \triangleq
	 \frac{1}{2} \bm{w}^T \bm{w} +  \frac{C}{2} \sum_{i=1}^S e_i^2 +b
	\end{equation}
	\begin{equation}
	\label{eq:oneClassConstr}
	\text{subject to}\, -b - \bm{w}^T \phi (\bm{a}^{(i)})  = e_i,  \quad i = 1,\dots S, 
	\end{equation}
\end{subequations}
where $C$ is a hyper-parameter.
Note that in the one-class case, the bias parameter $b$ appears also in the objective function.


We observe also in this case that the one-class \ac{svm} is suboptimal, as it does not provide a monotone function of the \ac{pdf} of the input points. In fact, it is not necessary that the training points far from the bound of the classification region are less probable, and the direction $\bm{w}$ is obtained by an ensemble elaboration of the \ac{pdf} of the input rather then been a point-wise function of it (\hl{rileggere}). Nevertheless, by resorting to the Chernoff bound, we can conclude that by minimizing the \ac{mse} we also minimize the upper bound the probability of false alarm; therefore the optimization process goes in the right direction although not optimal.



\begin{comment}
We want to show that the \ac{oclssvm} is a machine that asymptotically approximate, in the mean-square sense, the optimal decision rule \eqref{eq:oneClassDec}.

\begin{lemma}
\label{lem:lem2}
Given $S$ training samples $\bm{a}^{(i)}$ from a finite alphabet $\mathcal C$, taken with a given static probability distribution, for large number of training samples, i.e., as $S \rightarrow \infty$, problem \eqref{eq:oneClassSvm} is equivalent to 
\begin{equation}
		\underset{\bm{w},e_i, \rho}{\text{min}} \Exp{e_i}^2
\end{equation}
\end{lemma}
\begin{proof}
We first proceed as in the proof of Theorem \ref{th:lsnp} and re-write problem \eqref{eq:oneClassSvm} as
	\begin{subequations}
		\label{eq:oclssvm22}
		\begin{equation}
		\label{eq:oclssvm2}
		\underset{\bm{w},e}{\text{min}} \quad f_0' = \frac{1}{2} \bm{w}^T \bm{w} + C S \frac{1}{2} \sum_{j=1}^M p_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,1) e_j^2 - \rho  
		\end{equation}
		\begin{equation}
		\label{eq:ocstpart2}
		\text{subject to}\,  \rho - \bm{w}^T \phi (\bm{a}^{(i)})  = e_i,  \quad i = 1,\dots M, 
		\end{equation}		
	\end{subequations} 
Note that differently from \eqref{eq:lssvm22} we have only $M$ constraints (and not $2M$) because we have target labels only of one class.
We now solve \eqref{eq:oclssvm22} using the same steps as in \cite{choi2009least}. Let us define the Lagrangian
\begin{equation}
	\mathcal{L} = 	\frac{1}{2} \bm{w}^T \bm{w} - \rho +
	C S \frac{1}{2} \sum_{j=1}^M p_{\bm{a}^{(i)},\hat{t}_i}(\bm{\alpha}_j,1) e_j^2 - 
	\sum_{j=1}^{M} u_j \left[ \bm{w}^T \phi (\bm{a}^{(j)}) -\rho + e_j \right],
\end{equation}
and set to zero the derivatives with respect to optimization variables and multipliers $u_j$

\begin{subequations}
\begin{equation}
\label{eq:derivatives1}
\frac{\partial \mathcal{L}}{\partial \bm{w}}: \quad \bm{w} = \sum_{j=1}^{M} u_j \phi (\bm{a}^{(j)}), 		
\end{equation}
  \begin{equation}
  \label{eq:derivatives2}
  		\frac{\partial \mathcal{L}}{\partial \bm{e_j}}: \quad CS p_{\bm{a}^{(i)},\hat{t}_i}(\bm{\alpha}_j,1) e_j = u_j \quad
  		 j=1,\dots, M,
  \end{equation}
  \begin{equation}
  \label{eq:derivatives3}
  		\frac{\partial \mathcal{L}}{\partial \rho}: \quad \sum_{j=1}^{M} u_j = 1
  \end{equation}
  \begin{equation}
  \label{eq:derivatives4}
  	\frac{\partial \mathcal{L}}{\partial \bm{u_j}}:	\quad \phi (\bm{a}^{(j)}) \bm{w} + e_j - \rho = 0.
  \end{equation}
\end{subequations}
Substituting \eqref{eq:derivatives1} and \eqref{eq:derivatives2} in \eqref{eq:derivatives4} we get the system of equations
\begin{equation}
\begin{aligned}
	&\sum_{i=1}^{M}  u_i k( \bm{a}^{(i)},\bm{a}^{(j)}) - \rho + \frac{u_j}{SCp_{\bm{a}^{(i)},\hat{t}_i}(\bm{\alpha}_j,1)}=0 \quad j = 1,\dots, M\\
	&\sum_{i=1}^{M}u_i=1,
\end{aligned}	
\end{equation}
with $M+1$ unknowns and $M+1$ equations which therefore provides finite convergence values for $\{\rho,u_i\}_{i=1}^{i=M}$. In the dual formulation of \eqref{eq:oneClassSvm} we can express $\bm{w}$ as a function of the kernel and Lagrange multipliers $\{u_j\}$ 
\begin{equation}
\bm{w}^T\bm{w} = \sum_{i=1}^{M} \sum_{j=1}^{M} u_i u_j k(\bm{\alpha}_i,\bm{\alpha}_j), 
\end{equation}
which, given the finiteness of the sum, converges.
We can now write
\begin{equation}
\begin{aligned}
\lim_{S \to +\infty} &\frac{1}{S} \bm{w}^T\bm{w} =0, \\
\lim_{S \to +\infty} &\frac{1}{S}\rho =0.
\end{aligned}		
\end{equation}
It follows that
\begin{equation}
	\underset{\bm{w},e_i, \rho}{\text{min}} \frac{1}{S} f_o(\bm{w},e_i, b) = 
	\underset{\bm{w},e_i, \rho}{\text{min}} \frac{1}{S} \sum_{i=1}^S e_i^2 = 
	\underset{\bm{w},e_i, \rho}{\text{min}} \Exp{e_i}^2,	
\end{equation}
where $e_i^2 = (\bm{w}^T \phi (\bm{a}^{(i)}) -\rho)^2 $, the last equality follows from the law of large numbers, and the expected value is carried out \wrt the training $\bm{a}^{(i)}$.
\end{proof}

%Note that $|e_i|$ is proportional, by a factor $1/||\bm{w}||$, to the distance between any point $\phi(\bm{a}^{(i)})$ and the hyperplane $\bm{w}^T \phi (\bm{a}) + b = 0$ defined in the transformed space by the \ac{oclssvm}. We claim that $|e_i|$ is inversely proportional to $p(\bm{a}|\mathcal{H}_0)$ and we will prove that this holds in the mean-square sense. A direct consequence is that the \ac{oclssvm} approximates asymptotically the optimal decision rule of Section \ref{sec:oneClassOpt}. 

\begin{theorem}
	\label{th:onelsnp}
	Consider a \ac{oclssvm} with perfect training, \ie the training reaches a global minimum of $f_o(\bm{w},e_i,b)$ given an infinite number of training points $\bm{a}^{(i)}$ drawn from the finite alphabet $\mathcal C$. Then the classifier obtained by training the \ac{oclssvm} and by thresholding the soft output \eqref{eq:svm} is equivalent, in the \ac{mse} sense, to the optimal classifier \eqref{eq:oneClassDec}.
\end{theorem}

\begin{proof}
Let $(\bm{w}^*,e_i^*, \rho^*)$ be the solution for problem \eqref{eq:oneClassSvm}. We note that $\rho^* >0$. If this was not the case, then we cold define the new triplet $(-\bm{w}^*,e_i^*, -\rho^*)$ providing a lower value for $f_o(\bm{w},e_i,\rho)$. This is because from \eqref{eq:oneClass1} the first two terms of the sum remain unchanged, while in the third term we are now subtracting a positive value, yielding
\begin{equation}
		f_o(-\bm{w}^*,e_i^*, -\rho^*) < f_o(\bm{w}^*,e_i^*, \rho^*).
\end{equation} 
Let us define the function 
\begin{equation}
	e(\bm{a},\bm{w},\rho) \triangleq \bm{w}^T  \phi (\bm{a}) - \rho,	
\end{equation}
and consider 
\begin{equation}
\label{eq:coreTheorem}
	\begin{aligned}
		&\underset{\bm{w},\rho}{\text{min}} \Exp{ \left( e(\bm{a},\bm{w},\rho) - \left(-\frac{1}{p(\bm{a}|\mathcal{H}_0)}\right)\right) ^2} = \\
		&\underset{\bm{w},\rho}{\text{min}} \int_{\mathbb{R}^n} \left[ e(\bm{a},\bm{w},b) + \frac{1}{p(\bm{a}|\mathcal{H}_0)} \right] ^2 p(\bm{a}|\mathcal{H}_0) d\bm{a} = \\
		&\underset{\bm{w},\rho}{\text{min}} \left\lbrace \int_{\mathbb{R}^n} e^2(\bm{a},\bm{w},\rho) p(\bm{a}|\mathcal{H}_0) d\bm{a}
		+2\int_{\mathbb{R}^n} e(\bm{a},\bm{w},\rho) d\bm{a}
		+ \int_{\mathbb{R}^n} \frac{1}{p(\bm{a}|\mathcal{H}_0)} d\bm{a} \right\rbrace.
	\end{aligned}	
\end{equation}
Consider the integral in the double product
\begin{equation}
		\int_{\mathbb{R}^n} e(\bm{a},\bm{w},b) d\bm{a} =
		\int_{\mathbb{R}^n} \bm{w} ^T  \phi (\bm{a})d\bm{a} - \int_{\mathbb{R}^n} \rho d\bm{a},		
\end{equation}
For what concerns the second integral in the r.h.s. we can write
\begin{equation}
		\int_{\mathbb{R}^n} \rho d\bm{a} = \rho \int_{\mathbb{R}^n} d\bm{a} = \sign(\rho) (+\infty) = + \infty,
\end{equation}
since we have shown that at the optimum $\rho^*>0$. Now, using \eqref{eq:derivatives1}, we can write the first integral as
\begin{equation}
\begin{aligned}
		&\int_{\mathbb{R}^n} e(\bm{a},\bm{w},\rho) d\bm{a} = \int_{\mathbb{R}^n} \sum_{j=1}^{M} u_j k(\bm{a}^{(j)},\bm{a})d\bm{a} \\
		&= \sum_{j=1}^{M} u_j \int_{\mathbb{R}^n} k(\bm{a}^{(j)},\bm{a})d\bm{a} = \int_{\mathbb{R}^n} k(\bm{a}^{(j)},\bm{a})d\bm{a},
\end{aligned},
\end{equation}
where we used \eqref{eq:derivatives3}.
Note that the only term in the last line of \eqref{eq:coreTheorem} that depends on the optimization variables $\{\bm{w}, \rho \}$  is 
\begin{equation}
		\Exp{  e^2(\bm{a}, \bm{w}, \rho)} = \int_{\mathbb{R}^n} e^2(\bm{a},\bm{w},\rho) p(\bm{a}|\mathcal{H}_0) d\bm{a},
\end{equation}
which, from Lemma \ref{lem:lem2} is, asymptotically, the objective function optimized by the \ac{lssvm}.
%The third term inside the curly brackets does not depend on $(\bm{w},b)$. Therefore, the mean square error approximation of $1/p(\bm{a}|\mathcal{H}_0)$ is found by minimizing $\Exp{e^2(\bm{a},\bm{w},b)}$ which, by Lemma \ref{lem:lem2}, is the same function minimized by \ac{oclssvm}. Asymptotically we have, from \eqref{eq:svm},
%\begin{equation}
%\label{eq:approx}
%	\tilde{t} \approx \frac{1}{p(\bm{a}|\mathcal{H}_0)},	
%\end{equation} 
%in the mean square sense. Note that thresholding $\frac{1}{p(\bm{a}|\mathcal{H}_0)}$ with $\gamma$ is the same as thresholding $p(\bm{a}|\mathcal{H}_0)$ with $1/\gamma$ which is the optimal classifier of Section \ref{sec:oneClassOpt}.
\end{proof}
\end{comment}

\subsection{\ac{ml}-Based Attack Strategies}
\label{sec:attack}
\hl{LA TOGLIAMO??}

\revi{sezattack}{Until now we have used ML approaches to perform \ac{irlv}. Here we propose to use ML also to obtain new more powerful attacks. In particular, we focus on an attacker that moves outside $\mathcal A_0$ and performs multiple attacks. We assume that the attacker knows if each attack is successful or not, and aims at minimizing the number of attacks before success. Moreover, we assume that before attack the attacker can estimate the attenuation vector to each \ac{ap}, by exploiting training signals transmitted by the \acp{ap}: while these estimate come almost for free to the attacker, an active attack is more expensive, both in terms of transmitted energy and as an intense attack sequence can be detected by the \acp{ap} that can take suitable countermeasures, which however are outside the scope of this work. Therefore we simply focus on the problem of doing as few attacks are possible, while being able to have as much attenuation vectors of the area outside $\mathcal A_0$. The proposed strategy works as follows:}
\begin{enumerate}
    \item The attacker visit  $N$  points spread uniformly at random outside $\mathcal A_0$. From each point it collects the attenuation vector and performs the attack. If any of the attacks is successful, the procedure is stopped.
    \item If none of the $N$ attacks has been successful, the attenuation vectors are used to train a one-class classifier.
    \item The attacker picks a new position uniformly at random outside $\mathcal A_0$ and feeds its attenuation vector to the trained classifier.
    \item If the vector is classified as belonging to the class it is discarded, and the procedure goes back to point 3), otherwise an attack from that position is performed.
    \item If the attack is successful, the procedure is stopped. Otherwise, the attenuation vector is used to as further training input of the one-class classifier and the procedure goes back to point 3).
\end{enumerate}
\revi{sezattack2}{Note that other attack strategies are possible, including game-theoretic approaches, where the attacker and the \ac{irlv} system are confronting players. These strategies are left for future study and we concentrate on the described attack procedure as it is similar, while from the attack perspective, to that used by the \ac{irlv}.}

\begin{comment}
\ac{ml} techniques can be also exploited in order to perform more effective attacks. In particular, the attacker can $a$) compute estimates of the attenuation vectors of its channel to all the \acp{ap}, and $b$) move around in the area $\mathcal A_1$ and perform attacks. Point $a$) is possible if \acp{ap} transmit training signals to the \ac{ue}, so that it can estimate the channel characteristics. We also assume that the attacker has means to determine if its attack has been successful, e.g., by receiving the services reserved to \acp{ue} in the \ac{roi}.

%Consider a training set set large enough to cover the statistical description of the non-legitimate area $\mathcal{A}_1$. The attenuation vector with the highest reconstruction error in the \ac{ae} case or with the largest value of $\tilde{t}_o$ in the \ac{oclssvm} case can be considered at the border of the region $\mathcal{A}_1$, and hence nearer to region $\mathcal{A}_0$. In the next section we describe two attack strategies exploiting this property of the \ac{ml} algorithms: the former attack is the filter attack, which exploits the one class trained \ac{ml} algorithms to select proper attack vectors; the latter is the gradient based attack, which exploits the loss function of \ac{ml} algorithms in order to forge attenuation vectors that can be considered as authentic by the \ac{irlv} system.

%\subsection{Selective \ac{ml} Attack}


%Although it is possible to perform multiple attacks, 
The purpose of the attacker is to be successful with the minimum number of attacks in order not to let the network detect to be under a series of attacks and take countermeasures (e.g., activating additional \ac{irlv} techniques or switching off the service). Moreover, a smaller number of attacks reduces the resource consumption by the attacker and provides faster access to the services. In order to make attacks more efficient, we propose that the attacker 1) moves in the \ac{roi}-complementary area $\mathcal A_1$, 2) measures the attenuation vectors at various position, and then 3) decides whether to attack or not according to its previous experience of failed attacks. We denote this attack as {\em selective \ac{ml} attack}. As soon as an attack is successful, the procedure is stopped; therefore, the data on which the attacker can use to take its decision comprises only failed attacks.

In details, the attacker uses the attenuation vectors of (failed) attacks to train a one-class classifier. Then, when reaching a new position it feeds the attenuation vector to the classifier and, if it is classified as belonging to the same class of training, no attacks is performed since the position is deemed to be useless. Otherwise, if the attenuation vector is not recognized as belonging to the class of collected points, it is evaluated as a potential successful attack and the attacker sends a message claiming to be in $\mathcal A_0$ to the network. If successful, the procedure is stopped, while upon failure the attenuation vector is fed as additional training data to the machine so that the classifier becomes more accurate.  
\end{comment}
%As before stated the one class classification involves training the \ac{ml} algorithms with attenuation vectors measured from one of the two available classes. We here propose an attack strategy which trains the \ac{ml} algorithms with attenuation vectors measured from the non-legitimate area $\mathcal{A}_1$. However, differently from a simple random attack, the attenuation vectors are \emph{filtered} by the attacker with a machine trained to learn the class of non successful points. The chosen attack point is then only the one yielding the worst metric as output of the filter. In this way we aim at minimizing the number of attempted attacks.

%In particular, consider an attenuation vector $\bm{a}_{\mathcal{A}_1}$ measured in area $\mathcal{A}_1$ This vector could be a possible successful attack and is hence tested. If the attack is not successful $\bm{a}_{\mathcal{A}_1}$ is used to train the \ac{ml} algorithm. 
%We generate $n_{\rm x}$ spatial coordinates located in area $\mathcal{A}_1$ and we measure the attenuation values incurred in each position. We then filter this set of vectors with the \ac{ml} algorithm and select as a possible attack the vector which is more likely to belong to class $\mathcal{A}_0$ (i.e., the one with highest reconstruction error for the \ac{ae} and with smallest $\tilde{t}_0$ for the \ac{oclssvm}). If the selected vector is not a successful attack then it is used to update the training of the \ac{ml} algorithm.

For the one-class classifier, we use either the \ac{ae} or the \ac{svm}, as described in the previous section. 
%
% This process is repeated until a successful attack vector is generated. The algorithm steps are shown in Algorithm \ref{alg:filter}.
%
%\begin{algorithm}[t]
%\label{alg:filter}
%  \algsetup{linenosize=\tiny}
%  \scriptsize
%
% \KwData{ $\bm{a}_{\mathcal{A}_1}$}
% \KwResult{successful attack vector }
% 
%
% \Repeat{attack is successful}{
%        \eIf{first attack}{
%        test $\bm{a}_{\mathcal{A}_1}$\;
%        \If{attack $\neq$ successful}{
%        build and train the \ac{ml} architecture with $\bm{a}_{\mathcal{A}_1}$\;
%        }
%        }
%        {
%        build set $\bm{A}$ of randomly selected attenuation vectors from $\mathcal{A}_1$\;
%        $\bm{a}_{\mathcal{A}_1} = \underset{\bm{a} \in \bm{A}}{\max} \quad \rm{loss} \, \rm{function}$ $(\bm{A})$\;
%        \If{attack $\neq$ successful}{
%       update training with $\bm{a}_{\mathcal{A}_1}$
%       }
%      }
%      }
%    
% \caption{Selective \ac{ml} attack}
%\end{algorithm}

%Note that Point $b$) is possible by letting the attacker to be equipped with multiple antennas so that, thanks to the estimates its channel to the \acp{ap}, the attacker can beamform the training signals with different gains to the \acp{ap}, thus letting them estimate the intended attenuation values. In this setting even a static \ac{ue} can generate many attacks with different estimated attenuation vectors at the \acp{ap}. 

% \subsection{Gradient-based \ac{ae} attack}
% Consider the set $\bm{A}$ of the attenuation vectors from $\mathcal{A}_1$ used for training the attacker \ac{ae}. The vector with highest reconstruction error is selected as a starting point for a possible successful attack. In order to find a direction toward which move the values of the attenuation vector to increment the probability of a successful attack, knowing that a higher reconstruction error means an higher probability of the vector belonging to the authentic area $\mathcal{A}_0$, we perform a gradient ascent algorithm based on the reconstruction error function (\ref{eq: rec err}) . 
% Starting from the attenuation vector with highest reconstruction error we perform various steps of the gradient algorithm and, for each step we exploit the forged vector as a possible attack. Considering the first attack as $\bm{a}_f^{(0)}=\underset{\bm{a} \in \bm{A}}{\max}$ the attack vector at iteration $q$ is
% \begin{equation}\label{eq: rnn attack}
%     \bm{a}_f^{(q)} = \bm{a}_f^{(q-1)}+ \delta \nabla_{\bm{a}}\epsilon(\bm{a}_f^{(q-1)}).
% \end{equation}
% The gradient ascent algorithm continues up to the point where the attack is successful or when the reconstruction error is lower then the one obtained in the previous step, i.e., $\epsilon(\bm{a}_f^{(q)}) < \bm{a}_f^{(q-1)}$. When the algorithm stops due to the second case the training of the \ac{ae} is updated with $\bm{a}_f^{(q-1)}$. The new training set is hence updated as $\bm{A} = \bm{A} \cup \bm{a}_f^{(q)}$ and the attenuation vector with highest reconstruction error obtained by the updated \ac{ae} is selected as the new starting point of the gradient algorithm. The algorithm steps are shown in Algorithm \ref{alg:rnnGrad}.

% \begin{algorithm}[t]
% \label{alg:rnnGrad}
%   \algsetup{linenosize=\tiny}
%   \scriptsize

%  \KwData{ trained \ac{ae}, training set $\bm{A}$, $\delta$}
%  \KwResult{successful attack vector }
 

%  \Repeat{attack is successful}{
%         select $\bm{a}_f^{(0)} = \underset{\bm{a} \in \bm{A}}{\max}\epsilon(\bm{a})$ \;
%         test $\bm{a}_f^{(0)}$ as attack \;
%         \If{$a_f^{(0)}$ is not successful}{
%         \Repeat{attack is successful or $\epsilon(\bm{a}_f^{(q)}) < \bm{a}_f^{(q-1)}$}
%         {
%         generate attack $\bm{a}_f^{(q)}$ via (\ref{eq: rnn attack})\;
%         perform the attack \;
    
%       }
%       \If{attack is not successful $\&$ $\epsilon(\bm{a}_f^{(q)}) < \bm{a}_f^{(q-1)}$}
%         	{$\bm{A}=\{\bm{A},\bm{a}_f^{(q)}\}$\;
%             update training of the \ac{ae} \;}
%             }
%       }
    
%  \caption{Gradient-based \ac{ae} attack}
% \end{algorithm}


% \subsection{\Acl{oclssvm} Attack}
% The attacker trains a \ac{oclssvm} with the training data coming only from the non-authentic area and his objective is now to forge an attack value $\bm{a_{f}}$ that will be accepted as authentic by the \ac{irlv} system. We propose an euristic approach  exploiting the fact that the test function for the attacker's trained \ac{oclssvm} would be
% \begin{equation}
% \bm{a} \in
% 	\begin{cases}
% 		\mathcal{A}_1 \quad \text{if} \quad \tilde{t} \geq \Lambda \\
% 		\mathcal{A}_0 \quad \text{if} \quad \tilde{t} < \Lambda.
% 	\end{cases}	
% \end{equation} 
% Moreover, from Theorem \ref{th:onelsnp} we know that the more $\tilde{t}$ decreases, the more $p(\bm{a}|\mathcal{H}_0)$ decreases as well.
% This suggests that the attacker could start from the training point $\bm{a}_{f}^{(0)}$ yielding the lowest value of $\tilde{t}$ and then moving along the direction of greatest decrease $\bm{d}$, given by
% \begin{equation}
% \label{eq:dDef}
% 	\bm{d} \triangleq - \nabla_{\bm{a}} \tilde{t},
% \end{equation} 
% where $\nabla_{\bm{a}}$ is the gradient operator \wrt $\bm{a}$. Exploiting the dual formulation \cite{choi2009least} we can write
% \begin{equation}
% \label{eq:gradient}
% 		\nabla_{\bm{a}} \tilde{t} = \sum_{j=1}^{S} u_j \nabla_{\bm{a}} k(\bm{a}_j,\bm{a}).
% \end{equation}
% Using the radial-basis kernel
% \begin{equation}
% k(\bm{a}_j,\bm{a}_i) = e^{-\frac{||\bm{a}_j-\bm{a}_i||^2}{2\sigma^2}},
% \end{equation}
% the explicit expression for the gradient in \eqref{eq:gradient} is
% \begin{equation}
% 	\nabla_{\bm{a}} \tilde{t} =\frac{1}{\sigma^2} \sum_{j=1}^{S} u_j k(\bm{a}_j,\bm{a}) (\bm{a}_j - \bm{a}).
% \end{equation}
% Next, the attacker forges the point
% \begin{equation}
% 	\bm{a}_f^{(1)} = \bm{a}_f^{(0)} + \delta \bm{d}, 	
% \end{equation}
% where $\delta$ is a parameter, and performs the attack. If it does not succeed, he re-trains the \ac{oclssvm} with this new information and repeats the attack until he eventually succeeds. This constitutes Algorithm \ref{alg:svm}.

% \begin{algorithm}[t]
% \label{alg:svm}
%   \algsetup{linenosize=\tiny}
%   \scriptsize

%  \KwData{ Training set, $\delta$}
%  \KwResult{succesful attack vector }
 

%  \Repeat{attack is succesful}{
%  		train a \ac{oclssvm} \;
%         select $\bm{a}_{f}^{(0)}$ yielding the lowest value of $\tilde{t}$ \;
%         compute $\bm{d}$ from \eqref{eq:dDef} \;
%         compute $\bm{a}_f^{(1)} = \bm{a}_f^{(0)} + \delta \bm{d}$ \;
%         perform the attack \;
%         \If{
%         	attack is not succesful}
%         	{$\bm{a}_f^{(1)}$ belongs to non-authentic area\;
%         	add $\bm{a}_f^{(1)}$ to training set\;}
%       }
    
%  \caption{One-class \ac{svm} Attack}
% \end{algorithm}


\section{Numerical Results}\label{sec:numRes}

\uline{In this section, we present the performance of the proposed \ac{irlv} obtained from both experimental data and the channel models of Section II. We consider a unitary transmitting power for each user and a carrier frequency of $f_0=2.12$~GHz, apart for the experimental results, using the \ac{gsm} frequency $f_0 =900$~MHz. When spatial correlation of shadowing is considered, according to the model of Section II, we consider a correlation distance of $d_c = 75$~m.} 

 \uline{The training points are taken uniformly over the area $\mathcal A$ ($\mathcal A_0$) for two-class (one-class) classification.}
 
\revi{activation}{For the \ac{nn} used in two-class classification, the activation function of the input layer is the identity function, while the activation function of  hidden and output layers is the sigmoid function}
\begin{equation}\label{eq:sigmoid}
\psi^{(\ell)}(x) = \frac{1}{1-e^{-x}}, \quad \ell = 1, \ldots, Q.
\end{equation}
\revi{numResSimplScen3}{All results for \ac{nn} have been reported only for \ac{ce} loss function, as we have shown in Corollary 1 and Theorem 2 that with both training functions we achieve performance of the \ac{np} test.} Moreover, we always used fully-connected \acp{nn}.
   

\subsection{Two-class \ac{irlv} With Single \ac{ap}}\label{sec:singleAp}

We start with a \ac{irlv} system using a single \ac{ap}. Two channel models are considered: a model with spatially uncorrelated fading or shadowing (see Section \ref{sec:los}), and a model with spatially-correlated shadowing.

\paragraph*{Uncorrelated fading/shadowing} \revi{numResSimplScen}{First, the environment of Fig. \ref{fig:simpScen} is considered, with  $R_{\rm out}= 10$~m, $R_{\rm in} = 2$~m and $R_{\rm min} = 0.1$~m, describing a small area, and channel model with spatially-uncorrelated fading or  shadowing. Moreover, a \ac{los} model is assumed for path-loss. With uncorrelated fading we consider two path-loss coefficients, namely  $\nu=2$ and $3$; the close-form expression of the \acp{llr} for the \ac{np} test are given by (\ref{eq:llr1}) and (\ref{eq:llr2}). With spatially-uncorrelated shadowing  we set $\nu=2$, and three values of shadowing variance, namely  \colorbox{red}{SENZA QUADRATO (VEDI FIGURA):GIUSTO?} $\sigma_{s, {\rm dB}} = 0.1$, $1.8$, and 6~dB; the close-form expression of the \acp{llr} for the \ac{np} test is given by (\ref{eq:llr3}). For the \ac{ml} approaches, we consider $S=10^5$ training points, and a \ac{nn} with $N_L = 2$ hidden layers, each with $N_h=5$ neurons, designed with the \ac{ce} loss function.}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\columnwidth]{comp_NN_NP_CE.eps}
    \caption{\ac{roc} of \acp{irlv} methods for \ac{los}, uncorrelated fading/shadowing and various values of $\nu$ and $\sigma_{s, {\rm dB}}$. Environment of Fig. \ref{fig:simpScen}.}
    \label{fig:ceVSnp}
\end{figure}


\revi{numResSimplScen2}{Fig. \ref{fig:ceVSnp} shows the \ac{fa} probability versus the \ac{md} probability (i.e., the  \ac{roc}, obtained with the \ac{np} test,  the \ac{nn} and \ac{lssvm} classifiers. We notice that all solutions achieve the same performance, confirming our theoretical results that both \ac{nn} and \ac{lssvm} with long training and enough complexity are optimal as  \ac{np}.} \revi{numResSimplScen4}{We observe that fading has more impact on the performance than shadowing, yielding higher \ac{fa} and \ac{md} probabilities. Still, with fading a higher  path-loss coefficient provides better results as the attenuation increases more with the distance, thus easing classification. For spatially-uncorrelated shadowing performance improves as $\sigma_{s, {\rm dB}}$ decreases, as the lower the variance of the additive shadowing component the most the received signal is equal to the oath loss only and hence uncertainty is reduced.}

\paragraph*{Spatially-correlated shadowing} 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\columnwidth]{scenariotex.png}
    \caption{Reference environment. \colorbox{red}{METTERE $A_0$ COME QUADRATO (NON ARROTONDATO). togliere il tratteggio e aggiungere coordinate $d_1$ e $d_2$, mettere le quote sul lato di $\mathcal A$ e $\mathcal A_0$}} 
    \label{fig:mBS}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{map.eps}
    \caption{Example of attenuation map including path-loss and shadowing, with the \ac{ap} positioned at the center.}
    \label{fig:map}
\end{figure}

\uline{We now consider the spatially-correlated shadowing  ($\sigma_{s, {\rm dB}} = 8$), of Section II, and the environment of Fig. \ref{fig:mBS} with only one  \ac{ap}  located at the street intersection, and a square \ac{roi} with $d_1= 50$ m, $d_2= 50$ m and $\beta_1 = \beta_2 = 150$ m.} \revi{building}{The \ac{roi} is inside the  south-west building, modelling for example a scenario wherein privileged network resources are accessible only to users inside an office.} Along the streets, \ac{los} propagation conditions hold (with $\nu = 2$), while no-\ac{los} propagation conditions hold in the rest of the area. Fig. \ref{fig:map} shows a realization of the  attenuation map (including both path-loss and shadowing), highlighting the different propagation conditions. \uline{Since no close-form expression of the \ac{llr} is available in this scenario, we quantize the attenuations collected in the learning phase  with a large alphabet and estimate the sampled \ac{pdf} for the quantized attenuations. Lastly, we use the estimated \ac{pdf} to compute the \acp{llr}. We use $4.46 \cdot 10^6$ training points in the area $\mathcal A$, and a uniform quantizer for the attenuation (within the observed extreme values) with $300$ quantization values. Only $10^3$ points are instead used for training of both \ac{mlp} and \ac{svm}.} 
 

%Consider the \ac{llr} (\ref{eq:lr}). In the no-\ac{los} context the computation of the two area dependent probabilities has no closed-form solution. A numerical solution is obtained by sampling the attenuation values over the spatial grid of positions and computing the area dependent distributions of the attenuation values. Consider an attenuation value $\hat{a}$: the probability of measuring $\hat{a}$ given that the \ac{ue} is located in area $\mathcal{A}_0$ is given by the number of positions $(x_u,y_u) \in \mathcal{A}_0$ where the measured attenuation $a(x_u,y_u)=\hat{a}$ over the total number of positions $(x_u,y_u)$ in the entire map having the same attenuation $\hat{a}$, i.e.
%\begin{equation}
%    \mathbb{P}(\hat{a}|\mathcal{A}_0) \approx \frac{\text{number of positions} \, (x_u,y_u) \in \mathcal{A}_0 \, \text{s.t.} \, a(x_u,y_u) = \hat{a}}{\text{total number of positions} \, (x_u,y_u) \, \text{s.t.} \, a(x_u,y_u) = \hat{a}}
%\end{equation}
%With the same reasoning we compute $\mathbb{P}(\hat{a}|\mathcal{A}_1)$, and an approximation of equation (\ref{eq:lr} is hence obtained as
%\begin{equation}\label{eq:lrApp}
%    \mathcal{L} \approx \frac{\text{number of positions} \, (x_u,y_u) \in \mathcal{A}_0 \, \text{s.t.} \, a(x_u,y_u) = \hat{a}}{\text{number of positions} \, (x_u,y_u) \in \mathcal{A}_1 \, \text{s.t.} \, a(x_u,y_u) = \hat{a}}
%\end{equation}
%The value computed by (\ref{eq:lrApp}) gets closer to the real value as the number of grid points over the map increases, as an higher number of points means a better statistical characterization of the attenuation over the map area.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{res_NP_approx_SVM.eps}
    \caption{\ac{roc} of \ac{irlv} methods, with a \ac{nn} having $N_L=1$ and two values of $N_h$. Environment of Fig. \ref{fig:mBS}, with one \ac{ap} located at the street intersection, $d_1 = 50$ m, $d_2 = 50$ m, $\beta_1 = \beta_2 = 150$ and correlated shadowing ($\sigma_{s, {\rm dB}} = 8$.}
    \label{fig:trueMap}
\end{figure}

Fig. \ref{fig:trueMap} shows the \ac{roc}  of \ac{np}, \ac{nn}, and \ac{ls}-\ac{svm}, where for a given \ac{fa} probability we report the  \ac{md} probability averaged over the shadowing attenuation maps. We notice that both \ac{nn} and \ac{ls}-\ac{svm} outperform the \ac{np} test. This means that even for very large numbers of samples available to estimate the \ac{pdf}, we still we have a performance degradation with respect to perfect knowledge of the statistics which would outperform all other methods. On the other hand, with a small number of training points the \ac{ml} methods outperform \ac{np}, without knowing the channel model. Therefore, in the following sections we drop the \ac{np} method.
 


%Comparing the number of grid points and the number of training points used for the \ac{ml} algorithms we can conclude that the \ac{ml}-based solution is advantageous over the \ac{np}-based one, as it requires a smaller number of points in order to get an estimate of the area dependent probabilities. Furthermore this implies that the \ac{ml}-based \ac{irlv} system can be implemented without any a-priory knowledge of the \ac{pdf} of the hypothesis to be tested.


\subsection{Two-class \ac{irlv} With Multiple \acp{ap}}
\label{sec:res_fading}

\uline{We consider the environment of Fig. \ref{fig:mBS}, with $N_{\rm AP}=10$ \acp{ap} used for \ac{irlv}. The channel model includes \ac{los} and no-\ac{los} path-loss, spatially-correlated shadowing ($\sigma_{\rm s, Db} = 8$), and fading, as described in Section II. A deep \ac{nn} with $L=3$ hidden layers, each having $N_h = 100$ neurons.}  

\paragraph{No fading average} We first feed the test function with attenuations without fading average, i.e., $k_f=1$.  \ac{roi} position is $d_1 = 50$ m, $d_2 = 50$ m and $\beta_1 = \beta_2 = 150$ m. \uline{Fig. \ref{fig:kf1} shows the \ac{roc} for \ac{nn}  and \ac{ls}-\ac{svm} \ac{irlv} methods and different values of the training-set size $S$. We observe that for a given \ac{fa} probability, the \ac{md} probability decreases as the training-set size $S$ increases. Both \ac{ml} methods have similar  performance  with large  training sets, confirming our result that both are asymptotically optimal. However,  \ac{svm} converges faster than \ac{nn} (i.e., with a smaller $S$) to the optimal \ac{roc}. Therefore, for a practical implementation with finite training and limited computational capabilities, a careful design is needed. Note that with multiple \acp{ap}, we obtain a more accurate classification than using a single \ac{ap}. Still, for security purposes, we would prefer even lower  \ac{fa} and \ac{md} probabilities; this can be achieved, for example, by increasing the number of \acp{ap} or considering other channel features, e.g., its wideband impulse response. }

\colorbox{red}{METTERE I NUMERI E LA DESCRIZIONE}\revi{revnewarea}{We have also considered a different position of the \ac{roi}, with $d_1 = 100$ m, $d_2 = 225$ m and $\beta_1 = \beta_2 = 150$ m, i.e., the \ac{roi}  is still positioned south-west, but it also includes the street crossing and \ac{ap} \hl{number}. Path-loss and shadowing parameters are the same of Fig. \ref{fig:kf1}. Fig. \ref{fig:kf1_newArea} shows the resulting \ac{roc}, still obtained by averaging the \ac{md} probability over the shadowing map. The presence of the street, inside the \ac{roi}, with its  \ac{los} path-loss, turns out to facilitate \ac{irlv}, resulting in lower \ac{fa} and \ac{md} probabilities.}


\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{res_training_10BS_2Class.eps}
    \caption{\ac{roc} of \ac{irlv} methods for different values of training-set size $S$. Environment of Fig. \ref{fig:mBS}, with  $N_{\rm AP}=10$, $d_1 = 50$ m, $d_2 = 50$ and $\beta_1 = \beta_2 = 150$ m , $\sigma_{s,{\rm dB}} = 8$.}
    \label{fig:kf1}
\end{figure}


\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{res_training_10BS_2Class_newArea.eps}
    \caption{\ac{roc} of \ac{irlv} methods for different values of training-set size $S$. Environment of Fig. \ref{fig:mBS}, with  $N_{\rm AP}=10$, $d_1 = 100$ m , $d_2 = 225$ m and $\beta_1 = \beta_2 = 150$, $\sigma_{s,{\rm dB}} = 8$.}
    \label{fig:kf1_newArea}
\end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.6\columnwidth]{res_training_5BS_2Class.eps}
%     \caption{\ac{roc} of \ac{svm} and \ac{nn} for $N_{\rm AP}=5$ and for different numbers of training set size $S$.}
%     \label{fig:kf1}
% \end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{res_fading_5BS_2Class.eps}
    \caption{\ac{roc} of \ac{irlv} methods for different averages of fading. Environment of Fig. \ref{fig:mBS}, with  $N_{\rm AP}=5$, $d_1 = 50 $ m, $d_2 = 50$ m and $\beta_1 = \beta_2 = 150$ m, $\sigma_{s,{\rm dB}} = 8$.}
    \label{fig:kf10-5}
\end{figure}


\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{res_fading_10BS_2Class.eps}
    \caption{\ac{roc} of \ac{irlv} methods for different averages of fading. Environment of Fig. \ref{fig:mBS}, with  $N_{\rm AP}=10$, $d_1 = 50$ m and $d_2 = 50$, $\sigma_{s,{\rm dB}} = 8$.}
    \label{fig:kf10}
\end{figure}


\paragraph{Effect of fading average}  \uline{As discussed in Section \ref{sec:chMod}, for a given \ac{ue} position, the attenuation changes over time due to fading. By averaging  $k_f$ realizations of the the attenuations in the same position, the effect of fading on \ac{irlv} is mitigated. }  

We consider the environment of Fig. \ref{fig:mBS} with $N_{AP} =5$ \acp{ap}, four at the ends of the streets, and one  at the street intersection. Channel parameters are those of Fig. \ref{fig:kf1}. For $n_x$  explored locations by the \ac{ue}, and $k_f$  fading realizations per location, we obtain $S= n_x \cdot k_f$ training attenuation vectors. Fig. \ref{fig:kf10-5}  shows the \ac{roc} for $k_f=1$ and 10, \uline{with $S = 2 \times 10^4$ for \ac{svm} and $S = 3.2 \times 10^5$ for \ac{nn}. } \revi{revLI2a}{We also report the performance for a channel without fading ({\it no fading} in the legend). Lastly, we show the performance of  \ac{eda}, described in Section \ref{seccomp}, still obtained without fading and assuming to know the relation between the attenuation and the distance.}\revi{rev2fad}{We note that both \ac{md} and \ac{fa} can be significantly reduced by averaging the fading, approaching the no-fading performance. Indeed, an average on 10 fading realizations already reduces the average \ac{md} probability from $10^{-1}$ to $10^{-2}$ for an \ac{md} probability of $2\cdot 10^{-1}$, while without fading we achieve an average \ac{md} probability of $4\cdot 10^{-4}$ (using a \ac{nn}). We also notice that in the absence of fading \ac{svm} significantly outperforms  \ac{nn} even if the \ac{nn} uses a larger $S$, suggesting that in this scenario, wherein potentially very good performance can be achieved, the \ac{nn} has not yet converged to the optimum, for limits in both architecture and computational capabilities. We should remember in fact that the complexity of the function implemented with the \ac{svm} grows with the training, while complexity of the  \ac{nn} (i.e., the number of its tunable parameters) is fixed.}\revi{revLI2b}{Lastly, we observe that the proposed \ac{ml} techniques (both with and without fading) outperform  \ac{eda}  (whose performance has been obtained on channels without fading). This is due to the fact that \ac{ml} solutions are very robust and do not rely on specific channel models; moreover they do not convert attenuation measures into intermediate quantities obtained by specific models (as instead \ac{eda} does, by converting them first into distances), but directly take a decision directly on the attenuation estimates.} 

\uline{Fig. \ref{fig:kf10} shows the \ac{irlv} performance in the same setting of Fig. \ref{fig:kf10-5}, but now with $N_{\rm AP} = 10$ \acp{ap}, positioned as in Fig. \ref{fig:mBS}. Comparing Fig.s \ref{fig:kf10-5} and  \ref{fig:kf10} we note that using more \acp{ap} significantly lowers both FA and MD probabilities when fading is present. The advantage in the absence of fading of fading is instead very limited.}   


\begin{table}
\centering
\caption{Location of the \acp{ap} in the Berlin scenario}
\label{tab:berlin}
\begin{tabular}{c c c}
\toprule
\ac{ap} index $n$ & $X_{\rm AP}^{(n)}$ [m] & $Y_{\rm AP}^{(n)}$ [m] \\
\midrule
1 & 2500 & 2500 \\
2 & 500 & 4000 \\
3 & 4000 & 4000 \\
4 & 500 & 500 \\
5 & 4000 & 500 \\
6 & 100 & 4500 \\
7 & 1000 & 400 \\
8 & 4000 & 500 \\
9 & 4300 & 4000 \\
10 & 4500 & 500 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{berlinNew.eps}
    \caption{\ac{roc} of \ac{irlv} methods for the experimental data.}
    \label{fig:Berlinnew}
\end{figure}

\paragraph{Results on experimental data} \revi{Berlin}{We have also tested the proposed \ac{irlv} solutions on experimental data obtained by the MOMENTUM project {\cite{MOMENTUM-D53}} in a measurement campaign at Alexanderplatz in Berlin (Germany). Attenuations at the \ac{gsm} frequency have been measured for several \acp{ap} in an area of $4500~{\rm m} \times 4500~{\rm m}$ with a measurement grid of $50 \times 50$ m. We have considered 10 attenuation maps, corresponding to 10 \acp{ap} located approximately at the locations specified in Table \ref{tab:berlin}, while the \ac{roi}  has been positioned in the lower-right corner corresponding with, following the same notation of Fig \ref{fig:mBS}, $d_1 = 3000$, $ d_2 = 1500$ m and $\beta_1 = \beta_2 = 1000 $ m.  In this case we have a single realization of any channel effect (path-loss, shadowing, fading, ...) per location, for a total of 8464 realizations, of which 5000 have been used for training and the rest for testing. For \ac{nn} we set  $L=3$ and $N_h =500$. Fig. \ref{fig:Berlinnew} shows \ac{roc} for both \ac{nn} and \ac{lssvm}. The  performance is in line with the other figures obtained by simulation. Still, due to the small size of the available training set, \acp{roc} are not smooth. Moreover, we notice that \ac{svm} and \ac{nn} achieve approximately the same performance.}\revi{revLI}{Note also that in order to use \ac{eda}  we should first know the path-loss model to be used to convert the attenuation estimates into distances, an information not immediately available from the experiments: this is a further demonstration of the utility of model-less techniques for \ac{irlv}.}

%By comparing the two figures, we note that for small values of $S$, the performance get slightly worse as $k_f$ grows. For a large enough training set size $S$, different values $k_f$ provide approximately the same performance.  Therefore, we can conclude that, for large training sets, \ac{ml} algorithms are also robust to fading irrespective of the number of collected fading realization per location. However, in practical situations where the points for training may be limited, it may be advantageous to collect more fading realization per location. 


\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{res_Training_10BS_oneClass.eps}
    \caption{\ac{roc} for one-class \acp{irlv} in a scenario with $N_{\rm AP}=10$, path-loss, shadowing and fading with different training set size and $k_f=1$ fading realizations,  \ac{ae} with $N_h = 2$. }
    \label{fig:kf1Oc}
\end{figure}



\subsection{One-Class \ac{irlv} With Multiple \acp{ap}}\label{sec:numResOneClass}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.6\columnwidth]{noFading_10BS.eps}
%     \caption{\ac{roc} for one-class \acp{irlv} in a scenario with path-loss, shadowing and without fading.}
%     \label{fig:aeNh}
% \end{figure}

We now focus on the one-class \ac{irlv} solutions described in Section \ref{sec:OneClass}, where the training points come only from the \ac{roi} $\mathcal A_0$. \revi{designAE}{The \ac{ae} has been designed according to  \cite{Hinton-2006}, i.e., all neurons use the logistic sigmoid as activation function (\ref{eq:sigmoid}), except in the central hidden layer, where linear activation functions are used. The \ac{ae} has $N_L = 7$ hidden layers with 7, 6, 3, 2, 3, 6, and 7 neurons, respectively. Weights are initialized randomly.} \uline{The channel model is that described in Section II, and the environment is that of Fig. \ref{fig:mBS} (with $N_{\rm AP} =10$), with the parameters set in  Section \ref{sec:res_fading} and $d_1=50$ m , $d_2=50$ m, $\beta_1 = \beta_2 = 150$ m.} 

% Fig. \ref{fig:aeNh} shows the \ac{roc} for both \ac{oclssvm} and \ac{ae} with $N_h \in [1, 5]$ and $S=10^4$ training vectors. We see that, by increasing $N_h$, the performance of \ac{ae}-based \ac{irlv} does not improve: indeed, the optimum \ac{roc} is obtained for $N_h=2$. This is due to how \ac{ae} compresses the attenuation vectors: the best performance are achieved when it extracts the optimal number of features from the input. As we have seen, the one-class solutions are not optimal in general, and we clearly see that \ac{oclssvm} is significantly more powerful than \ac{ae}, as the obtained \ac{roc} achieves a lower $P_{\rm MD}$ for the same $P_{\rm FA}$.
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.6\columnwidth]{res_Training_5BS_oneClass.eps}
%     \caption{\ac{roc} for one-class \acp{irlv} in a scenario with $N_{\rm AP}=5$, path-loss, shadowing and fading with different training set size and $k_f=1$ fading realizations,  \ac{ae} with $N_h = 2$. }
%     \label{fig:kf1Oc5bs}
% \end{figure} 
 
\uline{We here consider the effects of fading and the choice of the number of training points $S$. Fig. \ref{fig:kf1Oc} shows the \ac{roc} for one-class \acp{irlv} systems for $k_f = 1$ and two values of $S$. We first notice that both \ac{ae} and \ac{oclssvm} are at convergence for $S = 5 \cdot 10^{3}$, and, as already seen in the case of two-classes classification, the \ac{svm}-based solution outperforms the \ac{nn}-based solution. Fig.  \ref{fig:kf10Oc} shows the \ac{roc} for $k_f=1$ and 10, while $n_x=2 \times 10^4$. We note that for both \ac{ml} techniques, averaging over fading significantly improve the performance.} \revi{revLI3}{We also report the performance of \ac{eda}, obtained without fading and assuming the knowledge of the relation between path-loss and distance. Again we note that the proposed \ac{ml} techniques significantly outperform \ac{eda} (in the absence of fading for all techniques).} 
 
When comparing Fig.s \ref{fig:kf10} and \ref{fig:kf10Oc}, we can observe that, in the considered scenario, the two-class \acp{irlv} outperforms the one-class \ac{irlv}: the former achieves a lower $P_{\rm MD}$ for the same $P_{\rm FA}$. This result is expected since the two-class \ac{irlv} also exploits the (estimated) statistics of attacks.  
 
 
 
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.6\columnwidth]{res_Fading_5BS_oneClass.eps}
%     \caption{\ac{roc} for one-class \acp{irlv} in a scenario with $N_{\rm AP}=5$, path-loss, shadowing and fading with different training set size and $k_f=10$ fading realizations,  \ac{ae} with $N_h = 2$. }
%     \label{fig:kf10Oc5bs}
% \end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{res_Fading_10BS_oneClass.eps}
    \caption{\ac{roc} of one-class \acp{irlv} for different values of $k_f$. Environment of Fig. \ref{fig:mBS} with $N_{\rm AP}=10$, and $n_x= 2 \cdot 10^4$. }
    \label{fig:kf10Oc}
\end{figure}




\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{res_selective_SVM.eps}
    \caption{\ac{cdf} of the time of first successful attack $\eta$ for various attack strategies. Both the selective \ac{ml} attack  and \ac{irlv} are based on \ac{oclssvm} and $P_{\text{FA}}= 10^{-2}$.}
    \label{fig:selectiveSVM}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{res_selective_AE.eps}
    \caption{\ac{cdf} of the time of first successful attack $\eta$ for various attack strategies. Both the selective \ac{ml} attacks  and \ac{irlv} are based on \ac{ae} and $P_{\text{FA}}= 0.5$. \colorbox{red}{E' NUOVA? L'AE E' STATO MODIFICATO?}}
    \label{fig:selectiveAE}
\end{figure}



\subsection{\ac{ml} Attack Strategies}

\uline{We consider now the \ac{ml} attack strategies described in Section \ref{sec:attack} for the scenario of Fig. \ref{fig:mBS}, with $N_{\rm AP} =5$ \acp{ap}, and channels including path-loss, shadowing, and fading as described in Section II \hl{check:} the parameters set in  Section \ref{sec:res_fading} and $d_1=0$ m, $d_2=0$ m, $\beta_1 = \beta_2 = 255$ m.  \ac{irlv} is  performed with one-class classifiers.  \ac{roi} $\mathcal A_0$ coincides with the whole south-west building of Fig. \ref{fig:trueMap}. } 

%In order to test the attacks we set the \ac{fa} probability at the defense side, such that the threshold value needed for classification is given. We compare attacks and defense both implemented via \ac{ae} and \ac{oclssvm}. 

We compare the proposed \ac{ml} attack strategies with the uniformly random attacks, wherein attacks are launched by uniform randomly selected positions in the \ac{roi}-complementary area $\mathcal{A}_1$.  Moreover, as a na\"ive enhancement, we consider a \emph{random-border} attack, wherein the attacker moves only along a strip of 2.5 meters at the border between areas $\mathcal{A}_0$ and $\mathcal A_1$. In this way, we expect that the chances of a successful attack increase by being closer to the \ac{roi}. Since the \ac{roi} coincides with the building, on the border between $\mathcal A_0$ and $\mathcal A_1$, the \ac{ue} is on the streets and has a \ac{los} propagation characteristic, whereas region $\mathcal A_0$ has a no-\ac{los} propagation characteristic. 

The same one-class \ac{ml} algorithm is implemented both for attack and \ac{irlv}, although the attacker training set includes only points in $\mathcal A_1$, while the \ac{ap} network training set includes only  points in $\mathcal A_0$. For  \ac{irlv}  we set $k_f=10$.

Fig.s \ref{fig:selectiveSVM} and \ref{fig:selectiveAE} show the \ac{cdf} of the number of the first successful attack $\eta$ for the random, random-border and selective ML attack strategies. Fig. \ref{fig:selectiveSVM} presents results for \ac{irlv} with $P_{\rm FA}=10^{-2}$ and \ac{ml} approaches based on \ac{oclssvm}. In this case, the selective-ML attack is faster than pure random attack, which in turn perform similarly to the border-random  attack.  Fig. \ref{fig:selectiveAE}, instead, shows results for  \ac{irlv} $P_{\rm FA} =0.5$ and \ac{ml} approaches based on \acp{ae}. We observe that the random-border attack outperforms a purely random attack, while still being less-powerful than selective \ac{ml}. 

%We can conclude that the \ac{ml} selective attack is clearly reducing the time to reach a success with respect to random attacks. Moreover, \ac{ae} is more robust to attacks than \ac{oclssvm} when used for \ac{irlv}, as for \ac{ae} the first successful attack as a similar statistics to random attacks while for \ac{oclssvm} the \ac{ml} selective strategy is  successful much earlier than the random strategies. 



\section{Conclusions}

In this paper, we have proposed innovative solutions for the \ac{irlv} in wireless networks that exploit the features of the channels between the \ac{ue} whose location must be verified by a trusted network of \acp{ap}. By observing that in typical situations the channel statistics are not available for \ac{irlv}, we have proposed \ac{ml}-based solutions, operating with both one- and two-class classification, i.e., with and without a-priori assumptions on attack statistics. For two-class classification we have proved that  both \ac{nn} and \ac{svm} solutions  are the most powerful tests for a given sensitivity, i.e., they are equivalent to the \ac{np} test. Instead, for one-class classification both \ac{ae} and \ac{svm} solutions are not equivalent to the \ac{glrt}. From numerical results we conclude that \ac{ml} converges to optimal performance with much smaller training set sizes than \ac{np} test implemented with estimated channel statistics. We have also investigated how to collect the training points for training in order to be robust against the channel fading.

\section*{Appendix}

	Given a finite  attenuation vector alphabet $\mathcal C = \{\bm{\alpha}_1, \ldots, \bm{\alpha}_M\}$ of $M$ elements, with $\bm{a}^{(i)} \in \mathcal C$, we indicate with $p_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j, t)$, with $t \in \{-1,1\}$, the joint probability of input vector $\bm{a}^{(i)}$ and corresponding output $t_i$, $i=1, \ldots, S$.
	
	By the GlivenkoCantelli theorem we have that with probability 1 as $S\rightarrow \infty$ there are $Sp_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,t)$ training vectors $\bm{\alpha}_j$ with associated true value $t$ in any training sequence.
	All these training points will have the same value $e_i$, from (\ref{eq:stpart}), that will appear $Sp_{\bm{a}^{(i)},y_i}(\bm{\alpha}_j,t)$ times in the sum $\sum_{i=1}^{S} e_i^2$.
	Note that in the training ensemble there could be two equal instances $\bm{a}^{(m)}=\bm{a}^{(n)}=\bm{\alpha}_j$, but with different labels $t_m \neq t_n$. Therefore, for $\bm{a}^{i}=\bm{\alpha}_j$ we can have two possible values for $e_i$, depending on $y_i$, and we denote them with $e_{j,1}$ and $e_{j,-1}$.
	This translates in only $2M$ \textit{distinct} constraints of the type \eqref{eq:stpart}.
	Asymptotically, for $S \to \infty$, problem (\ref{eq:lssvm}) becomes
	\begin{subequations}
		\label{eq:lssvm22}
		\begin{equation}
		\label{eq:lssvm2}
		\underset{\bm{w},e}{\text{min}} \quad f_l' \triangleq \frac{1}{2} \bm{w}^T \bm{w} + C S \frac{1}{2} \sum_{j=1}^M [p_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,1) e_{j,1}^2 + p_{\bm{a}^{(i)},y_i}(\bm{\alpha}_j,-1) e_{j,-1}^2]  
		\end{equation}
		subject to 
		\begin{equation}
		\label{eq:stpart2}
		[\bm{w}^T \phi (\bm{\alpha}_j) + b] = 1- e_{j,1}\quad j = 1 ,\dots,M.
		\end{equation}
		\begin{equation}
		\label{eq:stpart3}
		\quad  -[\bm{w}^T \phi (\bm{\alpha}_j) + b] = 1- e_{j,-1}\quad j = 1 ,\dots,M.
		\end{equation}
	\end{subequations}
	whose solution provides the convergence value (in probability) of vector $\bm{w}$. We write the Lagrangian
	\begin{equation}
	\mathcal{L}_1 = f_l' - \sum_{k=1}^{M} v_k \left[ \bm{w}^T \phi (\bm{\alpha}_j) + b - 1 + e_{j,1} \right] 
	- \sum_{k=1}^{M} u_k \left[- \bm{w}^T  \phi (\bm{\alpha}_j) - b  - 1 + e_{j,-1} \right], 
	\end{equation}
	where $\{u_k,v_k\}_{k=1}^{M}$ are the Lagrangian multipliers. Let us set to zero the derivatives with respect to $\{\bm{w},b,e_{j,1},e_{j,-1}, v_j,u_j\}$
	\begin{subequations}
		\begin{equation}
		\label{eq:deriv1_1}
		\frac{\partial \mathcal{L}_1}{ \partial \bm{w}}: \quad \bm{w} = \sum_{k=1}^{M} (u_k - v_k) \phi (\bm{\alpha}_k),
		\end{equation}
		\begin{equation}
		\label{eq:deriv1_2}
		\frac{\partial \mathcal{L}_1}{\partial b}: \quad \sum_{k=1}^{M} (u_k - v_k) = 0 ,
		\end{equation}
		\begin{equation}
		\label{eq:deriv1_3}
		\frac{\partial \mathcal{L}_1}{\partial e_{j,1}}: \quad v_j = CSp_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,1) e_{j,1} \quad j=1\dots M,
		\end{equation}
		\begin{equation}
		\label{eq:deriv1_4}
		\frac{\partial \mathcal{L}_1}{\partial e_{j,-1}}: \quad u_j = CSp_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,-1) e_{j,-1} \quad j=1\dots M,
		\end{equation}
		\begin{equation}
		\label{eq:deriv1_5}
		\frac{\partial \mathcal{L}_1}{\partial v_j}: \quad \bm{w}^T \phi (\bm{\alpha}_j) + b - 1 + e_{j,1} = 0 \quad j=1\dots M,
		\end{equation}
		\begin{equation}
		\label{eq:deriv1_6}
		\frac{\partial \mathcal{L}_1}{\partial u_j}: \quad - \bm{w}^T \phi (\bm{\alpha}_j) - b - 1 + e_{j,-1} = 0 \quad j=1\dots M.
		\end{equation}
	\end{subequations}
	Substituting \eqref{eq:deriv1_1}, \eqref{eq:deriv1_3} and \eqref{eq:deriv1_4} in \eqref{eq:deriv1_5} and \eqref{eq:deriv1_6} we get the system of equations
	\begin{subequations}
		\label{eq:system1}
		\begin{equation}
		\sum_{k=1}^{M} (u_k - v_k) k(\phi (\bm{\alpha}_k,\bm{\alpha}_j)) + b - 1 + \frac{v_j}{CSp_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,1)} = 0
		\quad j=1\dots M
		\end{equation}
		\begin{equation}
		- \sum_{k=1}^{M} (u_k - v_k) k(\phi (\bm{\alpha}_k,\bm{\alpha}_j)) - b - 1 + \frac{v_j}{CSp_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,-1)} = 0
		\quad j=1,\dots, M
		\end{equation}
		\begin{equation}
		\sum_{k=1}^{M} (u_k - v_k) = 0.
		\end{equation}
	\end{subequations}
	\eqref{eq:system1} is a system with $2M + 1$ equations, linear in the $2M + 1$ unknowns $\{u_k,v_k,b\}_{k=1}^{k=M}$ and therefore has finite solution. In particular, using \eqref{eq:deriv1_1}, we have
	\begin{equation}
	\label{eq:wSolution}
	\bm{w}^T\bm{w} =  \sum_{k=1}^{M} \sum_{h=1}^{M} k(\bm{\alpha}_k,\bm{\alpha}_h) (v_kv_h + u_ku_h -2 v_ku_h),
	\end{equation}
	where we used the fact that the kernel function
	\begin{equation}
	k(\bm{\alpha}_k,\bm{\alpha}_h) \triangleq \phi(\bm{\alpha}_k) \phi(\bm{\alpha}_h)^T
	\end{equation}
	 is symmetric \wrt its inputs. 
	
%	Note that while the original problem \eqref{eq:lssvm}, as $S \to \infty$, has infinite constraints, the equivalent formulation \eqref{eq:lssvm22} includes a finite number $2M$ of constraints.
	
	We conclude that $\bm{w}$ has a finite norm since the right hand side of \eqref{eq:wSolution} is a finite sum.
	  


%\bibliographystyle{IEEEtran}
%\bibliography{bibliography.bib}
\renewcommand*{\bibfont}{\footnotesize}

\printbibliography

\clearpage
\section*{Answer to Reviewers' Comments}
\section*{Reviewer: 1}

~

\setstretch{1.0}

\begin{framed}
 {\bf Rev: Positives:

- Classic hypothesis test is added on with machine learning algorithms, which bring novel ideas to the field.

- Some theories are also derived for the proposed algorithms.

- Numerical parts are solid and have many interesting insights. 

- The citations are sufficient. But there are many recent related work with machine learning in detection.
}
\end{framed}

\setstretch{1.5}

{\bf Ans:} We would like to thank you for your positive comments. We have addressed all the issues, updated the manuscript, and provided here a point-to-point response. In addition, as per request of other reviewers we have rewritten the numerical results by 
\begin{itemize}
    \item including a comparison with existing technique that estimates the \ac{ue} position in order to perform \ac{irlv} (see Section \ref{seccomp} and Fig.s \ref{fig:kf10} and \ref{fig:kf10Oc});
    \item considering also configurations with 10 \acp{ap} instead of 5 of the previous manuscript, in order to obtain lower MD and FA probabilities.
\end{itemize}


\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
{\bf Rev: The machine learning part looks trivial and too classic. Much more advance schemes are available everyday on the market.}
\end{framed}
 
\setstretch{1.5}

{\bf Ans:} We agree with you that various solutions have been considered in the literature for classification. Still, we believe that the addressed problem in this paper is simple (we only need to decide between two hypotheses) and the structure/type of input is also simple (we focus on the received signal power at various base stations). Therefore, we focused on two classical approaches, i.e., neural network and support vector machines. Moreover, the intent of the paper was also to establish a strong connection between the machine learning approach -- to be used when statistics of input data in the two hypotheses is not known a priori,-- and the Neyman-Pearson test, to be used when the statistics are known. In this respect, the presented theoretical results fill the gap and are actually applicable also to more complex scenarios. Indeed, as we consider the neural network as a generic parametric function, whose parameters are updated using specific target function, our results extend for example also to deep learning solutions, using more complex neural networks.

In order to make this point more clear we have updated the Introduction, by extending the literature survey, and adding the following sentence:
\begin{quote}
    "\revp{rev11a}"
\end{quote}

Moreover, we have added the following sentence after Theorem 1, to indicate that it also pertains quite complex deep-learning NNs:
\begin{quote}
    "\revp{rev11b}"
\end{quote}
 
Lastly, numerical results have been revised and now include the performance of more complex scenarios, using both more \acp{ap} (thus increasing the input size of the machine) and using more complex deep-learning \acp{nn}. 

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Theorem 1 looks too obvious.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Although Theorem 1 (Corollary 1 in the new version of the manuscript) largely relies on an existing result that connects the MLP to the Bayes optimal discriminant function, it is not so common in journal and even books on ML to frame the classification problem as a hypothesis testing problem and investigate the connection between ML solutions and Neyman-Pearson optimal test. We believe that this is the contribution of Theorem 1, also the other theorems of the manuscript that extended this results to SVM solutions and various training options. Following your advice we have here briefly recalled the result of \cite{Ruck-90} and reduced to the minimum the derivations for the proof of Theorem 1, which now only presented as a corollary of the result of \cite{Ruck-90}.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Neural networks in Figure 2 (Fig. \ref{fig:aeArch} in the new version of the manuscript) are fully connected and kind of shallow.}
\end{framed}

\setstretch{1.5}
{\bf Ans:}  We thank you for your comment. We have modified Fig. \ref{fig:aeArch} including the possibility of not having some connections among neurons. We also added the following more extensive description of the AE:
\begin{quote}
    "\revp{deep ae}"
\end{quote}
Moreover, following the advice of another reviewer, we have included more hidden layers in the same figure.

In the numerical results we still use a fully-connected NN, as the number of input in the considered scenario is small and still tractable with this kind of networks.

% We would like to thank the reviewer for having indicated more complex solutions to our problem. \hl{NON CAPISCO} In this paper we do not consider convolutional autoencoders and hence we implemented networks with fully connected layers. We added a more general description of the AE in Sec. \ref{sec:auto} : 
% \begin{quote}
%     "\revp{deep ae} \cite[Chapter 14]{goodfellow}.
%     \revp{deep ae2} \cite[Chapter 14]{goodfellow}."
    
% \end{quote}
 
\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Abstract sounds to stress something like the attacks, while in the main text, it is rarely mentioned and discussed.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thanks for your comment. We have revised the abstract to avoid misunderstanding about the attacks. It now reads as follows:
\begin{quote}
    "\revp{rev14}"
\end{quote}

\clearpage 
\section*{Reviewer: 2}
~
\begin{framed}
\noindent{\bf Rev: Positives:
The authors provide model descriptions and include realistic effects like fading and shadowing. They consider multiple algorithms and compare them to the theoretical optimum. An attacker scenario is considered, too, where the location of the attacker is optimised. ML is shown to reduce the time to read a success with respect to random attacks.}
\end{framed}
\setstretch{1.5}
{\bf Ans:} We would like to thank you for your positive comments. We have addressed all the issues, updated the manuscript, and provided here a point-to-point response. 

\setstretch{1.0}

\begin{framed}
\noindent {\bf Rev:
There exist a large number of literature on location aware services in WiFi as well as cellular networks. It must be clearly described what the benefits of the proposed (simple and idealised hypothesis test approach) are.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We have carefully revised the literature, according to your suggestion. Current literature can be classified into these two main categories:
\begin{itemize}
    \item Some works deal with the problem of comparing the current channel estimate with another single channel realization, used as a reference and collected earlier: our \ac{irlv} problem   is different as we aim at potentially comparing the current channel estimate with many other channel realizations (for the various points of the region of interest). 
    \item Other works deals with the problem of a {\em specific} location verification, i.e., checking if the user is a given specific position: in this case the literature converts attenuation measurements into distances with respect to reference points and then determine the position and verify it. This approach can be extended to \ac{irlv}, and in fact we have included a comparison with this approach in the revised manuscript (see  Section \ref{seccomp}, and the response to your next question. However, these approaches requires the a-priori knowledge of the relation between the measured physical quantity (e.g., the attenuation) and the distance. With realistic channel models this relation is not fixed but depends on the position itself (e.g., been in line of sight or not), and, as also shown by our results, these approaches are not robust.
    \item Most papers assume either to have perfect distance estimates of the user with respect to reference points, or to know the statistics of the error on distance. In practical scenarios however these assumptions are unrealistic.
\end{itemize}
Since most of the paper either consider a different problem rather than \ac{irlv} (e.g., single location verification) or have too simplistic assumption on the distance estimate (e.g., perfect estimates or known error statistics), we do not spend many words on them in the paper. However, following your advice we have added a direct comparison with a literature technique in the revised manuscript.

The benefits of a \ac{ml} approach are:
\begin{itemize}
    \item the robustness against uncertainties in the channel model: as the machine learns from collected data, it is widely agnostic of specific channel models, thus more robust to hardly predictable scenarios (los/no-los, shadowing parameters, interference, fading...)
    \item their asymptotic optimality. Our paper stresses that with a long training and with complex enough machines, the \ac{ml} approaches can achieve the performance of the optimal \ac{np} test. We agree with you that we consider idealized conditions for the theoretical results, but then in (simple) testing scenarios where the \ac{np} test can be applied we confirm that the asymptotic results are achieved with a limited effort in terms of training and complexity, thus our results are promising also from an implementation perspective.
\end{itemize}

In the revised version of the paper:
\begin{itemize}
    \item We have added the new references \cite{7398138}, \cite{singelee2005location},  and \cite{song2008secure};
    \item We have revised the introduction to better clarify the relation to the literature as follows:
    \begin{quote}
"\revp{rev2lit}\revp{rev3cit}\revp{rev2lit2}"
\end{quote} 
\item We have better highlighted the paper contributions as follows:
\begin{quote}
"The contributions of this paper are summarized hereby:
\begin{enumerate}
    \item we propose a physical layer-based \ac{irlv} solution based on \ac{ml} techniques: the proposed solutions are suitable to operate with noisy estimates and when the statistics of noise and other impairments affecting the estimates are not known, thus obtaining a model-less solution;
    \item we show that the performance (in terms of \ac{fa} and \ac{md} probabilities) of two-class classification \ac{ml} techniques for \ac{irlv} approaches (in asymptotic training and complexity conditions) that of the ac{np} test, which is most powerful for a given significance level;
    \item we explore some novel attack strategy against \ac{irlv}, still based on \ac{ml} techniques, now based on training sets collected by the attacker ouside the \ac{roi}.
\end{enumerate}
\revp{lit2}"
\end{quote} 
\end{itemize}
 
\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf  Rev: In the numerical simulations a comparison with state of the art algorithms should be included.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for the suggestion. In the revised manuscript we have included the description of the  method presented in \cite{li2010security}, wherein first the position of the user is estimated and then compared with the area of interest. Still, a) the technique of \cite{li2010security} assumes to know the relation between path-loss and distance, which may be unrealistic, and b) it was originally design to confirm a specific position rather then for asserting if the user is in a specific {\it region}. Therefore, we have extended the approach of \cite{li2010security} taking into account estimation errors. The comparison method is briefly described in Section \ref{seccomp} as follows:
\begin{quote}
    "\revp{literature_1} 
	\begin{align}
 \hat{\bm x}_{\rm UE} =  \underset{\bm x}{\arg \min} \sum_{n=1}^{N_{\rm AP}} \left(L(\bm{x},\bm{x}_{\rm AP}^{(n)}) - L(\bm{x}_{\rm UE},\bm{x}_{\rm AP}^{(n)}) \right)^2,\label{probmindist}
\end{align}
\revp{literature_2}
$$
\hat{\mathcal{H}}_{\rm MMSE} = 
\begin{cases}
\mathcal{H}_0 \quad \text{if } d < d_0 \\
\mathcal{H}_1 \quad {\rm otherwise}.
\end{cases}
$$
\revp{literature_3}"
\end{quote}


Moreover, Fig.s  \ref{fig:kf10}, \ref{fig:Berlinnew}, and \ref{fig:kf10Oc} now include the comparison with the literature model. We have added the following comments on the figures:  
\begin{itemize}
    \item Comment to Fig. \ref{fig:kf10}:
    \begin{quote}
        "\revp{revLI2a}" \\ ... \\ "\revp{revLI2b}" 
    \end{quote}
    \item Comment to Fig. \ref{fig:Berlinnew}:
    \begin{quote}
        "\revp{revLI}"
    \end{quote}
    \item Comment to Fig. \ref{fig:kf10Oc}:
    \begin{quote}
        "\revp{revLI3}"
    \end{quote}
\end{itemize}
\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The quality of the graphics could be improved.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for pointing out this issue. We have revised all the graphics in the paper and improve their quality.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The asymptotic results are only available for very idealised cases.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} As asymptotic results were shown in comparison with the \ac{np} framework described in Section \ref{sec:los}, we revised the entire Section in order to include more realistic scenarios and show the effect of the different channel parameters on the \ac{irlv} performance. In particular we added in Section \ref{sec:los}
\begin{quote}
"\revp{simpleScen}

\revp{simpleScen2}
\begin{equation*}
p(a|\mathcal{H}_0) = \int_{0}^{R_{\rm in}} p\left( \frac{P_{\rm tx}}{a} | d = d_0\right)p(d_0| d_0 \in \mathcal{A}_0) \, {\tt d} d_0,   
\end{equation*}
\revp{simpleScen2_1}
\begin{equation*}
p(d_0| d_0 \in \mathcal{A}_0) =
\begin{cases}
\frac{2 d_0}{R_{\rm in} ^ 2-R_{\rm min}^2} \, \, d_0 \in [R_{\rm min}, R_{\rm in}], \\
0 \, \, d_0 > R_{\rm in}
\end{cases}
\end{equation*}
\revp{simpleScen2_2}
\begin{equation*}
p(d_0| d_0 \in \mathcal{A}_1) =
\begin{cases}
0 \, \, d_0 \leq R_{\rm in},\\
\frac{2 d_0}{R ^ 2- R_{\rm in} ^2} \, \, d_0 \in (R_{\rm in},R].
\end{cases}
\end{equation*}
1) \emph{Fading scenario}
\revp{simpleScen3}
\begin{equation*}
    p(a|\mathcal{H}_0) = 
    \frac{2}{R_{\rm in}^2-R_{\rm min}^2}\int_{R_{\rm min}}^{R_{in}} 10^{P_{{\rm PL},{\rm LOS}}(d_0)/10} \exp\left(-10^{P_{{\rm PL},{\rm LOS}}(d_0)/10} \frac{P_{\rm tx}}{a}\right)d_0 \, {\tt d}d_0,
\end{equation*}
\revp{simpleScen3_1}
\begin{equation*}
    p(a|\mathcal{H}_1) = 
    \frac{2}{R^2-R_{\rm in}^2}\int_{R_{\rm in}}^R 10^{P_{{\rm PL},{\rm LOS}}(d_0)/10} \exp\left(-10^{P_{{\rm PL},{\rm LOS}}(d_0)/10} \frac{P_{\rm tx}}{a}\right)d_0 \, {\tt d}d_0,
\end{equation*}
\revp{simpleScen3_2}
\begin{equation*}
   \mathcal{M}(a) =
   \ln\left(\frac{R^2-R_{\rm min}^2}{R_{\rm in}^2-R_{\rm in}^2}\frac{\mathcal{V}(R_{\rm min},a)-\mathcal{V}(R_{\rm in},a)}{\mathcal{V}(R_{\rm in},a)-\mathcal{V}(R,a)}\right),
\end{equation*}
\revp{simpleScen3_2_1}
\begin{equation*}
\mathcal{V}(d_0,a) = \exp\left(-\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0 d_0}{c}\right)^2\right) \left(\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0 d_0}{c}\right)^2+1\right) .   
\end{equation*}
\revp{simpleScen3_3}
\begin{equation*}
 \mathcal{M}(a) =
 \ln\left(\frac{R^2-R_{\rm in}^2}{R_{\rm in}^2-R_{\rm min}^2}\frac{\Gamma\left(\frac{5}{3},\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R_{\rm min}^3\right)-\Gamma\left(\frac{5}{3},\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R_{\rm in}^3\right)}{\Gamma\left(\frac{5}{3},\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R_{\rm in}^3\right)-\Gamma\left(\frac{5}{3},\frac{P_{\rm tx}}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R^3\right)}\right),
\end{equation*}
\revp{simpleScen3_4}


2) \emph{Shadowing scenario}
\revp{simpleScen4}
\begin{equation*}
   p(a|\mathcal{H}_0) = 
    \frac{2}{R_{\rm in}^2-R_{\rm min}^2}\int_{R_{\rm min}}^{R_{\rm in}} \exp\left(-\frac{1}{2}\frac{\left(\frac{P_{\rm tx}}{a}+10\nu\log_{10}\left(\frac{4 \pi f_0 d_0}{c}\right)\right)^2}{\sigma_s^2}\right) d_0 \, {\tt d} d_0,  
\end{equation*}
\revp{simpleScen4_1}
\begin{equation*}
    p(a|\mathcal{H}_1) = 
    \frac{2}{R^2-R_{\rm in}^2}\int_{R_{\rm in}}^R \exp\left(-\frac{1}{2}\frac{\left(\frac{P_{\rm tx}}{a}+10\nu\log_{10}\left(\frac{4 \pi f_0 d_0}{c}\right)\right)^2}{\sigma_s^2}\right) d_0 \, {\tt d} d_0 .
\end{equation*}
\revp{simpleScen4_2}
\begin{equation*}
    \mathcal{M}(a) = \ln\left(\frac{R^2}{R_{\rm in}^2} \frac{\mathcal{T}(R_{\rm in})-\mathcal{T}(R_{\rm min})}{\mathcal{T}(R)-\mathcal{T}(R_{\rm in})}\right),
\end{equation*}
\revp{simpleScen4_3}
\begin{equation*}
    \mathcal{T}(d_0) = \erf\left( \frac{\frac{100 \nu^2}{\sigma_s^2}\ln(d_0)-\ln^2(10)+\frac{\frac{P_{\rm tx}}{a} 10 \nu \ln(10)}{2\sigma_s^2}}{\sqrt{1/2\sigma_s^2}10\nu\ln(10)}\right),
\end{equation*}
\revp{simpleScen4_4}"
\end{quote}

Then we showed the convergence of all the \ac{ml}-based systems to the optimal \ac{np} framework in Sec. \ref{sec:singleAp}.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
An overall framework/unified model is missing. The impact of the paper would be much larger if the model-less learning based approach is tested with real experimental data.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Technicalities in the system model section serve to test that \ac{irlv} is feasible also under realistic channel scenarios and to show the comparison between \ac{ml} techniques and the optimal \ac{np} approach. However, we think that the proposed \ac{irlv} system can be extended to a more general framework, using different channel features or other measurements, when available. We better clarified this in Section  \ref{sec:intro}:

\begin{quote}
"\revp{framework1}"
\end{quote}
Similarly, in Section \ref{sec:irlvML}:
\begin{quote}
"\revp{framework2}".
\end{quote}

We then applied our proposed \ac{ml} \ac{irlv} technique also on a real dataset, available in \cite{MOMENTUM-D53}. We show the new numerical results in Fig. \ref{fig:Berlinnew} and added a paragraph in Section \ref{sec:res_fading} which reads:
\begin{quote}
	"\revp{Berlin} \revp{revLI}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The security attack by choosing locations is not properly modelled and does not contain a complete analysis and assessment. Either elaborate or do not include. If the security attack is included, please modify the title accordingly.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Indeed, we do not have the ambition to fully describe an attack in which the user chooses the location. In order to make this point more clear we have revised the abstract to avoid misunderstanding about the attacks. It now reads as follows:
\begin{quote}
    "\revp{rev14}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
There are a number of typos and English grammar mistakes. The paper should be carefully proofread.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for pointing out this issue. We have carefully revised the paper to avoid typos and grammar mistakes.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Most applications are from the WiFi or IoT area. Why the paper then studies the cellular setup?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We agree with you that \ac{irlv} has been studied for WiFi applications. Still, we believe that the problem will be also relevant for future cellular networks that may provide IoT services and will rely more and more on the position of the user for location-specific services. On this point we have added the following sentence in the Introduction:
\begin{quote}
    "\revp{WiFi}"
\end{quote}
Moreover, in Section II we have added the following sentence:
\begin{quote}
    "\revp{WiFi2}"
\end{quote}
\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
If books are referenced, please include page or section or Theorem numbers for easier reference.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for the suggestion. We revised the manuscript in order to include chapter numbers for the cited books.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
In the introduction, there are no SoA references for the security attacks including models and countermeasures.}
\end{framed}
\setstretch{1.5}
{\bf Ans:} We better clarified the SoA attack model in location verification systems and added a paragraph in the Introduction, which reads:
\begin{quote}
"\revp{attack1}"
\end{quote}


\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Fig. 1 is not adding any real value. Please add more information like showing the variables such as regions A0 and A1 and the channel parameters.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for pointing out this issue. We revised Fig. 1 with system parameters.
\setstretch{1.0}

\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Justify and motivate why only the receive power and not the phase is used for hypothesis test.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} The received power was considered only as an example of channel feature that can be exploited for \ac{irlv}, and definitely other options as the phase or the wideband impulse response can be used for localization. In order to make this point more clear we added the following sentence in Section II:
\begin{quote}
    "\revp{revPHASE}"
\end{quote}
\setstretch{1.0}



\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Provide a reference for the chosen shadowing correlation model below (4).}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We added the reference to \cite[Chapter 2.7]{goldsmith2005} after the description of the shadowing correlation.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Explain how to choose the parameter Lambda in (6).}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for pointing out this. We added in Sec. \ref{sec:auth}
\begin{quote}
"\revp{lambda}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Provide more details on $\zeta(\rho)$ below (8) and its operational meaning.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} As the provided example in the old version of the paper was not practical from an operational point of view we modified it by considering two different scenarios: the former affected by path-loss and fading and the latter affected by path-loss and shadowing. The parameter $\zeta(\rho)$ does not exist anymore, as also the overall scenario for the example of application of the \ac{np} lemma has been changed, as shown in Fig. \ref{fig:simpScen}. 

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The example closes with equation (11): How does the test function look like? What are the insights from this example?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We decided not to include the plots for the test functions (\ref{eq:llr1}), (\ref{eq:llr2}) and (\ref{eq:llr3}) as they do not provide any insights if not compared with the threshold value $\Lambda$, allowing us to state whether the tested received power comes from a user located in $\mathcal{A}_0$ or $\mathcal{A}_1$. From this example we get the closed form equation of the functions that allows us to classify the received power in an optimal way, i.e., providing the minimum $P_{\rm MD}$ for a given $P_{\rm FA}$. In order to clarify this, we added in Sec. \ref{sec:los}:
\begin{quote}
"\revp{llrComp}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Section III, explicitly state that you apply supervised learning.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for the suggestion. We added in Sec \ref{sec:irlvML}
\begin{quote}
"\revp{supervised}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Below (13), is $\lambda$ optimised with ML, too?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Since Theorems 1 and 2 hold, the hypothesis testing implemented by the \ac{nn} classifier is the same implemented by the \ac{np} framework. Therefore the parameter $\lambda$ does not need to be optimize, but instead guarantees the minimum $P_{\rm MD}$ for the chosen $P_{\rm FA}$. In order to clarify this points we added in Sec. \ref{sec:nn}:
\begin{quote}
"\revp{lambdaNN}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Theorem 1 is basically a Corollary from [18] (now \cite{Ruck-90}).}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Following your suggestion we have reported the theorem by \cite{Ruck-90} and denoted former Theorem 1 as a corollary.
\setstretch{1.0}


\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
From the flow of the paper, it is not clear, why the section on NN CE Design is needed. Furthermore, sections D and E on SVM should be merged.}
\end{framed}

In order to clarify why both \ac{mse} and \ac{ce} loss functions are considered for \acp{nn} we added in \ref{sec:nn}:
\begin{quote}
"\revp{ceNeeded}"
\end{quote}

In Sec. \ref{sec: mse_train}

\begin{quote}
"\revp{ceNeeded2}"
\end{quote}

In Sec. \ref{sec: ce_train}

\begin{quote}
"\revp{ceNeeded3} \cite[Chapter~5.2]{Bishop2006}."
\end{quote}

Furthermore we merged Sec.s D and E on \ac{svm} as you suggested.


\setstretch{1.0}
\vspace{5mm} %5mm vertical space

\begin{framed}
\noindent {\bf Rev:
In Theorem 3 and following, the assumption of perfect training (reaching a global optimum) should be justified. Lemma 1 alone is not sufficient.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} In Theorem 3 we analyze the function obtained by SVM when it converges to the global optimum. We agree with you that in general, this requires a very long training, although this condition alone is not enough to ensure convergence to the optimum. In order to make this point more clear we have rewritten the hypothesis of Theorem 3 as follows:
\begin{quote}
    "\revp{revGO}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The phrase "parameter" is first used explicitly in Sec. 3-E without introducing it. However, it is implicitly used earlier when the activation function in NNs and kernel function in SVMs are described as being "fixed" (which refers to being a hyperparameter).}
\end{framed}

\setstretch{1.5}
{\bf Ans}: We better introduced the notion of "hyper-parameter" as soon as the first of them appears in Section \ref{sec:nn}, by writing:
\begin{quote}
	"\revp{hyper1}"
\end{quote}
We did the same for the feature space transformation function in Section \ref{sec:svm}
\begin{quote}
	"\revp{hyper2}"
\end{quote}
 and also for the kernel scale and $C$ in \eqref{eq:lssvm}
 \begin{quote}
 	"\revp{hyper3}"
 \end{quote} 

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Section IV switches to a new model where data is only collected within region A0. This is not clear and also not justified.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} In Sec. \ref{sec:OneClass} the new model collects data uniquely from region $\mathcal{A}_0$ in the training phase and consider particular implementation of \ac{ml} classifiers able to distinguish between two classes by being trained only with samples of one class. Hence samples are collected from $\mathcal{A}_0$ during the training phase and from both $\mathcal{A}_0$ and $\mathcal{A}_1$ during the testing phase. 

In order to clarify this aspect we added in Sec. \ref{sec:OneClass}:
\begin{quote}
"\revp{oneClass}"
\end{quote}

The choice of this new setting is motivated by the fact that, as reported in Sec. \ref{sec:OneClass}:
\begin{quote}
"In practice, having training points available for both regions $\mathcal A_0$ and ${\mathcal A}_1$ may be difficult since $a$) region $\A{1}$ may be quite wide and not necessarily well defined (being simply the complementary region of $\mathcal A_0$) and $b$) the attacker may use multiple antennas and, by beamforming, can induce attenuation estimates that not necessarily correspond to points in the region $\A{1}$."
\end{quote}


\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
In the AE architecture, the operational meaning and benefits of the low dimensional hidden layer are not clearly derived. Furthermore, the linear activation is not motivated.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} As \acp{ae} are well known architectures, the in-depth description of the meaning of the low dimensional layer as well as its derivation is beyond the scope of this paper, as well it is the choice of the linear activation function at the output layer (usual choice according to \cite[Chapter 14]{Goodfellow}). We added in Sec. \ref{sec:auto} a reference to \cite[Chapter 14]{Goodfellow}, for a more accurate description of the characteristics of \acp{ae}.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The resulting IRLV test function is the simple MSE thresholding.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} As the \ac{ae} is trained to attempt to copy the input to its output the result is that, in the testing phase, only those vectors with the same features of the training set will be reconstructed with small \ac{mse}, whereas input vectors with features different from those of the training set will be mapped to different vectors at the output, and hence with high \ac{mse}. Since training is based on vectors collected from area $\mathcal{A}_0$ and we want to grant access to the systems only to users located inside $\mathcal{A}_0$ and hence whose vectors will have the same features of the training set, by thresholding the \ac{mse} we can obtain the classifier needed for the \ac{irlv}.

\setstretch{1.0}
\begin{framed}
\noindent {\bf Rev:
The section on the ML-based attack strategies does not have a clear model and the interaction between system and attacker are correctly detailed. It seems a non-cooperative game model could fit here.}
\end{framed}
\setstretch{1.5}
{\bf Ans:} Thank you for your observation. The previous description of the attack was confusing, as it was also mentioning various strategies. We have completely rewritten Section \ref{sec:attack}, focusing on the specific attack and stressing its motivation, while hinting to other possibile strategies. The new section reads as follows:
\begin{quote}
    "\revp{sezattack}
\begin{enumerate}
    \item The attacker visit  $N$  points spread uniformly at random outside $\mathcal A_0$. From each point it collects the attenuation vector and performs the attack. If any of the attacks is successful, the procedure is stopped.
    \item If none of the $N$ attacks has been successful, the attenuation vectors are used to train a one-class classifier.
    \item The attacker picks a new position uniformly at random outside $\mathcal A_0$ and feeds its attenuation vector to the trained classifier.
    \item If the vector is classified as belonging to the class it is discarded, and the procedure goes back to point 3), otherwise an attack from that position is performed.
    \item If the attack is successful, the procedure is stopped. Otherwise, the attenuation vector is used to as further training input of the one-class classifier and the procedure goes back to point 3).
\end{enumerate}
\revp{sezattack2} 
\end{quote}


\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Reason for using Eq. (38) as activation function for the output layer is missing, especially since it is not a common choice for an activation function. Motivate the design choices!}
\end{framed}
\setstretch{1.5}


{\bf Ans:} 
Thanks for havigh highlighted this issue. We have carefully revised the AE and its design choice and we now use common activation functions in the literature. In particular, in Section \ref{sec:numResOneClass} we specify
\begin{quote}
"\revp{designAE}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Why not using more hidden layers to improve performance?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} In the revised manuscript both the feedforward \acp{nn} and the \ac{ae} hev been extended to include multiple layers in order to improve the system performance as you suggested. Results are reported in Sec. \ref{sec:numRes}.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
A illustration of the considered layout in Sec. V-A might be helpful.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for the suggestion. We added in Sec. \ref{sec:los} Fig. \ref{fig:simpScen} to illustrate the scenario where the \ac{np} framework has been applied and for which Sec. \ref{sec:singleAp} reports the numerical results.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
In the assessment of Fig 3 ( Fig. \ref{fig:ceVSmse} in the revised paper), the advantage of NN versus N-P should be clarified, too, since they perform equally (bad).}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We added in Sec. \ref{sec:los}:
\begin{quote}
"\revp{llrComp}"
\end{quote}

Furthermore the performance of the resulting \ac{irlv} system has been improved by considering more complicated scenarios for which is possible to compute closed form solutions for the \acp{llr}.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The scenario in Fig. 4 (Fig. \ref{fig:map} in the revised paper) is not well motivated. Why should the region A0 be outside the two main streets?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} There is no special reason for the positioning of area $\mathcal A_0$ outside of the two streets, other than considering it inside a building (e.g., an office). In order to clarify this point we added in Section \ref{sec:singleAp}:
\begin{quote}
"\revp{building}"
\end{quote}

Moreover, in the revised version of the paper we consider also another position of the \ac{roi}, \hl{DESCRIZIONE}. We added Fig. \ref{fig:kf1_newArea} that has been commented as follows:
\begin{quote}
"\revp{revnewarea}"
\end{quote}

In the new version we have also considered different numbers of \acp{ap}, namely 1, 5, and 10, in order to provide a more complete set of results. Still, our results are to be considered only exemplary and do not aim at exploring the performance in a comprehensive way, which is left to technical studies to be conducted in specific scenarios of interest.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The evaluation in the end of Sec V-B sounds contradictory. First, it is said that "[...] for small S, performance get slightly worse as $k_f$ grows.". Second, at the end of the evaluation, it is stated that "[...] in practical situations where the points for training may be limited, it may be advantageous to collect more fading realization per location.". Another way of saying this would be that for small S ("limited number of training points"), the number of $k_f$ should be increased ("collect more fading realizations per location"). However, this is contradictory to the first statement, that the performance decreases with increasing $k_f$ for small S.
- The considered layout in Sec. V-C is unclear.
}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for your note. Indeed, we have revised our approach in the presence of fading, and we average the $k_f$ fading realizations and give the resulting average as input to the learning machines. We now describe the fading average in Section \ref{sec:auth}:
\begin{quote}
    "\revp{avg_1}
$$
a^{(n)}_{\Sigma} = \frac{1}{k_f}\sum_{j=1}^{k_f} a^{(n)}."
$$
\end{quote}

The sentence mentioned in the revision has been replaced by the following comment on Fig. \ref{}:
\begin{quote}
    "\revp{rev2fad}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The conclusions from the numerical simulations (last paragraph before Section VI) are very specific and contain mainly numerical evidence from the chose numerical scenarios.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We agree with you that those considerations did not add much to the numberial results already discussed. In the revised version of the manuscript we have removed the paragraph.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
In the references: check capitalised letters in [14], [20]. Check author names in [16].}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for pointing out the mistakes. We have carefully revised the references section. 
\vspace{5mm} %5mm vertical space


\clearpage


\section*{Reviewer 3}
\setstretch{1.0}
\begin{framed}
\noindent {\bf Rev: Positives: This paper proposes machine learning based in-region location verification scheme, which uses neural networks (NNs) or SVM to learn the channel features of the region of interest without knowing the channel parameters. Numerical results show that this scheme achieves low miss detection rate. The theoretic study of the proposed scheme is reasonable.
}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We would like to thank you for your positive comments. We have addressed all the issues, updated the manuscript, and provided here a point-to-point response. 

\setstretch{1.0}
\begin{framed}
\noindent {\bf Rev:
The references of the work can be further enhanced and the model descriptions are not always comprehensive. Please explain the numerical results for more details. For example, please add the benchmark scheme to convince readers. In addition, the presentation can be further improved and the complexity of the proposed scheme should be provided.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We would like to thank your for your useful suggestions. We have carefully revised the paper according to your indications, with an in-depth revision of the numerical result section, improving the presentation, comparing our solutions with existing ones, and assessing the complexity of the proposed approach.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Please compare the proposed scheme with other existing schemes.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} {\bf Ans:} Thank you for the suggestion. In the revised manuscript we have included the description of the  method presented in \cite{li2010security}, wherein first the position of the user is estimated and then compared with the area of interest. Still, a) the technique of \cite{li2010security} assumes to know the relation between path-loss and distance, which may be unrealistic, and b) it was originally design to confirm a specific position rather then for asserting if the user is in a specific {\it region}. Therefore, we have extended the approach of \cite{li2010security} taking into account estimation errors. The comparison method is briefly described in Section \ref{seccomp} as follows:
\begin{quote}
    "\revp{literature_1} 
	\begin{align}
 \hat{\bm x}_{\rm UE} =  \underset{\bm x}{\arg \min} \sum_{n=1}^{N_{\rm AP}} \left(L(\bm{x},\bm{x}_{\rm AP}^{(n)}) - L(\bm{x}_{\rm UE},\bm{x}_{\rm AP}^{(n)}) \right)^2,\label{probmindist}
\end{align}
\revp{literature_2}
$$
\hat{\mathcal{H}}_{\rm MMSE} = 
\begin{cases}
\mathcal{H}_0 \quad \text{if } d < d_0 \\
\mathcal{H}_1 \quad {\rm otherwise}.
\end{cases}
$$
\revp{literature_3}"
\end{quote}


Moreover, Fig.s  \ref{fig:kf10}, \ref{fig:Berlinnew}, and \ref{fig:kf10Oc} now include the comparison with the literature model. We have added the following comments on the figures:  
\begin{itemize}
    \item Comment to Fig. \ref{fig:kf10}:
    \begin{quote}
        "\revp{revLI2a}" \\ ... \\ "\revp{revLI2b}" 
    \end{quote}
    \item Comment to Fig. \ref{fig:Berlinnew}:
    \begin{quote}
        "\revp{revLI}"
    \end{quote}
    \item Comment to Fig. \ref{fig:kf10Oc}:
    \begin{quote}
        "\revp{revLI3}"
    \end{quote}
\end{itemize}
\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Proof that this proposed scheme has robust against the channel fading. In other words, could you please provide some numerical results to support the robust of this scheme?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Please note that our considered channel model includes fading. Indeed, Fig.s \ref{fig:kf1}, \ref{fig:kf1_newArea}, \ref{fig:kf10-5}, \ref{fig:kf10}, \ref{fig:kf1Oc}, \ref{fig:kf10Oc} all include fading effect. Moreover, we have also considered a refinement of our approach, explicitly targeting the adverse effect of fading, wherein the input data to the learning machines are obtained by averaging over multiple fading realizations. By choosing the number of averaged realization we can understand the relevance of averaging fading, taking into account that having multiple realizations of attenuation vectors may not always be possibile and takes additional time. In order to make this point more clear we have added the following sentences in Section \ref{sec:auth}:
\begin{quote}
    "\revp{avg_1}
$$
a^{(n)}_{\Sigma} = \frac{1}{k_f}\sum_{j=1}^{k_f} a^{(n)}."
$$
\end{quote}


\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
What are the computation complexity of the two machine learning methods (i.e., neural networks (NNs) and SVM)?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We added Section \ref{sec:comp} showing the computational complexity of the two machine learning methods.

\begin{quote}
"\revp{comp1} 

\revp{comp2}

\revp{comp3}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The results in terms of the miss detection rate and the false alarm rate in Fig. 3 [Fig. \ref{fig:ceVSmse} in the revised paper] are not practical. Please explain.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Based on your comments we revised Fig. \ref{fig:ceVSmse} and the relative theoretical part in Sec. \ref{sec:los}. Results show that the implemented system achieves petter performance and the equivalence between hypothesis testing based on the \ac{np} framework and via \ac{ml} is still verified.

\vspace{5mm} %5mm vertical space

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
A couple of papers are worth citing:

(1). Physical layer authentication over MIMO fading wiretap channels, IEEE Trans. Wireless Communications, 2012.

(2). PHY-layer spoofing detection with reinforcement learning in wireless networks, IEEE Trans. Vehicular Technology,2016.
}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We have added a citation of the two papers in the Introduction, within the following sentence:
\begin{quote}
    "\revp{rev3cit}"
\end{quote}

\end{document}
