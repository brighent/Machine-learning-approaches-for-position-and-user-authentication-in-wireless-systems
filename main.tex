\documentclass[final,twocolumn]{IEEEtran}
%\usepackage[width=6.5in, left=2.5cm,height=54em]{geometry}
%\documentclass[final,journal]{IEEEtran}

\usepackage[utf8]{inputenc}
\usepackage{framed}
\usepackage[linesnumbered,lined, algoruled]{algorithm2e}
\usepackage{algorithmic,float}
\usepackage{amsmath}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
%\usepackage[toc,page]{appendix}
\usepackage{amssymb}
\usepackage{bm,array}
\usepackage{soul,color}
%\usepackage{epstopdf}
\usepackage[acronym,shortcuts]{glossaries}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{comment}
\usepackage{setspace}
\usepackage[inline]{enumitem}
\usepackage{booktabs}
\makeglossaries
%%% Glossaries/Acronyms
\DeclareMathOperator\erf{erf}
\newacronym{ae}{AE}{auto encoder}
\newacronym{auc}{AUC}{area under the curve}
\newacronym{ap}{AP}{access point}
\newacronym{ce}{CE}{cross entropy}
\newacronym{cdf}{CDF}{cumulative distribution function}
\newacronym{eda}{EDA}{estimated distance approach}
\newacronym{fa}{FA}{false alarm}
\newacronym{gnss}{GNSS}{global navigation satellite system}
\newacronym{irlv}{IRLV}{in-region location verification}
\newacronym{kl}{K-L}{Kullback-Leibler}
\newacronym{ls}{LS}{least-squares}
\newacronym{llr}{LLR}{log likelihood-ratio}
\newacronym{los}{LOS}{line of sight}
\newacronym{glrt}{GLRT}{generalized likelihood ratio test}
\newacronym{gsm}{GSM}{global system for mobile communications}
\newacronym{lssvm}{LS-SVM}{least squares SVM}
\newacronym{md}{MD}{mis-detection}
\newacronym{ml}{ML}{machine learning}
\newacronym{mlp}{MLP}{multi-layer perceptron}
\newacronym{mmse}{MMSE}{minimum mean square error}
\newacronym{mse}{MSE}{mean squared error}
\newacronym[\glslongpluralkey={neural networks}]{nn}{NN}{neural network}
\newacronym{np}{N-P}{Neyman-Pearson}
\newacronym{oclssvm}{OCLSSVM}{one-class least-square \ac{svm}}
\newacronym{pdf}{PDF}{probability density function}
\newacronym{pso}{PSO}{particle swarm optimization}
\newacronym{roc}{DET}{detection error tradeoff}
\newacronym{det}{DET}{detection error tradeoff}
\newacronym{roi}{ROI}{region of interest}
\newacronym{rss}{RSS}{received signal strength}
\newacronym{std}{std}{standard deviation}
\newacronym[\glslongpluralkey={support vector machines}]{svm}{SVM}{support vector machine}
\newacronym{ue}{UD}{user device}
\expandafter\def\expandafter\quote\expandafter{\quote\setstretch{1}~\\}
% Revisions macro
\usepackage[normalem]{ulem}
\usepackage[user]{zref}
\newcommand{\sot}[1]{}

\newcounter{revc}
\makeatletter \zref@newprop{revcontent}{} \zref@addprop{main}{revcontent}
\zref@newprop{revsec}{} \zref@addprop{main}{revsec}

\newcommand{\revi}[2]{%
\zref@setcurrent{revsec}{\thesection}%
\zref@setcurrent{revcontent}{#2}%
\refstepcounter{revc}%
\label{#1}
\zlabel{#1}%
\uline{#2} }

\newcommand{\revinu}[2]{%
\zref@setcurrent{revsec}{\thesection}%
\zref@setcurrent{revcontent}{#2}%
\refstepcounter{revc}%
\zlabel{#1}%
\label{#1}
#2 }

\newcommand{\revr}[2]{%
\zref@setcurrent{revsec}{\thesection}%
\zref@setcurrent{revcontent}{#2}%
\refstepcounter{revc}%
\zlabel{#1}%
\label{#1} \sot{#2}} \makeatother
\newcommand{\revp}[1]{\zref[revcontent]{#1}}
\newcommand{\zsecref}[1]{\zref[revsec]{#1}}



\newcommand{\ie}{i.e., }
\newcommand{\wrt}{with respect to }
\newcommand{\Exp}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\ai}{\bm{a}^{(i)}}
\newcommand{\A}[1]{\mathcal{A}_#1}

\DeclareMathOperator{\sign}{sign}
\newcommand{\E}{E}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}

\title{Machine Learning For In-Region Location Verification In Wireless Networks}
\author{Alessandro Brighente, Francesco Formaggio,\\  Giorgio Maria Di Nunzio, and  Stefano Tomasin }
\date{\today}


%\usepackage[autostyle]{csquotes}
\usepackage[backend=bibtex,style=ieee,sorting=none]{biblatex}
\bibliography{bibliography}


\begin{document}


\maketitle

\sloppy

\begin{abstract}
\uline{\Ac{irlv} aims at verifying whether a user is inside a \ac{roi}. In wireless networks, \ac{irlv} can exploit the features of the channel between the user and a set of trusted access points. In practice, the channel feature statistics is not available and we resort \ac{ml} solutions for \ac{irlv}. We first show that solutions based on either \acp{nn} or \acp{svm} are \ac{np}-optimal at learning convergence for sufficiently complex machines and large enough training datasets with typical loss functions. Indeed, for finite training, \ac{ml} solutions are more accurate than the \ac{np} test applied on estimated channel statistics. Then, as estimating channel features outside the \ac{roi} may be difficult, we consider one-class classifiers, namely auto-encoders \acp{nn} and one-class \acp{svm}, which however are not equivalent to the \acf{glrt},  typically replacing the \ac{np} test in the one-class problem.  Numerical results support the results in realistic \uline{wireless networks}, with channel model including path-loss, shadowing, and fading.}
\end{abstract}

\begin{IEEEkeywords}
Auto-encoder, in-region location verification, machine learning, neural network, support vector machine.
\end{IEEEkeywords}

\glsresetall
%\clearpage
\section{Introduction}
\label{sec:intro}

\uline{Location information without verification gives ample opportunities to attack a service granting system (with  applications in sensor networks \mbox{\cite{Zeng-survey, 8376254, wei2013}}, the Internet of things (IoT) \cite{7903611}, and geo-specific encryption \cite{quaglia}). In fact, the location information can be easily manipulated either by tampering the hardware/software reporting the location or by spoofing the \ac{gnss} signal outside the user device. In this context, location verification systems aim at verifying the position of mobile devices in a communication network.  In order to verify the location, the features of the wireless channel over which communications occur can be exploited. An example is given by {\cite{li2010security}}, where the \ac{rss} is used to estimate the distance between the user and other network nodes.}

\revi{rev2lit}{Location verification can be classified into two main sub-problems: \emph{single location verification} and {\it \ac{irlv}}. The \emph{single location verification} problem aims at verifying if a user is in a specific point. A solution is obtained by comparing some channel features of the user under test with those of a trusted user that was in the same location in the past. }\revi{rev3cit}{In some works, this approach is used to verify if different messages come from the same user, i.e., as a {\it user authentication} mechanism (see \protect{\cite{7270404}} for a survey): in \protect{\cite{Baracca-12}}, channel features are affected by noise with known  statistics; whereas, in \protect{\cite{7398138}}, statistics are unknown and a learning strategy is adopted.  The {\it \ac{irlv}} aims at verifying if a user is inside a \ac{roi} \cite{Zeng-survey}. }\revi{rev2lit2}{Solutions include distance bounding techniques with rapid exchanges of packets between the verifier and the prover \cite{Brands, singelee2005location}, also in the context of vehicular ad-hoc networks {\cite{song2008secure}}. Other solutions use radio-frequency and ultrasound signals {\cite{Sastry}}, or anchor nodes and transmit power variations {\cite{Vora}}. More recently, a delay-based verification technique leveraging geometric properties  has been proposed in {\cite{7145434}}. Some of the proposed techniques partially neglect wireless propagation phenomena (such as shadowing and fading) that corrupt the distance estimates {\cite{Brands,Sastry} and \cite{Vora}}. Other approaches assume specific channel statistics that may be not accurate due to changing environment conditions {\cite{quaglia}}.} 
\revi{attack1}{Two types of attacks to \ac{irlv} have been considered in the literature, where the attacker claims a false location \mbox{\cite{singelee2005location,song2008secure,Sastry}}  or tampers with the signal power making it coherent with the fake claimed position  \mbox{\cite{Vora,yan2016location}} and \mbox{\cite{li2010security}}.}

Focusing on \ac{irlv}, if the statistics of the channels to devices both inside and outside the \ac{roi} is known to the network, the \ac{np} theorem {\cite{Cover-book}} provides the most powerful test for a given significance level. When  the channel statistics is not available, a two-step solution would be to a) estimate the channel statistics and b) apply the \ac{np} theorem on the estimated statistics. However, as we also confirm in this paper, this approach may not be accurate. Alternatively, \ac{ml} techniques can be used. For example, in \cite{xiao-2018}, the single location verification problem is solved without assumptions  on the channel model by applying logistic regression. In \cite{tian2015robust}, the objective is to determine the position of a user inside a building by means of a multi-class \ac{svm}. Nevertheless, neither \cite{xiao-2018}  nor \cite{tian2015robust} compare the performance of their \ac{ml} approaches with that of the \ac{np} test.

In this paper, we remove the channel knowledge assumption and study two \ac{ml} solutions for \ac{irlv} based on \acp{nn} and \ac{svm}. In particular, we investigate \acp{mlp} that use either the \ac{ce} or the \ac{mse} as loss functions, and the \ac{ls} version of \acp{svm}. We show that these approaches are \ac{np}-optimal for sufficiently complex machines and sufficiently large training datasets. \revi{rev11a}{The obtained asymptotic results are applicable also to elaborate ML solutions, such as deep learning NNs, that can still be seen as parametric functions, although more complex than shallow NNs.}

%Two specific security issues are then addressed. 
\uline{Since it may be difficult to obtain training data from the space outside the \ac{roi}, as it can be vast or not well defined, we explore the one-class classification problem under the knowledge of legitimate channel statistics, and we conclude that conventional \ac{ml} solutions based on both the \ac{ae} and the one-class \ac{svm} do not coincide with the \ac{glrt}, even for large training datasets.}  
%\revi{rev14b}{Lastly, we consider  the use of (one-class) classifiers to accelerate the success of a sequence of attacks made from various positions.} 
Numerical results support the theoretical results in a realistic wireless network scenario, including path-loss, shadowing, and fading. We show that in a simple scenario a shallow \ac{nn} and a relatively small training dataset already provide optimal performance. We also show that one-class \ac{irlv} approaches achieve a performance comparable to that of two-class techniques.

\uline{The contributions of this paper are summarized hereby:}
\begin{enumerate}
    \item \uline{we propose physical-layer \ac{irlv} solutions based on \ac{ml} techniques that are suitable to operate with inaccurate estimates, even when their statistics are not known, thus being model-less;}
    \item \uline{we show that, in asymptotic training and complexity conditions, \ac{nn} and \ac{lssvm} at convergence achieve the error probabilities of the \ac{np} test, which is most powerful for a given significance level.}
\end{enumerate}
\revi{lit2}{About point 1, shadowing and fading effects on \ac{irlv} have not been much considered in the literature: for example, in \protect{\cite{Vora},} \ac{rss} estimates are assumed to be perfect; in {\cite{Sastry}}, agents are assumed to communicate over an  error-free channel (san assumption used for most distance-bounding protocols {\cite{singelee2005location,song2008secure}}). In {\cite{li2010security}} and {\cite{yan2016location}}, shadowing is taken into account, while fading is neglected, and channel statistics is assumed to be known. All these simplifying assumptions are not required by the \ac{ml} models studied in this paper.} \revi{framework1}{Indeed, we also consider an accurate wireless channel model (in Section II), but only in order to explain the complexity of the techniques in the literature (including the \ac{np} test) and, consequently, justify the use of \ac{ml}. Still,  our solution and theoretical results can be applied on any channel statistics and various features (see \cite{Zeng-survey} for a survey), even including  measurements from external sensors.}

\uline{The paper is organized as follows: Section~II introduces the system model for the \ac{irlv} problem, with an example of wireless channel, and recall two reference \ac{irlv} techniques. Section~III describes the proposed \ac{ml} solutions and presents the theoretical results on their asymptotic performance. In Section~IV, we propose the one-class classification approaches. Numerical results are shown and discussed in Section~V. Conclusions are outlined in Section~VII.}

\uline{The following notation is used throughout the paper: bold lowercase letters refer to vectors, whereas bold uppercase letters refer to matrices, $\mathbb{E}[\cdot]$ and $\mathbb P[\cdot]$ denote the expectation and probability operators, respectively, $(\cdot)^T$ denotes the transpose operator, $\ln x$, and $\log_{10} x$ denote the natural-base and base-10 logarithms, respectively.}



\section{System Model}

% \begin{figure}
%     \centering
%     \includegraphics[width=8.5cm]{irlv.jpg}
%     \caption{The considered \ac{irlv} scenario.}
%     \label{fig1}
% \end{figure}

We consider a wireless network  with $N_{\rm AP}$ \acp{ap} covering the area $\mathcal{A}$ over a plane. We propose a \ac{irlv} system to determine if a \ac{ue} is transmitting from within an {\em authorized} \ac{roi} $\mathcal{A}_0$ inside  $\mathcal{A}$, and we define $\mathcal{A}_1=\mathcal{A} \setminus \mathcal{A}_0$ as its complementary region. The verification process exploits the location dependency of the features of the channel between the \ac{ue} and the \acp{ap}. \revi{revPHASE}{For example, we consider as feature the channel power attenuation (of a narrowband transmission), similarly to \protect{\cite{li2010security,Vora}} and \protect{\cite{yan2016location}}. Indeed, other features can be exploited, such as the phase or the wideband impulse response (see \protect{\cite{7270404}} for a survey): our solutions readily apply also to these cases, as we do not make special assumptions on the channel model for their design and analysis.}

We assume that the \ac{ue} transmits a pilot signal with fixed power, known at the \acp{ap}, from which the \acp{ap} can measure the received power and estimate the channel attenuation. We assume that the attenuation estimation is perfect, i.e., not affected by noise or interference, thanks to a sufficiently long pilot signal.



\subsection{Channel Model}\label{sec:chMod}

We now describe a widely adopted wireless channel model to clarify the challenge faced by an \ac{irlv} based on the attenuation estimate. \revi{WiFi2}{In particular, we consider the general channel \cite{3gpp} model that covers a large frequency range from $800$~MHz to 2.5~GHz, suitable for wireless local area networks (WLANs) and IoT, where \ac{irlv} is typically applied.} Let $a^{(n)}$ be the attenuation incurred over the channel between the \ac{ue} and \ac{ap} $n$, including the effects of path-loss, shadowing, and fading. In particular, by assuming a Rayleigh model for fading, we have $g = (\sqrt{a^{(n)}})^{-1} \sim {\mathcal N}\left(0,\sigma_{g,n}^2\right)$, $(\sigma_{a,n}^2)_{\rm dB} =  -10\log_{10}\sigma_{g,n}^2={P_{\rm PL}^{(n)}} + s$ accounts for the path-loss and shadowing components, $P_{\rm PL}^{(n)}$ is the path-loss coefficient in dB, and $s \sim \mathcal{N}(0,\sigma_{s,{\rm dB}}^2)$, where ${\mathcal N}(m,\sigma^2)$ denotes a Gaussian random variable with mean $m$ and variance $\sigma^2$, is the shadowing component.   \uline{Shadowing components of two \acp{ue}  at  positions $\bm{x}_1$ and $\bm{x}_2$   have correlation $\sigma_{s,{\rm dB}}^2e^{-\frac{L(\bm{x}_1,\bm{x}_2)}{d_c}}$, where $d_c$ is the shadowing decorrelation distance \underline{\cite[Section 2.7]{goldsmith2005}}.} 

%Both path-loss and shadowing models are  derived from \cite{3gpp}. 
Let us denote as $\bm{x}_{\rm AP}^{(n)} =(X_{\rm AP}^{(n)},Y_{\rm AP}^{(n)})$ the position of  \ac{ap} $n= 1, \ldots, N_{\rm AP}$. For a \ac{ue} located at $\bm{x}_{\rm UD}=(X_u,Y_u)$, its distance from \ac{ap} $n$ is $L(\bm{x}_{\rm UD},\bm{x}_{\rm AP}^{(n)}) = \sqrt{||\bm{x}_{\rm UD}-\bm{x}_{\rm AP}^{(n)}||_2^2}$. For the path-loss, \cite{3gpp} provides two scenarios: \ac{los} and non-\ac{los}. For a \ac{los} link, the path-loss in dB is modelled as
\begin{equation}\label{eq:los}
\begin{split}
    P_{{\rm PL},{\rm LOS}} & \left(  L(\bm{x}_{\rm UD},\bm{x}_{\rm AP}^{(n)})\right) = \\
    &10 \nu \log_{10}\left(\frac{f 4\pi L(\bm{x}_{\rm UD},\bm{x}_{\rm AP}^{(n)})}{c}\right),
\end{split}
\end{equation}
where $\nu$ is the path-loss coefficient, $f$ is the carrier frequency and $c$ is the speed of light. 
For a  non-\ac{los} link, the path-loss coefficient in dB is defined as
\begin{equation}\label{eq:nlos}
\begin{split}
    P_{{\rm PL},  {\rm NLOS}} & \left(L(\bm{x}_{\rm UD},\bm{x}_{\rm AP}^{(n)})\right) = 40 (1 - 4 \cdot 10^{-3} h_ {\rm AP}^{(n)}) \cdot \\ &\log_{10}\left (\frac{L(\bm{x}_{\rm UD},\bm{x}_{\rm AP}^{(n)})}{10^3}\right ) - 18 \log_{10} h_{\rm AP}^{(n)} + \\ &+21\log_{10}\left(\frac{f}{10^6}\right) + 80,
    \end{split}
\end{equation}
where $h_{\rm AP}$ is the   AP height. Path-loss and shadowing components (thus $\sigma_{a,n}^2$) are assumed to be time-invariant, while the fading (thus attenuation $a^{(n)}$) is independent for each attenuation estimate. \revi{avg_1}{Fading does not give information on the \ac{ue} location; therefore it is a disturbance for \ac{irlv}. However, by performing $k_f$ estimates of the attenuation in a short time $a_j^{(n)}$, $j=1, \ldots,k_f$, and averaging them, we obtain the new attenuation estimate $a^{(n)}_{\Sigma} = \frac{1}{k_f}\sum_{j=1}^{k_f} a_j^{(n)}$.}
 

\subsection{\ac{irlv} With Known Channel Statistics}\label{sec:auth}

\ac{irlv} can be seen as a hypothesis testing problem between the two hypotheses (events):
\begin{itemize}
    \item $\mathcal{H}_0$: the \ac{ue} is transmitting from area $\mathcal{A}_0$;
    \item $\mathcal{H}_1$: the \ac{ue} is transmitting from area $\mathcal{A}_1$.
\end{itemize}
This is also denoted as a two-class classification problem. Given vector $\bm{a} = [a^{(1)}, \ldots, a^{(N_{\rm AP})}]$ collecting the attenuation estimates at all the \acp{ap}, we aim  at determining the most likely hypothesis, in order to perform \ac{irlv}. Let $\mathcal H \in  \{\mathcal{H}_0, \mathcal{H}_1\}$ be the state of the \ac{ue}, and $\hat{\mathcal H} \in  \{\mathcal{H}_0, \mathcal{H}_1\}$ the decision taken by the \acp{ap}. We have two possible errors: \acp{fa}, which occur when the \ac{ue}  is classified as outside the \ac{roi}, while being inside it, and \acp{md}, which occur when the \ac{ue}  is classified as inside the \ac{roi}, while being outside of it. We indicate the \ac{fa} probability as $P_{\rm FA} =\mathbb{P}(\hat{\mathcal H} = \mathcal H_1 | \mathcal H = \mathcal H_0)$, and the \ac{md} probability as $P_{\rm MD}=\mathbb{P}(\hat{\mathcal H} = \mathcal H_0 | \mathcal H = \mathcal H_1)$. 
%
Let $p(\bm{a}|\mathcal{H}_i)$ be the \ac{pdf} of observing the vector $\bm{a}$ given that $\mathcal{H} = \mathcal{H}_i$. The \ac{llr} for the considered hypothesis is defined as 
\begin{equation}\label{eq:lr}
    {\mathcal M}(\bm{a})=\ln \frac{p(\bm{a}|\mathcal{H}_0)}{p(\bm{a}|\mathcal{H}_1)}.
\end{equation}
According to the \ac{np} theorem, the most powerful test is obtained by comparing $\mathcal{M}(\bm{a})$ with a threshold value $\Lambda$, i.e., obtaining the test function
\begin{equation}
\label{eq:oneClassDec}
f^*(\bm{a}) =
\begin{cases}
-1 &\text{if } {\mathcal M}(\bm{a}) \geq \Lambda, \\
1 & \text{if } {\mathcal M}(\bm{a}) < \Lambda,
\end{cases}
\end{equation}
where $f^*(\bm{a})=-1$ corresponds to $\hat{\mathcal{H}}=\mathcal{H}_0$ and $f^*(\bm{a})=1$ corresponds to $\hat{\mathcal{H}}=\mathcal{H}_1$.
\revi{lambda}{Parameter $\Lambda$ must be chosen to obtain a desired significance level, \ie a desired \ac{fa} probability. It can be set either by assessing the \ac{fa} probability through simulations or by inverting, when available, the expression of \ac{fa} probability as a function of $\Lambda$ \protect{\cite[Section 3.3]{Kay-book}}.}

\subsection{Example of \ac{np} Test}\label{sec:los}
\begin{figure}
    \centering
    \includegraphics[width=6cm]{simpleScen.jpg}
    \caption{Simplified scenario with a single \ac{ap} located at the center of a circular \ac{roi}.}
    \label{fig:simpScen}
\end{figure}
\revi{simpleScen}{As example of application of the \ac{np} test we consider the scenario of Fig. \ref{fig:simpScen}, wherein area $\mathcal{A}$ is a ring with smaller radius $R_{\rm min}$ and larger radius $R_{\rm out}$ and \ac{roi} $\mathcal{A}_{0}$ is a ring concentric to $\mathcal{A}$, with larger radius $R_{\rm in}$ and smaller radius $R_{\rm min}$. A single \ac{ap} ($N_{\rm AP} =1$) is located at the \ac{roi} center and a \ac{ue} is transmitting from distance $d_0$. We consider two models: a) \emph{uncorrelated fading scenario}, which includes \ac{los} path-loss and spatially uncorrelated fading, and b) \emph{uncorrelated shadowing scenario}, which includes \ac{los} path loss and spatially uncorrelated shadowing. In both case, we consider the \ac{los} model for path-loss.}
\revi{simpleScen2}{In order to compute}\footnote{Note that for a single \ac{ap} vector $\bm{a}$ becomes the scalar $a$.} \revi{simpleScen2_0}{$p(a|\mathcal{H}_i)$, we first observe that the \ac{pdf} of incurring in attenuation $a$ for a user located inside the \ac{roi} is (by the total probability law)}
\begin{equation}\label{eq:prc}
p(a|\mathcal{H}_0) = \int_{R_{\rm min}}^{R_{\rm in}} p\left( a | d_0\right)p(d_0| d_0 \in \mathcal{A}_0) \, {\tt d}d_0,    
\end{equation}
\revi{simpleScen2_1}{where $p(d_0| d_0 \in \mathcal{A}_0)$ is the \ac{pdf} of the \ac{ue} transmitting from distance $d_0$ inside the \ac{roi}. Assuming that \ac{ue} position is uniformly distributed in $\mathcal{A}$, and letting $\Delta_0 = R_{\rm in}^2-R_{\rm min}^2$ and $\Delta_1= R_{\rm out}^2-R_{\rm in}^2$, we have $p(d_0| d_0 \in \mathcal{A}_0) = \frac{2 d_0}{\Delta_0}$ for $d_0 \in [R_{\rm min}, R_{\rm in}]$, and $p(d_0| d_0 \in \mathcal{A}_0) = 0$ otherwise.}
\revi{simpleScen2_2}{A similar expression holds for $p(d_0|d_0 \in \mathcal{A}_1)$.}Closed-form expressions of the  \ac{llr} in the two scenarios are derived in Appendix \ref{sec:llrDer}.

\revi{llrComp}{We can see that obtaining \acp{llr} needs the computation of various integrals evein in this simple case. Therefore, in general (e.g., with either multiple \acp{ap} or correlated shadowing/fading), the \ac{llr} can not be computed in closed-form, thus making  \ac{np} test problematic.}

\subsection{Estimated Distance Approach} \label{seccomp}
\revi{literature_1}{We will compare our \ac{irlv} solutions with the \ac{eda} of {\cite{li2010security}}. In \ac{eda}, first the estimate $\hat{L}(\bm{x}_{\rm UD},\bm{x}^{n}_{\rm AP})$ of the \ac{ue}-\ac{ap} distance is obtained by inverting the path-loss formula, and then the \ac{ue} position is estimated as 
}
\begin{align}
 \hat{\bm x}_{\rm UD} =  \underset{\bm x}{\arg \min} \sum_{n=1}^{N_{\rm AP}} \left(L(\bm{x},\bm{x}_{\rm AP}^{(n)}) - \hat{L}(\bm{x}_{\rm UD},\bm{x}_{\rm AP}^{(n)}) \right)^2.
 \label{probmindist}
\end{align}
\revi{literature_2}{Let $\mathcal B_0$ be the set of points of the border of $\mathcal A_0$, and let the estimated distance of the \ac{ue} from the  border $\mathcal{B}_0$ $d_{\mathcal B} = \min_{\bm{x} \in \mathcal{B}_0} \pm||\hat{\bm x}_{\rm UD} - \bm{x}||$,  where the sign is negative if $\hat{\bm x}_{\rm UD} \in \mathcal A_0$, and positive otherwise. Lastly, $d_{\mathcal B}$ is compared with a suitable threshold $d_\delta$, chosen in order to achieve a desired FA probability, resulitng in $\hat{\mathcal{H}}_{\rm MMSE} = \mathcal{H}_0, \quad \text{if } d_{\mathcal B} < d_\delta$, $\hat{\mathcal{H}}_{\rm MMSE} = \mathcal{H}_1$, otherwise.} \revi{literature_3}{Note that this approach requires the knowledge of the path-loss model (including knowledge of LOS and non-LOS state), which is quite unrealistic. Moreover, the estimator (\ref{probmindist}) is not optimal, since the position error is usually not a Gaussian variable.}



\section{\Ac{irlv} by Machine Learning Approaches}\label{sec:irlvML}

The application of the \ac{np} theorem requires the knowledge of the conditional \acp{pdf} $p(\bm{a}|\mathcal{H}_i)$ at the \acp{ap}, which can be hard to obtain also because a-priori assumptions on them may be quite unrealistic. \revi{supervised}{Therefore, we propose to use a \emph{supervised} \ac{ml} approach} operating in two phases:
\begin{itemize}
    \item {\em Learning phase}: the \acp{ap} collect attenuation vectors from a trusted \ac{ue} moving both inside and outside the \ac{roi}, while the \ac{ue} reports its position to the \acp{ap}. In this way, the \acp{ap} can learn the behaviour of the attenuation in both regions $\mathcal A_0$ and $\mathcal A_1$.
    \item {\em Exploitation phase}: the \acp{ap} verify the location of an un-trusted \ac{ue} by the attenuation's estimate, using the data acquired in the learning phase. 
\end{itemize}

The learning phase works as follows: for each training attenuation vector $\ai$,  $i=1, \ldots, S$, collected during the learning phase, there is an associated label $t_i$, $i=1, \ldots, S$, where $t_i= -1$ if the trusted \ac{ue} is in region $\mathcal{A}_0$, and $t_i = 1$ if the trusted \ac{ue} is in region $\mathcal{A}_1$. Vector $\bm{t}=[t_1, \ldots, t_S]$ collects the labels of all the  attenuation vectors in the training phase. Given these data, the \ac{ap} learns the function  $\hat{t} = f(\bm{a})\in \{-1, 1\}$ that provides the decision $\hat{\mathcal H}$ for each attenuation vector $\bm{a}$. Then, in the exploitation phase, the \ac{irlv} algorithm computes $\hat{t} = f(\bm{a})$ for a new attenuation vector and takes the decision between the two hypotheses. Note that our solution does not explicitly evaluate the \ac{pdf} and the \ac{llr}, but rather directly implements the test function.

\revi{framework2}{We stress the fact that the channel model of Section~\ref{sec:chMod} provides a realistic communication scenario, while the analysis that follows is general, as no specific channel statistics are assumed.}

In the rest of this Section, we briefly review the \ac{mlp} \ac{nn} and the \ac{svm}, describe the learning process and show that in asymptotic conditions (infinite training attenuation vectors, sufficiently complex models, and proper learning phase convergence) both \ac{mlp} and \ac{svm} functions approximate the \ac{llr} function (\ref{eq:lr}).
  
\subsection{Neural Networks}\label{sec:nn}

A \ac{nn} is a $\mathbb{R}^N \to \mathbb{R}^O$ function mapping a set of $N$ real values into $O$ real values. A \ac{nn} processes the input in $Q$ stages, named layers, where the output of one layer is the input of the next layer. Layer $0$ with (column vector) input $\bm{y}^{(0)}$ is denoted as {\em input layer}, layer $Q-1$ with (column vector) output $\bm{y}^{(Q)}$ is denoted as {\em output layer}, while intermediate layers are denoted as {\em hidden layers}. \underline{We denote as $N_L$ the number of hidden layers}.
%
Each layer $\ell=0, \ldots, Q-1$, has $N^{(\ell)}$ outputs obtained by processing the inputs with $N^{(\ell-1)}$ functions named neurons. The output of the $n^{\rm th}$ neuron of layer $\ell$ is
$
y_n^{(\ell+1)} = \psi^{(\ell)}\left( \bm{w}_n^{(\ell)}\bm{y}^{(\ell)}+b_n^{(\ell)} \right)$,
where the mapping between the input and the outputs is given by the {\em activation function} $\psi^{(\ell)}(\cdot)$. The argument of the activation function is a weighted linear combination, with (row vector) weights $\bm{w}_n^{(\ell)}$, of the outputs $\bm{y}^{(\ell)}$ of the previous layer plus a bias $b_n^{(\ell)}$. We focus here on feedforward \acp{nn}, i.e., without loops between neurons' input and output, an architecture also known as \ac{mlp}. For an in-depth description of \acp{nn} refer for example to \underline{\cite[Chapter 6]{goodfellow}}.\revi{hyper1}{Activation functions are typically chosen before training, while vectors $\bm{w}_n^{(\ell)}$ are adapted according to the \ac{nn} learning algorithm in order to minimize the loss function.}

In our setting, the input of the \ac{nn} is the attenuation vector $\bm{a}$, $N=N_{\rm AP}$, and the output layer has a single neuron ($O=1$) providing as output the scalar $y^{(Q)}_1$. Let $\tilde{t}(\bm{a}) = y^{(Q)}_1$ be the output of the \ac{nn} corresponding to the attenuation vector input $\bm{a}$. A threshold $\lambda$ is used on the \ac{nn} output to obtain the test function
\begin{equation}
\label{testfunNN}
    f(\bm{a}) = \begin{cases}
    1 & \tilde{t}(\bm{a}) > \lambda, \\
    -1 & \tilde{t}(\bm{a}) \leq \lambda.
    \end{cases}
\end{equation}

\revi{lambdaNN}{Parameter $\lambda$ shall be chosen in order to obtain the required \ac{fa} probability. The value of $\lambda$ which guarantees a certain \ac{fa} probability can obtained by simulation, whereas it can not be obtained by inverting the \ac{fa} probability function. This is due to the fact that the \ac{ml} framework is applied when there is no knowledge of the distribution of the variables and hence we can not compute a closed-form expression of the \ac{fa} probability}\footnote{Notice that usually, for zero-one loss function, literature assumes $\lambda = 0.5$. However, this choice does not provide control of neither \acp{fa}, or \ac{md} probabilities.}.

\revi{ceNeeded}{Based on the loss function to be optimized during training \acp{nn} can solve different problems, and we consider here two widely used loss functions: \ac{mse} and \ac{ce}. }

\subsection{\ac{nn} MSE Design}
\label{sec: mse_train}
\revi{ceNeeded2}{As optimal hypothesis testing is implemented via the \ac{np} framework, which exploits the knowledge of the \ac{llr} function, we aim at learning this function from data. This problem is referred to as \emph{curve fitting} and it can be solved by training a \ac{nn} via the \ac{mse} loss function \cite{bishop92}.}
According to the \ac{mse} design criterion, the \ac{mlp} parameters are updated in the training phase in order to minimize the \ac{mse} \cite{bishop92}
\begin{equation}\label{eq:mseFunct}
\Gamma = \sum_{i=1}^S |\tilde{t}(\ai) - t_i|^2.
\end{equation}
This is achieved by using the stochastic gradient descent algorithm \underline{\cite[Section~3.1.3]{Bishop2006}}.

In order to prove the connection of \ac{nn} classifier with \ac{mse} design with the \ac{np} test, we first recall the following theorem \cite{Ruck-90}

\begin{theorem}[see \cite{Ruck-90}]
Let $g_0(\bm{a})$ be the Bayes optimal discriminant function
\begin{equation}\label{eq:bayesDisc}
g_0(\bm{a}) = \mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a}) - \mathbb{P}(\mathcal{H}=\mathcal{H}_1|\bm{a}).
\end{equation} 
Then the \ac{mlp} trained by backpropagation via (\ref{eq:mseFunct}) minimizes the error
$\sum_{i=1}^S \left(\tilde{t}(\bm{a}^{(i)}) - g_0(\bm{a}^{(i)})\right)^2$.
\label{teoruck}
\end{theorem}
\revi{teoruck2}{Hence, Theorem \ref{teoruck} proves that in the presence of i) perfect training, ii) an infinite number of neurons, and iii) convergence of the learning algorithm to the minimum error, the function implemented by \ac{mlp} is the Bayes optimal discriminant function. Now we have the following corollary.}
\begin{corollary}
\label{th:nn_np}
Consider an \ac{mlp} with training converged to the global minimum of the \ac{mse}, by using an infinite number of training points  ($S \rightarrow \infty$). Then the test function (\ref{testfunNN}) provides the \ac{np} test, thus it is the most powerful test.
\end{corollary}
\begin{proof}
From the Bayes rule we have 
\begin{equation}
g_0(\bm{a}) = \frac{p(\bm{a}|\mathcal H_0){\mathbb P}(\mathcal{H}=\mathcal H_0) - p(\bm{a}|\mathcal H_1){\mathbb P}(\mathcal{H}=\mathcal H_1)}{p(\bm{a}|\mathcal H_0){\mathbb P}(\mathcal{H}=\mathcal H_0) + p(\bm{a}|\mathcal H_1){\mathbb P}(\mathcal{H}=\mathcal H_1)}.
\end{equation}
Now, function (\ref{testfunNN}) imposes a threshold $\lambda$ on $g_0(\bm{a})$ and reorganizing terms we obtain $f(\bm{a}) = -1$ when
\begin{equation}
\frac{p(\bm{a}|\mathcal H_0)}{p(\bm{a}|\mathcal H_1)}> \frac{1 + \lambda}{1-\lambda} \, \frac{{\mathbb P}(\mathcal{H}=\mathcal H_1)}{{\mathbb P}(\mathcal{H}=\mathcal H_0)}  = \lambda^*,
\end{equation}
which is equivalent to the \ac{np} criterion, except for a fixed scaling of the threshold.
\end{proof}
\revi{rev11b}{Note that this result is quite general and can be applied to NNs with any number of layers and neurons, and any parameter adaptation approach, as long as the target design function is the MSE. Thus, Corollary 1 is suited also to describe the asymptotic behaviour of elaborate solutions, such as deep learning NNs.}

\subsection{\ac{nn} CE Design}
\label{sec: ce_train}

\revi{ceNeeded3}{Binary classification aims at assigning labels $0$ or $1$ to input vectors. In this case, the usual choice for the loss function is the \ac{ce} between the \ac{nn} output and the true labels of the input vector }\underline{\cite[Chapter~5.2]{Bishop2006}}
\begin{equation}\label{eq:ce}
\chi = -\sum_{i=1}^{S} t_i\ln\tilde{t}(\ai)+(1-t_i)\ln( 1-\tilde{t}(\ai)).
\end{equation}

We now prove the connection of \ac{ce} design criterion with the \ac{np} theorem.
\begin{theorem}
\label{th:nn_np2}
Consider an \ac{mlp} with training converged to the global minimum of the \ac{ce}, by using an infinite number of training points  ($S \rightarrow \infty$). Then the test function (\ref{testfunNN}) provides the \ac{np} test, thus it is the most powerful test.
\end{theorem}
\begin{proof}
The probability of being in hypothesis $\mathcal{H}_1$ given the attenuation vector $\bm{a}$ satisfies
$
    \mathbb{P}(\mathcal{H} = \mathcal{H}_1|\bm{a} ) = 1- \mathbb{P}(\mathcal{H} = \mathcal{H}_0|\bm{a} ).
$
When training is performed with the \ac{ce} loss function, the output of the \ac{mlp} is the minimum \ac{mse} approximation of the probability $\mathbb{P}(\mathcal{H}_0|\bm{a})$ of being in hypothesis $\mathcal{H}_0$, given the attenuation vector $\bm{a}$ \underline{\cite[Section~5.2]{Bishop2006}}, i.e.,
$
    \tilde{t}(\bm{a}) \approx \mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a})\,,
$
where the approximation is in the \ac{mse} sense. \uline{An alternative proof of this is given by \cite{nostro}.}

Now, by using the threshold function (\ref{testfunNN}), we have $
    \mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a}) \approx  \tilde{t}(\bm{a}) > \lambda,
$ which can be rewritten as (with $\hat{\lambda}=2\lambda-1)$
% \begin{equation}
%     2\mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a} )-1 \gtrsim \hat{\lambda}
% \end{equation}
\begin{equation}
    \mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a} )-(1-\mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a} )) \gtrsim \hat{\lambda}
\end{equation}
\begin{equation}
\label{lasteq}
    \mathbb{P}(\mathcal{H}=\mathcal{H}_0|\bm{a} )-\mathbb{P}(\mathcal{H}=\mathcal{H}_1|\bm{a} ) \gtrsim \hat{\lambda}.
\end{equation}
By using (\ref{testfunNN}) on the output of the \ac{nn} designed with the \ac{ce} criterion, under the convergence hypothesis, (\ref{lasteq}) coincides (except for a different threshold value) with (\ref{eq:bayesDisc}), the function implemented by the \ac{nn} trained with the \ac{mse} criterion. Therefore, from Corollary~1 we conclude that also the \ac{ce} design criterion provides a test function equivalent the \ac{np} test function.
\end{proof}

\subsection{Support Vector Machines}\label{sec:svm}

A \ac{svm} \underline{\cite[Chapter~7]{Bishop2006}} is a supervised learning model that can be used for classification and regression. We focus here on binary classification to solve the \ac{irlv} problem. The \ac{svm} implements the $\tilde{t}(\bm{a}): \mathbb{R}^{N_{\rm AP}} \to \mathbb{R}$  function 
\begin{equation}
\label{eq:svm}
\tilde{t}(\bm{a}) = \bm{w}^T \phi (\bm{a}) + b,
\end{equation}
where $\phi: \mathbb{R}^{N_{\rm AP}} \to \mathbb{R}^K$ is a feature-space transformation function, $\bm{w} \in \mathbb{R}^K$ is the weight column vector and $b$ is a bias parameter. The test function is again provided by (\ref{testfunNN}), where now $\tilde{t}(\bm{a})$ is given by (\ref{eq:svm}). Note that in the conventional \ac{svm} formulation, we have $\lambda = 0$, while here $\lambda$ is chosen according to the desired \ac{fa} probability. \revi{hyper2}{While the feature-space transformation function is chosen before training \mbox{\cite[Chapter~7]{Bishop2006}}, vector $\bm{w}$ must be properly learned from the data to obtain the desired hypothesis testing.}

We consider the \ac{lssvm} approach \cite{Suykens1999} for the optimization of the \ac{svm} parameters.  Learning for \ac{lssvm} is performed by solving the following optimization problem
\begin{subequations}
	\label{eq:lssvm}
	\begin{equation}
	\label{eq:lssvmOrig}
	\underset{\bm{w},b }{\text{min}} \quad \omega(\bm{w},b) \triangleq \frac{1}{2} \bm{w}^T \bm{w} + C \frac{1}{2} \sum_{i=1}^S e_i ^2 
	\end{equation}
	\begin{equation}
	\label{eq:stpart}
	e_i =   t_i[\bm{w}^T \phi (\bm{a}^{(i)}) + b]-1   \quad i = 1 ,\dots,S\,,
	\end{equation}
\end{subequations}
\revi{hyper3}{where $C$ is not optimized by the learning algorithm, but must be tuned on training data using a separate procedure, e.g., see \cite{guo2008novel}.}
In conventional \ac{svm}, variables $e_i$, $i=1,\ldots,S$, are constrained to be non-negative and appear in the objective function without squaring. Inequalities in the constraints translate into a quadratic programming problem, while equalities constraints in \ac{lssvm} yield a linear system of equations in the optimization values. In \cite{Yevs}, it is shown that \ac{svm} and \ac{lssvm} are equivalent under mild conditions. From  constraints  \eqref{eq:lssvm} and the fact that $t_i = \pm 1$ we have
\begin{equation}
\label{eq:els}
e_i^2 = (1 - t_i\tilde{t}(\bm{a}^{(i)}) )^2 = (t_i - \tilde{t}(\bm{a}^{(i)}))^2,
\end{equation}
that is the squared error between the soft output of the \ac{lssvm} $\tilde{t}(\bm{a}^{(i)})$ and the correct training label $t_i$.

We now prove the equivalence between the \ac{lssvm} and \ac{np} classifiers. Let us first consider the following lemma that establishes the convergence of the learning phase of \ac{svm}, as $S\rightarrow \infty$.

\begin{lemma}
	\label{lem:lem1}
	For a large number of training samples $\bm{a}^{(i)}$ taken with a given static probability distribution from a finite alphabet $\mathcal C$, i.e., for $S \rightarrow \infty$, the vector $\bm{w}$ of the \ac{lssvm} converges in probability to a vector of finite norm $||\bm{w}||_2 = \bm{w}^T\bm{w}$.
\end{lemma}

\begin{proof}
See the Appendix \ref{sec:proofTh3}.
\end{proof}
 
We can now prove the following theorem establishing the optimality of the \ac{svm} solution, as it provides the most powerful \ac{np} test for a given \ac{fa} probability.
\begin{theorem}
	\label{th:lsnp}
	\revi{revGO}{Consider a \ac{lssvm} with training converged to the global minimum of $\omega(\bm{w},b)$ and using an infinite number of training points $\bm{a}^{(i)}$ drawn from the finite alphabet $\mathcal C$.} Then the test function (\ref{eq:svm}) provides the \ac{np} test, thus it is the most powerful test.
\end{theorem}
\begin{proof}
	From \eqref{eq:lssvmOrig} consider
	\begin{equation}
	\label{eq:lssvmDim1}
	\lim_{S \to +\infty} \frac{1}{S} \omega(\bm{w},b) =\frac{C}{2} \lim_{S \to +\infty}\frac{1}{S}  \sum_{i=1}^S e^2_i	=\frac{C}{2}\E_t(\bm{w},b),
	\end{equation}
	where $\E_t(\bm{w},b) = \Exp{\epsilon_i^2} $ is the expected value computed \wrt the training points $\bm{a}^{(i)}$, as $S$ goes to infinity. 	The first equality in \eqref{eq:lssvmDim1} comes from Lemma 1: since $\bm{w}$ converges to a finite norm, we can write
$
	\lim_{S\to \infty} \frac{1}{S} \bm{w}^T \bm{w} 	= 0.
$
	The last equality comes from the strong law of large numbers. In the limit, the optimization problem \eqref{eq:lssvm} is equivalent to
	\begin{equation}
	\label{eq:lsInf}
	\begin{aligned}
	& \underset{\bm{w},b}{\text{min}} & &  \E_t(\bm{w},b), & 
	\end{aligned}	
	\end{equation}
	where we dropped constraints  \eqref{eq:lssvm} by using \eqref{eq:els}. The optimization problem is the same as of \ac{nn} design and from \cite{Ruck-90}, with the pair $(\bm{w}^*,b^*)$ minimizing \eqref{eq:lsInf} and parametrizing \eqref{eq:svm}, we have
$
	\tilde{t}(\bm{a}^{(i)})  \approx \mathbb{P}(\mathcal{H}_0|\bm{a}^{(i)}) - \mathbb{P}(\mathcal{H}_1|\bm{a}^{(i)}).
$
	Lastly, we exploit Corollary \ref{th:nn_np} to conclude the \ac{np}-optimality of \ac{ls}-\ac{svm}.
\end{proof}

In summary, we have proven that both \ac{nn} (with \ac{ce} and \ac{mse} design) and \ac{svm} (with \ac{ls} design) converge to the \ac{np} test function as the training set size $S$ goes to infinity, thus establishing their asymptotic optimality and their relation to the theory of most powerful hypothesis testing. 


\subsection{Computational Costs of \ac{ml} Approaches}
\label{sec:comp}
\revi{comp1}{In this section, we briefly review the computational cost for i) training each machine and ii) making a prediction on a new data point. Let $\eta$ be the number of epochs (how many times each training point is used) of a \ac{nn}.}

\revi{comp2}{For a basic fully connected feed-forward \ac{nn}, the backpropagation training algorithm is $\mathcal O(\eta \cdot S \cdot N_L \cdot N_{\rm AP}^3)$ when the number of neurons of each hidden layer is proportional to the input size, while the prediction of a new unseen data point is $\mathcal O(N_L \cdot N_{\rm AP}^3)$. For a more detailed analysis, which takes into account also the cost of the choice of the  activation function, see {\cite{Bianchini2014}}.}

\revi{comp3}{For a \ac{lssvm}, the estimate of the vector $\bm{w}$ at training time is found by solving a linear set of equations (instead of the traditional quadratic programming of \ac{svm}). In general, the computational cost is $\mathcal O(S^3)$; however, there are more efficient solutions that reduce this complexity to $\mathcal O(S^2)$ (see \cite{vanGestel2004}). At test time, the prediction is linear in the number of features and the number of training points, \ie $\mathcal O(N_{\rm AP} \cdot S)$.} %Indeed, more efficient online training algorithms are available {\cite{BordesEtAl2005}}.}

%It is common practice in the literature \cite{Bishop2006,Suykens1999} to work with the dual formulation of the optimization problems \eqref{eq:svmS} to \eqref{eq:lssvm} by constructing the Lagrangian. 
%In the dual formulation objective functions and constraints are expressed as functions of the kernel 
%\begin{equation}
%	\psi(\bm{r}_i,\bm{r}_j) = \phi (\bm{r}_i)^T \phi(\bm{r}_j),	
%\end{equation}
%without explicitly defining the function $\phi(\cdot)$. 
%The output of $\phi(\cdot)$ can now be of infinite dimension, like with the radial kernel family
%\begin{equation}
%	\psi(\bm{r}_i,\bm{r}_j; \sigma) = \exp \left( \frac{|| \bm{r}_i - \bm{r}_j ||^2}{2\sigma^2} \right).
%\end{equation}
%In this case, Theorem \ref{th:lsnp} holds only if
%\begin{equation}
%	\lim_{S \to +\infty} \frac{1}{S} \bm{w}^T \bm{w} < +\infty.	
%\end{equation} 
%However, if we let $C \to +\infty$ in \eqref{eq:lssvm}

\section{\ac{irlv} By One-class Classification}
\label{sec:OneClass}
 

\revi{revOC}{In practice, collecting training points from region ${\mathcal A}_1$ may be difficult, since this region may be large and not necessarily well defined (being simply the complement of $\mathcal A_0$).} \revi{oneClass}{Therefore, during the training phase, we collect only from inside $\mathcal{A}_0$ attenuation vectors that are used to train a \ac{ml} classifier to distinguish between vectors belonging to $\mathcal{A}_0$ and $\mathcal{A}_1$ in the testing phase.} This problem can also be denoted as one-class classification, since we have only samples taken from one of the two classes of the problem at training. 

In the following, we address the problem of  one-class classification  implemented via both \ac{nn} and \ac{svm}. Two approaches are considered: the \ac{ae}, using a \ac{nn}, and the \ac{oclssvm}.

Before proceeding, we consider the optimal approach when only the channel statistics from within $\mathcal A_0$ are known a-priori. In this case the \ac{llr} \eqref{eq:lr} can not be used as discriminant function, as $p(\bm{a}|\mathcal{H}_1)$ is not known. We can instead resort to the \ac{glrt} \cite{Kay-book}, which, although in general sub-optimal, is a meaningful generalization of the \ac{np} test, providing the test function 
\begin{equation}\label{eq:GLRT}
f^*(\bm{a}) =
\begin{cases}
-1 &\text{if } p(\bm{a}|\mathcal{H}_0) \geq \Lambda \\
1 & \text{if } p(\bm{a}|\mathcal{H}_0) < \Lambda.
\end{cases}
\end{equation} 

\subsection{Auto Encoder \ac{nn}}
\label{sec:auto}

\revi{deep ae}{We consider the \ac{ae} \protect{\cite{Hinton-2006}}, i.e., a \ac{nn} trained to copy the input to the output. It comprises an encoder NN (with $N_e$ layers), which transforms the $N$-dimensional input data into the $M$-dimensional code, with $M<N$, and a decoder NN (with $N_d$ layers), which reconstructs the original high-dimensional data from the low-dimensional code. For an in-depth description of the \ac{ae} architecture, please refer to \protect{\cite[Chapter 14]{goodfellow}}. 
%An example of \ac{ae} architecture is shown in Fig. \ref{fig:aeArch}. Note that not all neurons are connected to each other (i.e., we do not have a fully connected \ac{nn}), in order to reduce complexity. Indeed, it has been shown that with many locally correlated inputs, it is useful to provide only local connections on parts of the input for a faster and more accurate convergence.
When implementing \acp{ae}, it is convenient to use linear activation functions at the last hidden layer of the decoder \protect{\cite[Chapter 14]{goodfellow}}.} Note that the \ac{ae} output is a vector of the same size of the \ac{ae} input, and one-class classification is obtained by computing the reconstruction error between the input and the output of the \ac{ae} and comparing its absolute value with a chosen threshold.

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.5\columnwidth]{AE.jpg}
%     \caption{Example of \ac{ae} architecture with $5$ input (and output) values and 3 hidden layers.} 
%     \label{fig:aeArch}
% \end{figure}

For our \ac{irlv} problem, we train the \ac{ae} with attenuation vectors $\bm{a}^{(i)}$ taken only when the trusted \ac{ue} is in  \ac{roi} $\mathcal A_0$. Then, by letting $\bm{y}^{(Q)}(\bm a)$ be the output vector of the \ac{ae} for the attenuation input $\bm{a}$, the \ac{mse} is 
\begin{equation}\label{eq: rec err}
    \Gamma^{(AE)} = \frac{1}{N}\sum_{n=1}^{N}|a_n-y^{(Q)}_n(\bm{a})|^2.
\end{equation}
Finally, the \ac{irlv} test function  is  
\begin{equation}
f(\bm{a}) =
\begin{cases}
1 &\text{if } \Gamma^{(AE)} \geq \lambda^{(\rm AE)}, \\
-1 & \text{if } \Gamma^{(AE)} < \lambda^{(\rm AE)},
\end{cases}
\end{equation}
where again $\lambda^{(\rm AE)}$ must be chosen to achieve a desired \ac{fa} probability.

\revi{mseThresholding}{As the \ac{ae} attempts to copy the input to its output, in the testing phase only vectors with features similar to those of the training set will be reconstructed with smaller \ac{mse}, whereas input vectors with different features will be mapped to different vectors at the output, with large \ac{mse}. Since training is based on vectors collected from area $\mathcal{A}_0$ and we want to verify users located inside $\mathcal{A}_0$, by thresholding the \ac{mse}, we can obtain the desired classifier.}

About the test power of the \ac{ae}, we observe that it can be seen as the quantizer (or compression process) of an $N$-dimensional signal into an $M$-dimensional signal. In order to minimize the \ac{mse} of the reconstruction error, inputs with higher probability will have smaller quantization regions. Moreover, as the number of quantization points goes to infinity (since the quantization indices are in the continuous $M$-dimensional space) all points in the same quantization region will have approximately the same probability. However, the quantization error for points within each region will be different for each point; in particular, equal to zero for the quantization point and greater than zero at the edges of the quantization region. Thus, we can conclude that the \ac{ae} can not provide as output the \ac{pdf} of the input, even with infinite training and an infinite number of neurons, as required by the \ac{glrt} decision rule (\ref{eq:GLRT}). On the other hand, input points with a smaller \ac{pdf} belong to larger quantization regions for which the reconstruction error is {\em on average} larger; therefore, the output provided by the \ac{ae} is on average monotonically decreasing with the \ac{pdf} of the input point. 

\begin{comment}
The performance of the obtained classifier are given by the following 
\begin{theorem}
    Consider a \ac{ae} with perfect training, i.e., a \ac{ae} with a sufficient number of neurons and a sufficient training. Then the classifier obtained by training the \ac{ae} and by thresholding the soft output $\tilde{\epsilon}(\bm{a}^{(n)}) = \sqrt{\frac{1}{N}\sum_{i=1}^{N}|a^{(n)}_i-\hat{a}^{(n)}_i|^2}$ is equivalent, in the \ac{mse} sense, to the optimal classifier \eqref{eq:oneClassDec}.
\end{theorem}
\begin{proof}
Let us consider the \ac{mse} approximation of $\tilde{\epsilon}(\bm{a}^{(n)})$ being $1/p(\bm{a}^{(n)}|\mathcal{H}_0)$ and hence consider the minimization problem over the weight vector $\bm{w}$
\begin{equation}
	\begin{aligned}
		&\underset{\bm{w}}{\text{min}}\,\, \Exp{ \left( \tilde{\epsilon}(\bm{a},\bm{w}) - \frac{1}{p(\bm{a}|\mathcal{H}_0)}\right) ^2} = \\
		&\underset{\bm{w}}{\text{min}} \int_{\bm{a} \in \mathbb{R}^n} \left[ \tilde{\epsilon}(\bm{a},\bm{w}) - \frac{1}{p(\bm{a}|\mathcal{H}_0)} \right] ^2 p(\bm{a}|\mathcal{H}_0) d\bm{a} = \\
		&\underset{\bm{w}}{\text{min}} \left\lbrace \int_{\bm{a} \in \mathbb{R}^n} \tilde{\epsilon}(\bm{a},\bm{w})^2 p(\bm{a}|\mathcal{H}_0) d\bm{a}
		-2\int_{\bm{a} \in \mathbb{R}^n} \tilde{\epsilon}(\bm{a},\bm{w}) d\bm{a}
		+ \int_{\bm{a} \in \mathbb{R}^n} \frac{1}{p(\bm{a}|\mathcal{H}_0)} d\bm{a} \right\rbrace.
	\end{aligned}	
\end{equation}
We notice that the second term in brackets is the sum of the reconstruction error of the attenuation vectors over $\mathbb{R}^{n}$. Since different regions of $\mathbb{R}^n$ are characterized by different features and since the \ac{ae} is able to reconstruct, with small reconstruction error, only those vectors with features similar to those of the training set we can assume that the summation of the reconstruction errors over all possible feature spaces goes to infinity. The second integral does not hence depend on $\bm{w}$ as for each value of $\bm{w}$ it goes to infinity. The last term in brackets does not depend on the weight vector $\bm{w}$ and hence the only term that depends on $\bm{w}$ is the first one, which is the objective function of the training optimization problem. Noticing that thresholding $\frac{1}{p(\bm{a}|\mathcal{H}_0)}$ with $\gamma$ is equivalent to thresholding $p(\bm{a}|\mathcal{H}_0)$ with $1/\gamma$ we conclude that training the \ac{ae} with $\epsilon$ loss function provides a classifier that approximates in the \ac{mse} sense the optimal one (\ref{eq:oneClassDec}).
\end{proof}
\end{comment}

\subsection{One-Class LS-SVM}

We can also resort to \ac{svm} to perform the one-class classification in \ac{irlv}: we focus in particular on the  \ac{oclssvm}, first introduced in \cite{choi2009} as an extension of the one-class \ac{svm} \cite{Scholkopf2001estimating}. 
The only difference with respect to the \ac{svm} introduced in Section~III is that the training optimization problem is now
\begin{subequations}
	\label{eq:oneClassSvm}
	\begin{equation}
	\label{eq:oneClass1}
	\underset{\bm{w},b}{\min} \quad \omega(\bm{w}, b) \triangleq
	 \frac{1}{2} \bm{w}^T \bm{w} +  \frac{C}{2} \sum_{i=1}^S e_i^2 +b
	\end{equation}
	\begin{equation}
	\label{eq:oneClassConstr}
	\text{subject to}\, -b - \bm{w}^T \phi (\bm{a}^{(i)})  = e_i,  \quad i = 1,\dots S.
	\end{equation}
\end{subequations}
Note that in the one-class case, the bias parameter $b$ appears also in the objective function.


\uline{We observe that also for \ac{oclssvm} we can not establish a correspondence with \ac{glrt}.} Nevertheless, by resorting to the Chernoff bound, we can conclude that by minimizing the \ac{mse} we also minimize the upper bound of the \ac{fa} probability; therefore, the optimization process goes in the right direction although being not optimal.



\begin{comment}
We want to show that the \ac{oclssvm} is a machine that asymptotically approximate, in the mean-square sense, the optimal decision rule \eqref{eq:oneClassDec}.

\begin{lemma}
\label{lem:lem2}
Given $S$ training samples $\bm{a}^{(i)}$ from a finite alphabet $\mathcal C$, taken with a given static probability distribution, for large number of training samples, i.e., as $S \rightarrow \infty$, problem \eqref{eq:oneClassSvm} is equivalent to 
\begin{equation}
		\underset{\bm{w},e_i, \rho}{\text{min}} \Exp{e_i}^2
\end{equation}
\end{lemma}
\begin{proof}
We first proceed as in the proof of Theorem \ref{th:lsnp} and re-write problem \eqref{eq:oneClassSvm} as
	\begin{subequations}
		\label{eq:oclssvm22}
		\begin{equation}
		\label{eq:oclssvm2}
		\underset{\bm{w},e}{\text{min}} \quad f_0' = \frac{1}{2} \bm{w}^T \bm{w} + C S \frac{1}{2} \sum_{j=1}^M p_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,1) e_j^2 - \rho  
		\end{equation}
		\begin{equation}
		\label{eq:ocstpart2}
		\text{subject to}\,  \rho - \bm{w}^T \phi (\bm{a}^{(i)})  = e_i,  \quad i = 1,\dots M, 
		\end{equation}		
	\end{subequations} 
Note that differently from \eqref{eq:lssvm22} we have only $M$ constraints (and not $2M$) because we have target labels only of one class.
We now solve \eqref{eq:oclssvm22} using the same steps as in \cite{choi2009least}. Let us define the Lagrangian
\begin{equation}
	\mathcal{L} = 	\frac{1}{2} \bm{w}^T \bm{w} - \rho +
	C S \frac{1}{2} \sum_{j=1}^M p_{\bm{a}^{(i)},\hat{t}_i}(\bm{\alpha}_j,1) e_j^2 - 
	\sum_{j=1}^{M} u_j \left[ \bm{w}^T \phi (\bm{a}^{(j)}) -\rho + e_j \right],
\end{equation}
and set to zero the derivatives with respect to optimization variables and multipliers $u_j$

\begin{subequations}
\begin{equation}
\label{eq:derivatives1}
\frac{\partial \mathcal{L}}{\partial \bm{w}}: \quad \bm{w} = \sum_{j=1}^{M} u_j \phi (\bm{a}^{(j)}), 		
\end{equation}
  \begin{equation}
  \label{eq:derivatives2}
  		\frac{\partial \mathcal{L}}{\partial \bm{e_j}}: \quad CS p_{\bm{a}^{(i)},\hat{t}_i}(\bm{\alpha}_j,1) e_j = u_j \quad
  		 j=1,\dots, M,
  \end{equation}
  \begin{equation}
  \label{eq:derivatives3}
  		\frac{\partial \mathcal{L}}{\partial \rho}: \quad \sum_{j=1}^{M} u_j = 1
  \end{equation}
  \begin{equation}
  \label{eq:derivatives4}
  	\frac{\partial \mathcal{L}}{\partial \bm{u_j}}:	\quad \phi (\bm{a}^{(j)}) \bm{w} + e_j - \rho = 0.
  \end{equation}
\end{subequations}
Substituting \eqref{eq:derivatives1} and \eqref{eq:derivatives2} in \eqref{eq:derivatives4} we get the system of equations
\begin{equation}
\begin{aligned}
	&\sum_{i=1}^{M}  u_i k( \bm{a}^{(i)},\bm{a}^{(j)}) - \rho + \frac{u_j}{SCp_{\bm{a}^{(i)},\hat{t}_i}(\bm{\alpha}_j,1)}=0 \quad j = 1,\dots, M\\
	&\sum_{i=1}^{M}u_i=1,
\end{aligned}	
\end{equation}
with $M+1$ unknowns and $M+1$ equations which therefore provides finite convergence values for $\{\rho,u_i\}_{i=1}^{i=M}$. In the dual formulation of \eqref{eq:oneClassSvm} we can express $\bm{w}$ as a function of the kernel and Lagrange multipliers $\{u_j\}$ 
\begin{equation}
\bm{w}^T\bm{w} = \sum_{i=1}^{M} \sum_{j=1}^{M} u_i u_j k(\bm{\alpha}_i,\bm{\alpha}_j), 
\end{equation}
which, as the sum is over a finite set of numbers, converges.
We can now write
\begin{equation}
\begin{aligned}
\lim_{S \to +\infty} &\frac{1}{S} \bm{w}^T\bm{w} =0, \\
\lim_{S \to +\infty} &\frac{1}{S}\rho =0.
\end{aligned}		
\end{equation}
It follows that
\begin{equation}
	\underset{\bm{w},e_i, \rho}{\text{min}} \frac{1}{S} f_o(\bm{w},e_i, b) = 
	\underset{\bm{w},e_i, \rho}{\text{min}} \frac{1}{S} \sum_{i=1}^S e_i^2 = 
	\underset{\bm{w},e_i, \rho}{\text{min}} \Exp{e_i}^2,	
\end{equation}
where $e_i^2 = (\bm{w}^T \phi (\bm{a}^{(i)}) -\rho)^2 $, the last equality follows from the law of large numbers, and the expected value is carried out \wrt the training $\bm{a}^{(i)}$.
\end{proof}

%Note that $|e_i|$ is proportional, by a factor $1/||\bm{w}||$, to the distance between any point $\phi(\bm{a}^{(i)})$ and the hyperplane $\bm{w}^T \phi (\bm{a}) + b = 0$ defined in the transformed space by the \ac{oclssvm}. We claim that $|e_i|$ is inversely proportional to $p(\bm{a}|\mathcal{H}_0)$ and we will prove that this holds in the mean-square sense. A direct consequence is that the \ac{oclssvm} approximates asymptotically the optimal decision rule of Section~\ref{sec:oneClassOpt}. 

\begin{theorem}
	\label{th:onelsnp}
	Consider a \ac{oclssvm} with perfect training, \ie the training reaches a global minimum of $f_o(\bm{w},e_i,b)$ given an infinite number of training points $\bm{a}^{(i)}$ drawn from the finite alphabet $\mathcal C$. Then the classifier obtained by training the \ac{oclssvm} and by thresholding the soft output \eqref{eq:svm} is equivalent, in the \ac{mse} sense, to the optimal classifier \eqref{eq:oneClassDec}.
\end{theorem}

\begin{proof}
Let $(\bm{w}^*,e_i^*, \rho^*)$ be the solution for problem \eqref{eq:oneClassSvm}. We note that $\rho^* >0$. If this was not the case, then we cold define the new triplet $(-\bm{w}^*,e_i^*, -\rho^*)$ providing a lower value for $f_o(\bm{w},e_i,\rho)$. This is because from \eqref{eq:oneClass1} the first two terms of the sum remain unchanged, while in the third term we are now subtracting a positive value, yielding
\begin{equation}
		f_o(-\bm{w}^*,e_i^*, -\rho^*) < f_o(\bm{w}^*,e_i^*, \rho^*).
\end{equation} 
Let us define the function 
\begin{equation}
	e(\bm{a},\bm{w},\rho) \triangleq \bm{w}^T  \phi (\bm{a}) - \rho,	
\end{equation}
and consider 
\begin{equation}
\label{eq:coreTheorem}
	\begin{aligned}
		&\underset{\bm{w},\rho}{\text{min}} \Exp{ \left( e(\bm{a},\bm{w},\rho) - \left(-\frac{1}{p(\bm{a}|\mathcal{H}_0)}\right)\right) ^2} = \\
		&\underset{\bm{w},\rho}{\text{min}} \int_{\mathbb{R}^n} \left[ e(\bm{a},\bm{w},b) + \frac{1}{p(\bm{a}|\mathcal{H}_0)} \right] ^2 p(\bm{a}|\mathcal{H}_0) d\bm{a} = \\
		&\underset{\bm{w},\rho}{\text{min}} \left\lbrace \int_{\mathbb{R}^n} e^2(\bm{a},\bm{w},\rho) p(\bm{a}|\mathcal{H}_0) d\bm{a}
		+2\int_{\mathbb{R}^n} e(\bm{a},\bm{w},\rho) d\bm{a}
		+ \int_{\mathbb{R}^n} \frac{1}{p(\bm{a}|\mathcal{H}_0)} d\bm{a} \right\rbrace.
	\end{aligned}	
\end{equation}
Consider the integral in the double product
\begin{equation}
		\int_{\mathbb{R}^n} e(\bm{a},\bm{w},b) d\bm{a} =
		\int_{\mathbb{R}^n} \bm{w} ^T  \phi (\bm{a})d\bm{a} - \int_{\mathbb{R}^n} \rho d\bm{a},		
\end{equation}
For what concerns the second integral in the r.h.s. we can write
\begin{equation}
		\int_{\mathbb{R}^n} \rho d\bm{a} = \rho \int_{\mathbb{R}^n} d\bm{a} = \sign(\rho) (+\infty) = + \infty,
\end{equation}
since we have shown that at the optimum $\rho^*>0$. Now, using \eqref{eq:derivatives1}, we can write the first integral as
\begin{equation}
\begin{aligned}
		&\int_{\mathbb{R}^n} e(\bm{a},\bm{w},\rho) d\bm{a} = \int_{\mathbb{R}^n} \sum_{j=1}^{M} u_j k(\bm{a}^{(j)},\bm{a})d\bm{a} \\
		&= \sum_{j=1}^{M} u_j \int_{\mathbb{R}^n} k(\bm{a}^{(j)},\bm{a})d\bm{a} = \int_{\mathbb{R}^n} k(\bm{a}^{(j)},\bm{a})d\bm{a},
\end{aligned},
\end{equation}
where we used \eqref{eq:derivatives3}.
Note that the only term in the last line of \eqref{eq:coreTheorem} that depends on the optimization variables $\{\bm{w}, \rho \}$  is 
\begin{equation}
		\Exp{  e^2(\bm{a}, \bm{w}, \rho)} = \int_{\mathbb{R}^n} e^2(\bm{a},\bm{w},\rho) p(\bm{a}|\mathcal{H}_0) d\bm{a},
\end{equation}
which, from Lemma \ref{lem:lem2} is, asymptotically, the objective function optimized by the \ac{lssvm}.
%The third term inside the curly brackets does not depend on $(\bm{w},b)$. Therefore, the mean square error approximation of $1/p(\bm{a}|\mathcal{H}_0)$ is found by minimizing $\Exp{e^2(\bm{a},\bm{w},b)}$ which, by Lemma \ref{lem:lem2}, is the same function minimized by \ac{oclssvm}. Asymptotically we have, from \eqref{eq:svm},
%\begin{equation}
%\label{eq:approx}
%	\tilde{t} \approx \frac{1}{p(\bm{a}|\mathcal{H}_0)},	
%\end{equation} 
%in the mean square sense. Note that thresholding $\frac{1}{p(\bm{a}|\mathcal{H}_0)}$ with $\gamma$ is the same as thresholding $p(\bm{a}|\mathcal{H}_0)$ with $1/\gamma$ which is the optimal classifier of Section~\ref{sec:oneClassOpt}.
\end{proof}


\subsection{\ac{ml}-Based Attack Strategies}
\label{sec:attack}
\hl{LA TOGLIAMO??}

\revi{sezattack}{Until now we have used ML to perform \ac{irlv}. Here we propose to use ML also to improve the attack strategy. In particular, we focus on an attacker that moves outside $\mathcal A_0$ and performs multiple attacks. We assume that the attacker knows if each attack is successful or not and can estimate the attenuation vector to each \ac{ap} before attacking. The attacker aims at minimizing the number of attacks before success. This can be achieved for example by exploiting training signals transmitted by the \acp{ap}. While these estimate come almost for free to the attacker, an active attack is more power consuming. Moreover, a sequence of wrong attacks could be detected by the \acp{ap} that can take suitable countermeasures, which however are outside the scope of this work. Therefore, we simply focus on the problem of doing as few attacks are possible before the first success. The proposed strategy works as follows:}
\begin{enumerate}
    \item The attacker visits $N$  points spread uniformly at random outside $\mathcal A_0$. From each point it collects the attenuation vector and performs the attack. If any of the attacks is successful, the procedure is stopped.
    \item If none of the $N$ attacks is successful, the attenuation vectors are used to train a one-class classifier.
    \item The attacker picks a new position uniformly at random outside $\mathcal A_0$ and feeds its attenuation vector to the trained classifier.
    \item A vector classified into the class it is discarded, and the procedure goes back to point 3). Otherwise, an attack is performed from the selected position.
    \item If the attack is successful, the procedure is stopped. Otherwise, the attenuation vector is used as further training input of the one-class classifier and the procedure goes back to point 3).
\end{enumerate}
\revi{sezattack2}{Note that other attack strategies are possible, including game-theoretic approaches, where the attacker and the \ac{irlv} system are confronting players. These strategies are left for future study and we concentrate on the described attack procedure as it is similar, while from the attacker perspective, to that used in \ac{irlv}.}
\end{comment}
\begin{comment}
\ac{ml} techniques can be also exploited in order to perform more effective attacks. In particular, the attacker can $a$) compute estimates of the attenuation vectors of its channel to all the \acp{ap}, and $b$) move around in the area $\mathcal A_1$ and perform attacks. Point $a$) is possible if \acp{ap} transmit training signals to the \ac{ue}, so that it can estimate the channel characteristics. We also assume that the attacker has means to determine if its attack has been successful, e.g., by receiving the services reserved to \acp{ue} in the \ac{roi}.

%Consider a training set set large enough to cover the statistical description of the non-legitimate area $\mathcal{A}_1$. The attenuation vector with the highest reconstruction error in the \ac{ae} case or with the largest value of $\tilde{t}_o$ in the \ac{oclssvm} case can be considered at the border of the region $\mathcal{A}_1$, and hence nearer to region $\mathcal{A}_0$. In the next section we describe two attack strategies exploiting this property of the \ac{ml} algorithms: the former attack is the filter attack, which exploits the one class trained \ac{ml} algorithms to select proper attack vectors; the latter is the gradient based attack, which exploits the loss function of \ac{ml} algorithms in order to forge attenuation vectors that can be considered as authentic by the \ac{irlv} system.

%\subsection{Selective \ac{ml} Attack}


%Although it is possible to perform multiple attacks, 
The purpose of the attacker is to be successful with the minimum number of attacks in order not to let the network detect to be under a series of attacks and take countermeasures (e.g., activating additional \ac{irlv} techniques or switching off the service). Moreover, a smaller number of attacks reduces the resource consumption by the attacker and provides faster access to the services. In order to make attacks more efficient, we propose that the attacker 1) moves in the \ac{roi}-complementary area $\mathcal A_1$, 2) measures the attenuation vectors at various position, and then 3) decides whether to attack or not according to its previous experience of failed attacks. We denote this attack as {\em selective \ac{ml} attack}. As soon as an attack is successful, the procedure is stopped; therefore, the data on which the attacker can use to take its decision comprises only failed attacks.

In details, the attacker uses the attenuation vectors of (failed) attacks to train a one-class classifier. Then, when reaching a new position it feeds the attenuation vector to the classifier and, if it is classified as belonging to the same class of training, no attacks is performed since the position is deemed to be useless. Otherwise, if the attenuation vector is not recognized as belonging to the class of collected points, it is evaluated as a potential successful attack and the attacker sends a message claiming to be in $\mathcal A_0$ to the network. If successful, the procedure is stopped, while upon failure the attenuation vector is fed as additional training data to the machine so that the classifier becomes more accurate.  

For the one-class classifier, we use either the \ac{ae} or the \ac{svm}, as described in the previous section. 
\end{comment}
%As before stated the one class classification involves training the \ac{ml} algorithms with attenuation vectors measured from one of the two available classes. We here propose an attack strategy which trains the \ac{ml} algorithms with attenuation vectors measured from the non-legitimate area $\mathcal{A}_1$. However, differently from a simple random attack, the attenuation vectors are \emph{filtered} by the attacker with a machine trained to learn the class of non successful points. The chosen attack point is then only the one yielding the worst metric as output of the filter. In this way we aim at minimizing the number of attempted attacks.

%In particular, consider an attenuation vector $\bm{a}_{\mathcal{A}_1}$ measured in area $\mathcal{A}_1$ This vector could be a possible successful attack and is hence tested. If the attack is not successful $\bm{a}_{\mathcal{A}_1}$ is used to train the \ac{ml} algorithm. 
%We generate $n_{\rm x}$ spatial coordinates located in area $\mathcal{A}_1$ and we measure the attenuation values incurred in each position. We then filter this set of vectors with the \ac{ml} algorithm and select as a possible attack the vector which is more likely to belong to class $\mathcal{A}_0$ (i.e., the one with highest reconstruction error for the \ac{ae} and with smallest $\tilde{t}_0$ for the \ac{oclssvm}). If the selected vector is not a successful attack then it is used to update the training of the \ac{ml} algorithm.


%
% This process is repeated until a successful attack vector is generated. The algorithm steps are shown in Algorithm \ref{alg:filter}.
%
%\begin{algorithm}[t]
%\label{alg:filter}
%  \algsetup{linenosize=\tiny}
%  \scriptsize
%
% \KwData{ $\bm{a}_{\mathcal{A}_1}$}
% \KwResult{successful attack vector }
% 
%
% \Repeat{attack is successful}{
%        \eIf{first attack}{
%        test $\bm{a}_{\mathcal{A}_1}$\;
%        \If{attack $\neq$ successful}{
%        build and train the \ac{ml} architecture with $\bm{a}_{\mathcal{A}_1}$\;
%        }
%        }
%        {
%        build set $\bm{A}$ of randomly selected attenuation vectors from $\mathcal{A}_1$\;
%        $\bm{a}_{\mathcal{A}_1} = \underset{\bm{a} \in \bm{A}}{\max} \quad \rm{loss} \, \rm{function}$ $(\bm{A})$\;
%        \If{attack $\neq$ successful}{
%       update training with $\bm{a}_{\mathcal{A}_1}$
%       }
%      }
%      }
%    
% \caption{Selective \ac{ml} attack}
%\end{algorithm}

%Note that Point $b$) is possible by letting the attacker to be equipped with multiple antennas so that, thanks to the estimates its channel to the \acp{ap}, the attacker can beamform the training signals with different gains to the \acp{ap}, thus letting them estimate the intended attenuation values. In this setting even a static \ac{ue} can generate many attacks with different estimated attenuation vectors at the \acp{ap}. 

% \subsection{Gradient-based \ac{ae} attack}
% Consider the set $\bm{A}$ of the attenuation vectors from $\mathcal{A}_1$ used for training the attacker \ac{ae}. The vector with highest reconstruction error is selected as a starting point for a possible successful attack. In order to find a direction toward which move the values of the attenuation vector to increment the probability of a successful attack, knowing that a higher reconstruction error means an higher probability of the vector belonging to the authentic area $\mathcal{A}_0$, we perform a gradient ascent algorithm based on the reconstruction error function (\ref{eq: rec err}) . 
% Starting from the attenuation vector with highest reconstruction error we perform various steps of the gradient algorithm and, for each step we exploit the forged vector as a possible attack. Considering the first attack as $\bm{a}_f^{(0)}=\underset{\bm{a} \in \bm{A}}{\max}$ the attack vector at iteration $q$ is
% \begin{equation}\label{eq: rnn attack}
%     \bm{a}_f^{(q)} = \bm{a}_f^{(q-1)}+ \delta \nabla_{\bm{a}}\epsilon(\bm{a}_f^{(q-1)}).
% \end{equation}
% The gradient ascent algorithm continues up to the point where the attack is successful or when the reconstruction error is lower then the one obtained in the previous step, i.e., $\epsilon(\bm{a}_f^{(q)}) < \bm{a}_f^{(q-1)}$. When the algorithm stops due to the second case the training of the \ac{ae} is updated with $\bm{a}_f^{(q-1)}$. The new training set is hence updated as $\bm{A} = \bm{A} \cup \bm{a}_f^{(q)}$ and the attenuation vector with highest reconstruction error obtained by the updated \ac{ae} is selected as the new starting point of the gradient algorithm. The algorithm steps are shown in Algorithm \ref{alg:rnnGrad}.

% \begin{algorithm}[t]
% \label{alg:rnnGrad}
%   \algsetup{linenosize=\tiny}
%   \scriptsize

%  \KwData{ trained \ac{ae}, training set $\bm{A}$, $\delta$}
%  \KwResult{successful attack vector }
 

%  \Repeat{attack is successful}{
%         select $\bm{a}_f^{(0)} = \underset{\bm{a} \in \bm{A}}{\max}\epsilon(\bm{a})$ \;
%         test $\bm{a}_f^{(0)}$ as attack \;
%         \If{$a_f^{(0)}$ is not successful}{
%         \Repeat{attack is successful or $\epsilon(\bm{a}_f^{(q)}) < \bm{a}_f^{(q-1)}$}
%         {
%         generate attack $\bm{a}_f^{(q)}$ via (\ref{eq: rnn attack})\;
%         perform the attack \;
    
%       }
%       \If{attack is not successful $\&$ $\epsilon(\bm{a}_f^{(q)}) < \bm{a}_f^{(q-1)}$}
%         	{$\bm{A}=\{\bm{A},\bm{a}_f^{(q)}\}$\;
%             update training of the \ac{ae} \;}
%             }
%       }
    
%  \caption{Gradient-based \ac{ae} attack}
% \end{algorithm}


% \subsection{\Acl{oclssvm} Attack}
% The attacker trains a \ac{oclssvm} with the training data coming only from the non-authentic area and his objective is now to forge an attack value $\bm{a_{f}}$ that will be accepted as authentic by the \ac{irlv} system. We propose an euristic approach  exploiting the fact that the test function for the attacker's trained \ac{oclssvm} would be
% \begin{equation}
% \bm{a} \in
% 	\begin{cases}
% 		\mathcal{A}_1 \quad \text{if} \quad \tilde{t} \geq \Lambda \\
% 		\mathcal{A}_0 \quad \text{if} \quad \tilde{t} < \Lambda.
% 	\end{cases}	
% \end{equation} 
% Moreover, from Theorem \ref{th:onelsnp} we know that the more $\tilde{t}$ decreases, the more $p(\bm{a}|\mathcal{H}_0)$ decreases as well.
% This suggests that the attacker could start from the training point $\bm{a}_{f}^{(0)}$ yielding the lowest value of $\tilde{t}$ and then moving along the direction of greatest decrease $\bm{d}$, given by
% \begin{equation}
% \label{eq:dDef}
% 	\bm{d} \triangleq - \nabla_{\bm{a}} \tilde{t},
% \end{equation} 
% where $\nabla_{\bm{a}}$ is the gradient operator \wrt $\bm{a}$. Exploiting the dual formulation \cite{choi2009least} we can write
% \begin{equation}
% \label{eq:gradient}
% 		\nabla_{\bm{a}} \tilde{t} = \sum_{j=1}^{S} u_j \nabla_{\bm{a}} k(\bm{a}_j,\bm{a}).
% \end{equation}
% Using the radial-basis kernel
% \begin{equation}
% k(\bm{a}_j,\bm{a}_i) = e^{-\frac{||\bm{a}_j-\bm{a}_i||^2}{2\sigma^2}},
% \end{equation}
% the explicit expression for the gradient in \eqref{eq:gradient} is
% \begin{equation}
% 	\nabla_{\bm{a}} \tilde{t} =\frac{1}{\sigma^2} \sum_{j=1}^{S} u_j k(\bm{a}_j,\bm{a}) (\bm{a}_j - \bm{a}).
% \end{equation}
% Next, the attacker forges the point
% \begin{equation}
% 	\bm{a}_f^{(1)} = \bm{a}_f^{(0)} + \delta \bm{d}, 	
% \end{equation}
% where $\delta$ is a parameter, and performs the attack. If it does not succeed, he re-trains the \ac{oclssvm} with this new information and repeats the attack until he eventually succeeds. This constitutes Algorithm \ref{alg:svm}.

% \begin{algorithm}[t]
% \label{alg:svm}
%   \algsetup{linenosize=\tiny}
%   \scriptsize

%  \KwData{ Training set, $\delta$}
%  \KwResult{succesful attack vector }
 

%  \Repeat{attack is succesful}{
%  		train a \ac{oclssvm} \;
%         select $\bm{a}_{f}^{(0)}$ yielding the lowest value of $\tilde{t}$ \;
%         compute $\bm{d}$ from \eqref{eq:dDef} \;
%         compute $\bm{a}_f^{(1)} = \bm{a}_f^{(0)} + \delta \bm{d}$ \;
%         perform the attack \;
%         \If{
%         	attack is not succesful}
%         	{$\bm{a}_f^{(1)}$ belongs to non-authentic area\;
%         	add $\bm{a}_f^{(1)}$ to training set\;}
%       }
    
%  \caption{One-class \ac{svm} Attack}
% \end{algorithm}


\section{Numerical Results}\label{sec:numRes}

\uline{In this section, we present the performance of the proposed \ac{irlv} methods, obtained from both experimental data and the channel models of Section~II. We consider a unitary transmitting power for each user and a carrier frequency of $f_0=2.12$~GHz, and $h_{\rm AP}^{(n)} = 15$~m for all the APs, unless differently specified. When spatial correlation of shadowing is assumed, we consider a decorrelation distance of $d_c = 75$~m according to the model of Section~II.} \uline{The training points for the classification tasks are taken uniformly over the area $\mathcal A$ ($\mathcal A_0$).}

\uline{For the \ac{lssvm} we use a Gaussian kernel function \protect{\cite[Chapter 6]{Bishop2006}}.}
\revi{activation}{For the \ac{nn} approach we use fully connected networks. For the two-class classification problem, the activation function of the input layer is the identity function, while the activation function of neurons in the  hidden and output layers is the sigmoid \protect{\cite[Section 6.2.2.2]{goodfellow}.}} \revi{numResSimplScen3}{All results for \acp{nn} have been reported only for \ac{ce} loss function, as we have shown in Corollary 1 and Theorem 2 that with both \ac{mse} and \ac{ce} loss functions we achieve the same performance of the \ac{np} test.}

\subsection{Two-class \ac{irlv} With Single \ac{ap}}\label{sec:singleAp}

We start with a \ac{irlv} system using a single \ac{ap}. 
\paragraph*{Uncorrelated fading/shadowing} \revi{numResSimplScen}{Firstly, we consider the environment of Section \ref{sec:los} describing a small area. The channel model includes  spatially uncorrelated fading or shadowing, with $R_{\rm out}= 10$~m, $R_{\rm in} = 2$~m, and $R_{\rm min} = 0.1$~m. Moreover, \ac{los} is assumed for path-loss. For uncorrelated fading, we consider two path-loss coefficients, namely  $\nu=2$ and $3$; the closed-form expression of the \acp{llr} for the \ac{np} test are given by (\ref{eq:llr1}) and (\ref{eq:llr2}). With spatially uncorrelated shadowing, we set $\nu=2$, and three values of shadowing standard deviation, namely  $\sigma_{s, {\rm dB}} = 0.1$~dB, $1.8$~dB, and 6~dB; the closed-form expression of the \acp{llr} for the \ac{np} test is given by (\ref{eq:llr3}). For the \ac{ml} approaches, we consider $S=10^5$ training points and a \ac{nn} with $N_L = 2$ hidden layers, each layer with $N^{(i)}=5$ neurons in layer $i = 1,2$.}

\begin{figure}
    \centering
    \includegraphics[width=8.5cm]{comp_NN_NP_CE.eps}
    \caption{\acs{roc} of \acp{irlv} methods for \ac{los}, uncorrelated fading/shadowing and various values of $\nu$ and $\sigma_{s, {\rm dB}}$. Environment of Section \ref{sec:los}.}
    \label{fig:ceVSnp}
\end{figure}


\revi{numResSimplScen2}{Fig. \ref{fig:ceVSnp} shows the \ac{fa} probability versus the \ac{md} probability i.e., the  \acf{roc}, obtained with the \ac{np} test,  the \ac{nn}, and \ac{lssvm} classifiers. We notice that all models achieve the same performance, confirming our theoretical results that both \ac{nn} and \ac{lssvm} with sufficient training data and number of hidden layers are optimal as \ac{np}.} \revi{numResSimplScen4}{We observe that fading has more impact on the performance than shadowing, yielding higher \ac{fa} and \ac{md} probabilities. Still, with fading, a higher path-loss coefficient provides better results, since the attenuation increases more with the distance, thus easing classification. For spatially uncorrelated shadowing, performance improves as $\sigma_{s, {\rm dB}}$ decreases, since in this case path-loss alone already provides error-free decisions, thus the shadowing component is a disturbance in the decision process.}

\paragraph*{Spatially correlated shadowing} 

\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{scenariotex.png}
    \caption{Reference environment.} 
    \label{fig:mBS}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{map.eps}
    \caption{Example of attenuation map including path-loss and shadowing, with the \ac{ap} positioned at the center.}
    \label{fig:map}
\end{figure}

\uline{We now consider the spatially correlated shadowing  ($\sigma_{s, {\rm dB}} = 8$~dB) of Section~II. The simulation environment is shown in Fig. \ref{fig:mBS}, using only $\rm AP_1$  at the street intersection (while all other \acp{ap} are not used) and a square \ac{roi} with $d_1= 50$~m, $d_2= 50$~m, and $\beta_1 = \beta_2 = 150$~m.} \revi{building}{The \ac{roi} is inside the  south-west building, modelling for example a scenario wherein privileged network resources are accessible only to users inside an office.} Along the streets, \ac{los} propagation conditions hold (with $\nu = 2$), while non-\ac{los} propagation conditions hold in the rest of the area. 
Fig. \ref{fig:map} shows a realization of the  attenuation map (including both path-loss and shadowing), highlighting the different propagation conditions. 
\uline{Since no closed-form expression of the \ac{llr} is available in this scenario, we quantize the attenuations collected in the learning phase  with a large alphabet and estimate the sampled \ac{pdf} for the quantized attenuations. Lastly, we use the estimated \ac{pdf} to compute the \acp{llr}. We use $4.46 \cdot 10^6$ training points in the area $\mathcal A$ and a uniform quantizer for the attenuation (within the observed extreme values) with $300$ quantization values. Only $10^3$ points are used for training both the \ac{mlp} and \ac{svm}.} 
 

%Consider the \ac{llr} (\ref{eq:lr}). In the non-\ac{los} context the computation of the two area dependent probabilities has no closed-form solution. A numerical solution is obtained by sampling the attenuation values over the spatial grid of positions and computing the area dependent distributions of the attenuation values. Consider an attenuation value $\hat{a}$: the probability of measuring $\hat{a}$ given that the \ac{ue} is located in area $\mathcal{A}_0$ is given by the number of positions $(x_u,y_u) \in \mathcal{A}_0$ where the measured attenuation $a(x_u,y_u)=\hat{a}$ over the total number of positions $(x_u,y_u)$ in the entire map having the same attenuation $\hat{a}$, i.e.
%\begin{equation}
%    \mathbb{P}(\hat{a}|\mathcal{A}_0) \approx \frac{\text{number of positions} \, (x_u,y_u) \in \mathcal{A}_0 \, \text{s.t.} \, a(x_u,y_u) = \hat{a}}{\text{total number of positions} \, (x_u,y_u) \, \text{s.t.} \, a(x_u,y_u) = \hat{a}}
%\end{equation}
%With the same reasoning we compute $\mathbb{P}(\hat{a}|\mathcal{A}_1)$, and an approximation of equation (\ref{eq:lr} is hence obtained as
%\begin{equation}\label{eq:lrApp}
%    \mathcal{L} \approx \frac{\text{number of positions} \, (x_u,y_u) \in \mathcal{A}_0 \, \text{s.t.} \, a(x_u,y_u) = \hat{a}}{\text{number of positions} \, (x_u,y_u) \in \mathcal{A}_1 \, \text{s.t.} \, a(x_u,y_u) = \hat{a}}
%\end{equation}
%The value computed by (\ref{eq:lrApp}) gets closer to the real value as the number of grid points over the map increases, as an higher number of points means a better statistical characterization of the attenuation over the map area.
\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{res_NP_approx_SVM.eps}
    \caption{\ac{roc} of \ac{irlv} methods, with a \ac{nn} having $N_L=1$ and two values of $N_h$. Environment of Fig. \ref{fig:mBS}, with one \ac{ap} located at the street intersection, $d_1 = 50$~m, $d_2 = 50$~m, $\beta_1 = \beta_2 = 150$ and correlated shadowing ($\sigma_{s, {\rm dB}} = 8$~dB).}
    \label{fig:trueMap}
\end{figure}

Fig. \ref{fig:trueMap} shows the \ac{roc}  of \ac{np}, \ac{nn}, and \ac{ls}-\ac{svm}, where for a given \ac{fa} probability we report the  \ac{md} probability averaged over the shadowing attenuation maps. We notice that both \ac{nn} and \ac{ls}-\ac{svm} outperform the \ac{np} test. This means that, even for a very large number of samples available to estimate the \ac{pdf}, we still have a performance degradation with respect to \ac{np} with perfect knowledge of the statistics. On the other hand, with a small amount of training points the \ac{ml} methods outperform \ac{np}, without knowing the channel model. Therefore, in the following sections we drop the \ac{np} method.
 


%Comparing the number of grid points and the number of training points used for the \ac{ml} algorithms we can conclude that the \ac{ml}-based solution is advantageous over the \ac{np}-based one, as it requires a smaller number of points in order to get an estimate of the area dependent probabilities. Furthermore this implies that the \ac{ml}-based \ac{irlv} system can be implemented without any a-priory knowledge of the \ac{pdf} of the hypothesis to be tested.


\subsection{Two-class \ac{irlv} With Multiple \acp{ap}}
\label{sec:res_fading}

\uline{We consider the environment of Fig. \ref{fig:mBS} with $N_{\rm AP}=10$ \acp{ap} used for \ac{irlv}, namely ${\rm AP}_i$ with $i = 2,\dots,11$. The channel model includes \ac{los} and non-\ac{los} path-loss, spatially correlated shadowing ($\sigma_{\rm s, dB} = 8$ dB), and fading, as described in Section~II. We use a \ac{nn} with $L=3$ hidden layers, each layer having $N^{(i)} = 100$ neurons, $i = 1,2,3$.}  

\paragraph{No fading average} We first feed the \uline{learning machine} with attenuation estimates obtained without fading average, i.e., $k_f=1$. \ac{roi} position is $d_1 = 50$~m, $d_2 = 50$~m, and $\beta_1 = \beta_2 = 150$~m. \uline{Fig. \ref{fig:kf1} shows the \ac{roc} for \ac{nn}  and \ac{ls}-\ac{svm} \ac{irlv} methods and different values of the training-set size $S$. We observe that, for a given \ac{fa} probability, the average \ac{md} probability decreases as the training-set size $S$ increases. Both \ac{ml} models have similar performance with large training sets, confirming our result that they are both asymptotically optimal. However,  \ac{svm} converges faster than \ac{nn} (i.e., with a smaller $S$) to the optimal \ac{roc}. Therefore, a careful design is needed for a practical implementation with finite training and limited computational capabilities. Note that we obtain a more accurate classification with multiple \acp{ap} rather than using a single \ac{ap}. Still, for security purposes, we would prefer even lower \ac{fa} and \ac{md} probabilities; this can be achieved, for example, by increasing the number of \acp{ap} or considering other channel features, e.g., its wideband impulse response. }

\revi{revnewarea}{We have also considered a different \ac{roi} layout, with $d_1 = 100$~m, $d_2 = 255$~m and $\beta_1 = \beta_2 = 150$~m. The \ac{roi} is still positioned in the south-west corner, but it includes both the crossroads and $\rm AP_8$ (see Fig. \ref{fig:mBS}). Channel parameters are the same of Fig. \ref{fig:kf1}.}
\revi{newarea2}{Fig. \ref{fig:kf1_newArea} shows the resulting \ac{roc}, still obtained by averaging the \ac{md} probabilities over the shadowing maps. Including the street inside the \ac{roi}, with its \ac{los} path-loss, turns out to facilitate \ac{irlv} resulting in lower \ac{fa} and \ac{md} probabilities.}


\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{res_training_10BS_2Class.eps}
    \caption{\ac{roc} of \ac{irlv} methods for different values of training-set size $S$. Environment of Fig. \ref{fig:mBS}, with  $N_{\rm AP}=10$, $d_1 = 50$~m, $d_2 = 50$, $\beta_1 = \beta_2 = 150$~m, and $\sigma_{s,{\rm dB}} = 8$~dB.}
    \label{fig:kf1}
\end{figure}


\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{res_training_10BS_2Class_newArea.eps}
    \caption{\ac{roc} of \ac{irlv} methods for different values of training-set size $S$. Environment of Fig. \ref{fig:mBS}, with  $N_{\rm AP}=10$, $d_1 = 100$~m, $d_2 = 225$~m, $\beta_1 = \beta_2 = 150$, and $\sigma_{s,{\rm dB}} = 8$~dB.}
    \label{fig:kf1_newArea}
\end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=8.5cm]{res_training_5BS_2Class.eps}
%     \caption{\ac{roc} of \ac{svm} and \ac{nn} for $N_{\rm AP}=5$ and for different numbers of training set size $S$.}
%     \label{fig:kf1_5bs}
% \end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{res_fading_5BS_2Class.eps}
    \caption{\ac{roc} of \ac{irlv} methods for different averages of fading. Environment of Fig. \ref{fig:mBS}, with  $N_{\rm AP}=5$, $d_1 = 50 $~m, $d_2 = 50$~m, $\beta_1 = \beta_2 = 150$~m, and $\sigma_{s,{\rm dB}} = 8$~dB.}
    \label{fig:kf10-5}
\end{figure}


% \begin{figure}[t]
%     \centering
%     \includegraphics[width=8.5cm]{res_fading_10BS_2Class.eps}
%     \caption{\ac{roc} of \ac{irlv} methods for different averages of fading. Environment of Fig. \ref{fig:mBS}, with  $N_{\rm AP}=10$, $d_1 = 50$~m, $d_2 = 50$, and $\sigma_{s,{\rm dB}} = 8$~dB.}
%     \label{fig:kf10}
% \end{figure}


\paragraph{Effect of fading average}  \uline{As discussed in Section~\ref{sec:chMod}, for a given \ac{ue} position, the attenuation changes over time due to fading. By averaging $k_f$ realizations of attenuation in the same position, the effect of fading on \ac{irlv} is mitigated.}
We consider the environment of Fig. \ref{fig:mBS} with $N_{AP} =5$ \acp{ap}\uline{ used for \ac{irlv}, namely ${\rm AP}_i$ with $i = 1,\dots,5$}, and he values of the channel parameters are those of Fig. \ref{fig:kf1}. For $n_x$  explored locations by the \ac{ue} we obtain $S= n_x \cdot k_f$ training attenuation vectors. Fig. \ref{fig:kf10-5}  shows the \ac{roc} for $k_f=1$ and 10, \uline{with $n_x = 2 \cdot 10^4$ for \ac{svm} and $n_x = 3.2 \cdot 10^5$ for \ac{nn}. } \revi{revLI2a}{We also report the performance of \ac{eda}, assuming to know the path-loss relation between the attenuation and the distance.} \revi{rev2fad}{We note that both \ac{md} and \ac{fa} probabilities can be significantly reduced by averaging fading, thus approaching the performance on channels without fading. Indeed, an average of 10 fading realizations already reduces the average \ac{md} probability from $10^{-1}$ to $10^{-2}$, for an \ac{fa} probability of $2\cdot 10^{-1}$, while we achieve an average \ac{md} probability of $4\cdot 10^{-4}$ without fading using a \ac{nn}. We also notice that, in absence of fading, \ac{svm} significantly outperforms  \ac{nn} even if \ac{nn} uses a larger $S$. This suggests that, in this scenario, the \ac{nn} has not yet converged to the optimum, wherein potentially very good performance can be achieved, due to limits in architecture, computational capabilities, and design algorithms. We should remember, in fact, that the number of parameters defining the \ac{svm} grows with the training size, while the number of parameters of the  \ac{nn} is set a-priori.} \revi{revLI2b}{Lastly, we observe that the proposed \ac{ml} techniques (both with and without fading) outperform \ac{eda}, whose performance has been obtained on channels without fading. This is due to the fact that \ac{eda} is more severely affected by shadowing seen as disturbance in the derivation of the distance, while \ac{ml} solutions may exploit it in making the decision, while still not relying on specific channel models.} 

%\uline{Fig. \ref{fig:kf10} shows the \ac{irlv} performance in the same setting of Fig. \ref{fig:kf10-5} with $N_{\rm AP} = 10$ \acp{ap} positioned as in Fig. \ref{fig:mBS}. Comparing Fig.s \ref{fig:kf10-5} and \ref{fig:kf10} we note that by using more \acp{ap} significantly lowers the MD probability for a given FA probability when fading is present. The advantage in the absence of fading is instead very limited.}   


% \begin{table}
% \centering
% \caption{Location of the \acp{ap} in the Berlin scenario}
% \label{tab:berlin}
% \begin{tabular}{c c c}
% \toprule
% \ac{ap} index $n$ & $X_{\rm AP}^{(n)}$ [m] & $Y_{\rm AP}^{(n)}$ [m] \\
% \midrule
% 1 & 2500 & 2500 \\
% 2 & 500 & 4000 \\
% 3 & 4000 & 4000 \\
% 4 & 500 & 500 \\
% 5 & 4000 & 500 \\
% 6 & 100 & 4500 \\
% 7 & 1000 & 400 \\
% 8 & 4000 & 500 \\
% 9 & 4300 & 4000 \\
% 10 & 4500 & 500 \\
% \bottomrule
% \end{tabular}
% \end{table}

\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{berlinNew.eps}
    \caption{\ac{roc} of \ac{irlv} methods for the experimental data.}
    \label{fig:Berlinnew}
\end{figure}

\paragraph{Results on experimental data} \revi{Berlin}{We have tested the proposed \ac{irlv} solutions on real data collected by the MOMENTUM project {\cite{MOMENTUM-D53}} in a measurement campaign at Alexanderplatz in Berlin (Germany). Attenuations at the frequency of the \ac{gsm} (that may refer to a cellular IoT scenario in our \ac{irlv} context) have been measured for several \acp{ap} in an area of $4500~{\rm m} \cdot 4500~{\rm m}$, on a measurement grid of $50 \cdot 50$~m. We have considered 10 attenuation maps, corresponding to 10 \ac{ap} positions (all in meters) $\bm{x}_{\rm AP}^{(1)} = [2500, 2500]$, $\bm{x}_{\rm AP}^{(2)} = [500, 4000]$, $\bm{x}_{\rm AP}^{(3)} = [4000, 4000]$, $\bm{x}_{\rm AP}^{(4)} = [500, 500]$, $\bm{x}_{\rm AP}^{(5)} = [4000, 500]$, $\bm{x}_{\rm AP}^{(6)} = [100, 4500]$, $\bm{x}_{\rm AP}^{(7)} = [1000, 400]$, $\bm{x}_{\rm AP}^{(8)} = [4000, 500]$, $\bm{x}_{\rm AP}^{(9)} = [4300, 4000]$, and $\bm{x}_{\rm AP}^{(10)} = [4500, 500]$. The \ac{roi}  has been positioned in the lower-right corner, corresponding to, following the same notation of Fig \ref{fig:mBS}, $d_1 = 3000$~m, $ d_2 = 1500$~m, and $\beta_1 = \beta_2 = 1000 $~m.  In this case, we have a single realization of any channel effect (path-loss, shadowing, fading, \ldots) per location, for a total of 8464 realizations, 5000 of which have been used for training and the rest for testing. For \ac{nn}, we set $L = 3$ and $N^{(i)} = 500$, $i = 1,2,3$. Fig. \ref{fig:Berlinnew} shows the \ac{roc} for both \ac{nn} and \ac{lssvm}. The  performance is in line with the other figures obtained by simulation. Still, due to the small size of the available training set, \acp{roc} are not smooth. Moreover, we notice that \ac{svm} and \ac{nn} achieve approximately the same performance.}\revi{revLI}{Note also that, in order to use \ac{eda}, we should first know the path-loss to convert the attenuation estimates into distances, an information not immediately available from the experimental data. Therefore we could not compare \ac{ml} with \ac{eda} in this case, further demonstrating the utility of \ac{ml} model-less techniques for \ac{irlv}.}

%By comparing the two figures, we note that for small values of $S$, the performance get slightly worse as $k_f$ grows. For a large enough training set size $S$, different values $k_f$ provide approximately the same performance.  Therefore, we can conclude that, for large training sets, \ac{ml} algorithms are also robust to fading irrespective of the number of collected fading realization per location. However, in practical situations where the points for training may be limited, it may be advantageous to collect more fading realization per location. 


\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{res_Training_10BS_oneClass.eps}
    \caption{\ac{roc} for one-class \acp{irlv} for different training-set sizes. Environment of Fig \ref{fig:mBS} with $N_{\rm AP}=10$, $k_f=1$, and \ac{ae} with $N_L = 7$. }
    \label{fig:kf1Oc}
\end{figure}



\subsection{One-Class \ac{irlv} With Multiple \acp{ap}}\label{sec:numResOneClass}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=8.5cm]{noFading_10BS.eps}
%     \caption{\ac{roc} for one-class \acp{irlv} in a scenario with path-loss, shadowing and without fading.}
%     \label{fig:aeNh}
% \end{figure}

We now focus on the one-class \ac{irlv} solutions, described in Section~\ref{sec:OneClass}, where the training points come only from the \ac{roi} $\mathcal A_0$. \revi{designAE}{The \ac{ae} has been designed according to  \cite{Hinton-2006}, i.e., all neurons use the logistic sigmoid as activation function except for those in the central hidden layer, using linear activation functions. The \ac{ae} has $N_L = 7$ hidden layers with 7, 6, 3, 2, 3, 6, and 7 neurons, respectively. Weights are initialized randomly.} \uline{The channel model is  described in Section~II, for the environment of Fig. \ref{fig:mBS} (with $N_{\rm AP} =10$), and the parameters of Section~\ref{sec:res_fading}, with $d_1=50$~m, $d_2=50$~m, and $\beta_1 = \beta_2 = 150$~m.} 

% Fig. \ref{fig:aeNh} shows the \ac{roc} for both \ac{oclssvm} and \ac{ae} with $N_h \in [1, 5]$ and $S=10^4$ training vectors. We see that, by increasing $N_h$, the performance of \ac{ae}-based \ac{irlv} does not improve: indeed, the optimum \ac{roc} is obtained for $N_h=2$. This is due to how \ac{ae} compresses the attenuation vectors: the best performance are achieved when it extracts the optimal number of features from the input. As we have seen, the one-class solutions are not optimal in general, and we clearly see that \ac{oclssvm} is significantly more powerful than \ac{ae}, as the obtained \ac{roc} achieves a lower $P_{\rm MD}$ for the same $P_{\rm FA}$.
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=8.5cm]{res_Training_5BS_oneClass.eps}
%     \caption{\ac{roc} for one-class \acp{irlv} in a scenario with $N_{\rm AP}=5$, path-loss, shadowing and fading with different training set size and $k_f=1$ fading realizations,  \ac{ae} with $N_h = 2$. }
%     \label{fig:kf1Oc5bs}
% \end{figure} 
 
\revi{fadingRes}{Here, we consider the effects of fading and the choice of the number of training points $S$. Fig. \ref{fig:kf1Oc} shows the \ac{roc} for one-class \ac{irlv} systems for $k_f = 1$ and two values of $S$. We first notice that both \ac{ae} and \ac{oclssvm} converge for $S = 5 \cdot 10^{3}$, and the \ac{svm}-based solution outperforms the \ac{nn}-based solution, as already seen in the case of two-class classification. Fig. \ref{fig:kf10Oc} shows the \ac{roc} for $k_f=1$ and 10, while $n_x=2 \cdot 10^4$. We note that, for both \ac{ml} techniques, averaging over fading significantly improves the performance.} \revi{revLI3}{We also report the performance of \ac{eda} obtained without fading and assuming the knowledge of the path-loss relation between attenuation and distance. Again, we note that the proposed \ac{ml} techniques significantly outperform \ac{eda} (in the absence of fading).} \uline{In the figure we also report the performance of two-class \ac{svm} for channels without fading: we can observe that, in the considered scenario, two-class \ac{irlv} outperforms the one-class \ac{irlv}: the former achieves a lower $P_{\rm MD}$ for the same $P_{\rm FA}$. This result is expected since the two-class \ac{irlv} also exploits the (estimated) statistics of attenuation while under attacks.}
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=8.5cm]{res_Fading_5BS_oneClass.eps}
%     \caption{\ac{roc} for one-class \acp{irlv} in a scenario with $N_{\rm AP}=5$, path-loss, shadowing and fading with different training set size and $k_f=10$ fading realizations,  \ac{ae} with $N_h = 2$. }
%     \label{fig:kf10Oc5bs}
% \end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{res_Fading_new_10BS_oneClass.eps}
    \caption{\ac{roc} of one-class \acp{irlv} for different values of $k_f$. Environment of Fig. \ref{fig:mBS} with $N_{\rm AP}=10$, and $n_x= 2 \cdot 10^4$,  \ac{ae} with $N_L = 7$.  }
    \label{fig:kf10Oc}
\end{figure}




% \begin{figure}[t]
%     \centering
%     \includegraphics[width=8.5cm]{res_selective_SVM.eps}
%     \caption{\ac{cdf} of the time of first successful attack $\eta$ for various attack strategies. Both the selective \ac{ml} attack  and \ac{irlv} are based on \ac{oclssvm} and $P_{\text{FA}}= 10^{-2}$.}
%     \label{fig:selectiveSVM}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=8.5cm]{res_selective_AE.eps}
%     \caption{\ac{cdf} of the time of first successful attack $\eta$ for various attack strategies. Both the selective \ac{ml} attacks  and \ac{irlv} are based on \ac{ae} and $P_{\text{FA}}= 0.5$. \underline{AE with $N_L = 1$ and $N_h = 3$.}}
%     \label{fig:selectiveAE}
% \end{figure}


\begin{comment}
\subsection{\ac{ml} Attack Strategies}

\uline{We consider now the \ac{ml} attack strategies described in Section~\ref{sec:attack} for the scenario of Fig. \ref{fig:mBS}, with $N_{\rm AP} =5$ \acp{ap}, and channels including path-loss, shadowing, and fading as described in Section~II. The parameter set is the same of  Section~\ref{sec:numResOneClass} and $d_1=0$~m, $d_2=0$~m, $\beta_1 = \beta_2 = 255$~m.  \ac{irlv} is  performed with one-class classifiers.  When considering the \ac{ae} we consider an implementation with $N_L = 1$ and $N_h = 3$ in order to keep a simple structure. \ac{roi} $\mathcal A_0$ coincides with the whole south-west building of Fig. \ref{fig:trueMap}. } 

%In order to test the attacks we set the \ac{fa} probability at the defense side, such that the threshold value needed for classification is given. We compare attacks and defense both implemented via \ac{ae} and \ac{oclssvm}. 

We compare the proposed \ac{ml} attack strategies with the uniformly random attacks, wherein attacks are launched by uniform randomly selected positions in the \ac{roi}-complementary area $\mathcal{A}_1$.  Moreover, as a na\"ive enhancement, we consider a \emph{random-border} attack, wherein the attacker moves only along a strip of 2.5 meters at the border between areas $\mathcal{A}_0$ and $\mathcal A_1$. In this way, we expect that the chances of a successful attack increase by being closer to the \ac{roi}. Since the \ac{roi} coincides with the building, on the border between $\mathcal A_0$ and $\mathcal A_1$, the \ac{ue} is on the streets and has a \ac{los} propagation characteristic, whereas region $\mathcal A_0$ has a non-\ac{los} propagation characteristic. 

The same one-class \ac{ml} algorithm is implemented both for attack and \ac{irlv}, although the attacker training set includes only points in $\mathcal A_1$, while the \ac{ap} network training set includes only  points in $\mathcal A_0$. For  \ac{irlv}  we set $k_f=10$.

Fig. \ref{fig:selectiveSVM} shows the \ac{cdf} of the number of the first successful attack $\eta$ for the random, random-border and selective ML attack strategies. The figure presents results for \ac{irlv} with $P_{\rm FA}=10^{-2}$ and \ac{ml} approaches based on \ac{oclssvm}. In this case, the selective-ML attack is faster than pure random attack, which, in turn, performs similarly to the border-random  attack.  %Fig. \ref{fig:selectiveAE}, instead, shows results for  \ac{irlv} $P_{\rm FA} =0.5$ and \ac{ml} approaches based on \acp{ae}. We observe that the random-border attack outperforms a purely random attack, while still being less-powerful than selective \ac{ml}. 

%We can conclude that the \ac{ml} selective attack is clearly reducing the time to reach a success with respect to random attacks. Moreover, \ac{ae} is more robust to attacks than \ac{oclssvm} when used for \ac{irlv}, as for \ac{ae} the first successful attack as a similar statistics to random attacks while for \ac{oclssvm} the \ac{ml} selective strategy is  successful much earlier than the random strategies. 
\end{comment}


\section{Conclusions}

In this paper, we have proposed innovative solutions for \ac{irlv} in wireless networks that exploit the features of the channels between the \ac{ue} whose location must be verified by a trusted network of \acp{ap}. By observing that in typical situations the channel statistics are not available for \ac{irlv}, we have proposed \ac{ml}-based solutions, operating with both one- and two-class classification, i.e., with and without a-priori assumptions on attack statistics. For two-class classification we have proved that  both \ac{nn} and \ac{svm} solutions  are the most powerful tests for a given sensitivity, i.e., they are equivalent to the \ac{np} test. Instead, for one-class classification both \ac{ae} and \ac{svm} solutions are not equivalent to the \ac{glrt}. We have also investigated how to collect the training points in order to be robust against the channel fading.

\appendices

\section{LLRs derivation}
\label{sec:llrDer}

\subsubsection{Uncorrelated Fading scenario}
\revi{simpleScen3}{Assuming spatially uncorrelated Rayleigh fading, without shadowing (\ie $\sigma_{s,\rm dB}=0)$, given a \ac{ue} located at distance $d$, the channel gain $g=1/a$ is exponentially distributed with mean (in dB) $P_{\rm PL,LOS}(d)$ given by $\eqref{eq:los}$. Letting}
\begin{equation}
\begin{split}
    F(\Delta,R_0,R_1) &= 
    \frac{2}{\Delta}\int_{R_0}^{R_1} 10^{P_{{\rm PL},{\rm LOS}}(d_0)/10} \\
     & \exp\left(-10^{P_{{\rm PL},{\rm LOS}}(d_0)/10} \frac{1}{a}\right)d_0 \, {\tt d}d_0,
\end{split}
\end{equation}
\revi{simpleScen3_1}{from the uniform \ac{ue} distribution and \eqref{eq:prc} we have $p(a|\mathcal{H}_0)=F(\Delta_0,R_{\rm min},R_{\rm in})$, whereas  $p(a|\mathcal{H}_1) = F(\Delta_1,R_{\rm in},R_{\rm out})$.}
\revi{simpleScen3_2}{By computing integrals for path-loss coefficient $\nu = 2$, the \ac{llr} is} 
\begin{equation}\label{eq:llr1}
   \mathcal{M}(a) =
   \ln\left(\frac{R^2-R_{\rm min}^2}{R_{\rm in}^2-R_{\rm in}^2}\frac{\mathcal{V}(R_{\rm min},a)-\mathcal{V}(R_{\rm in},a)}{\mathcal{V}(R_{\rm in},a)-\mathcal{V}(R,a)}\right),
\end{equation}
 \begin{equation}
 \begin{split}
&\mathcal{V}(d_0,a) = \\
& \exp\left(-\frac{1}{a}\left(\frac{4 \pi f_0 d_0}{c}\right)^2\right) \left(\frac{1}{a}\left(\frac{4 \pi f_0 d_0}{c}\right)^2+1\right) .   
 \end{split}
\end{equation}

\revi{simpleScen3_3}{Let $\Gamma(\gamma,b)= \int_{b}^{\infty}t^{\gamma-1}e^{-t} dt$ be the incomplete gamma function, then for $\nu=3$ we have instead}
\begin{equation}\label{eq:llr2}
\begin{split}
 \mathcal{M}(a) = &
 \ln\left(\frac{R^2-R_{\rm in}^2}{R_{\rm in}^2-R_{\rm min}^2}
 \frac{\Gamma\left(\frac{5}{3},\frac{1}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R_{\rm min}^3\right)}
 {\Gamma\left(\frac{5}{3},\frac{1}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R_{\rm in}^3\right)} \right.\\
  & \left. \frac{-\Gamma\left(\frac{5}{3},\frac{1}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R_{\rm in}^3\right)}{-\Gamma\left(\frac{5}{3},\frac{1}{a}\left(\frac{4 \pi f_0}{c}\right)^3 R^3\right)} \right),
\end{split}
\end{equation}
 
\subsubsection{Uncorrelated shadowing scenario}
\revi{simpleScen4}{Assuming spatially uncorrelated shadowing, without fading   we have $10\log_{10}a^{(n)}=P^{(n)}_{\rm PL}+s$, \ie the received power from a given location is distributed in the logarithmic domain as a Gaussian random variable with mean value given by the path-loss (\ref{eq:los}) and standard deviation $\sigma_{s,\rm dB}$. Letting}
\begin{equation}\label{eq:sh}
\begin{split}
&   G(\Delta, R_0,R_1) = \\ 
&\frac{2}{\Delta}\int_{R_0}^{R_1} \exp\left(-\frac{1}{2}\frac{\left(\frac{1}{a}+10\nu\log_{10}\left(\frac{4 \pi f_0 d_0}{c}\right)\right)^2}{\sigma_{s,\rm dB}^2}\right) d_0 \, {\tt d} d_0, 
\end{split}
\end{equation}
\revi{simpleScen4_1}{from (\ref{eq:prc}), the \ac{pdf} of incurring an attenuation $a$ in hypothesis $\mathcal{H}_0$ is $p(a|\mathcal{H}_0)=G(\Delta_0,R_{\rm min}, R_{\rm in})$, and $p(a|\mathcal{H}_1) = G(\Delta_1, R_{\rm in},R_{\rm out})$.}
\revi{simpleScen4_2}{By solving the integral in (\ref{eq:sh}) we obtain the \ac{llr}}
\begin{equation}\label{eq:llr3}
    \mathcal{M}(a) = \ln\left(\frac{R_{\rm out}^2}{R_{\rm in}^2} \frac{\mathcal{T}(R_{\rm in})-\mathcal{T}(R_{\rm min})}{\mathcal{T}(R_{\rm out})-\mathcal{T}(R_{\rm in})}\right),
\end{equation}
\revi{simpleScen4_3}{where $\erf(x)= \frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} {\tt d}t$ is the error function and}
\begin{equation}
    \mathcal{T}(d_0) = \erf\left( \frac{\frac{100 \nu^2}{\sigma_{s,\rm dB}^2}\ln d_0-\ln^2(10)+\frac{\frac{1}{a} 10 \nu \ln 10}{2\sigma_{s,\rm dB}^2}}{\sqrt{1/2\sigma_{s,\rm dB}^2}10\nu\ln 10}\right).
\end{equation}

\section{Proof of Theorem 3}\label{sec:proofTh3}

	Given a finite  attenuation vector alphabet $\mathcal C = \{\bm{\alpha}_1, \ldots, \bm{\alpha}_M\}$ of $M$ elements, with $\bm{a}^{(i)} \in \mathcal C$, we indicate with $p_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j, t)$, with $t \in \{-1,1\}$, the joint probability of input vector $\bm{a}^{(i)}$ and corresponding output $t_i$, $i=1, \ldots, S$.
	
	By the GlivenkoCantelli theorem we have that with probability 1 as $S\rightarrow \infty$ there are $Sp_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,t)$ training vectors $\bm{\alpha}_j$ with associated true label $t$ in any training sequence.
	All these training points will have the same \uline{error values $\epsilon_j$}, from (\ref{eq:stpart}), that will appear $Sp_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,t)$ times in the sum $\sum_{i=1}^{S} e_i^2$.
	Note that in the training ensemble there could be two equal instances $\bm{a}^{(m)}=\bm{a}^{(n)}=\bm{\alpha}_j$, but with different labels $t_m \neq t_n$. Therefore, \uline{for a given $\bm{\alpha}_j$} we can have two possible \uline{errors}, depending on $t_i$, and we denote them with $\epsilon_{j,1}$ and $\epsilon_{j,-1}$.
	This translates into only $2M$ \textit{distinct} constraints of type \eqref{eq:stpart}.
	Asymptotically, for $S \to \infty$, problem (\ref{eq:lssvm}) becomes
		\begin{equation}
		\label{eq:lssvm2}
		\begin{split}
		\underset{\bm{w},e}{\text{min}} \quad f_l' \triangleq \frac{1}{2} \bm{w}^T \bm{w} + & C S \frac{1}{2} \sum_{j=1}^M [p_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,1) \epsilon_{j,1}^2 + \\
		&+p_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,-1) \epsilon_{j,-1}^2]  
		\end{split}
		\end{equation}
		subject to 
$
		[\bm{w}^T \phi (\bm{\alpha}_j) + b] = 1- \epsilon_{j,1}
$
and
$
-[\bm{w}^T \phi (\bm{\alpha}_j) + b] = 1- \epsilon_{j,-1}\quad j = 1 ,\dots,M,
$
	whose solution provides the convergence value (in probability) of vector $\bm{w}$. We write the Lagrangian
	\begin{equation}
	\begin{split}
	\mathcal{L}_1 = f_l'& - \sum_{j=1}^{M} v_j \left[ \bm{w}^T \phi (\bm{\alpha}_j) + b - 1 + \epsilon_{j,1} \right] + \\
	&- \sum_{j=1}^{M} u_j \left[- \bm{w}^T  \phi (\bm{\alpha}_j) - b  - 1 + \epsilon_{j,-1} \right], 
	\end{split}
	\end{equation}
	where $\{u_k,v_k\}_{k=1}^{M}$ are the Lagrangian multipliers. By setting to zero the derivatives with respect to $\{\bm{w},b,\epsilon_{j,1},\epsilon_{j,-1}, v_j,u_j\}$  we get the system of equations
	\begin{subequations}
		\label{eq:system1}
		\begin{equation}
		\begin{split}
		\sum_{k=1}^{M} &(u_k - v_k) k(\phi (\bm{\alpha}_k,\bm{\alpha}_j)) + b - 1 + \\ 
		&+ \frac{v_j}{CSp_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,1)} = 0
		\quad j=1\dots M,
		\end{split}
		\end{equation}
		\begin{equation}
		\begin{split}
		- \sum_{k=1}^{M} &(u_k - v_k) k(\phi (\bm{\alpha}_k,\bm{\alpha}_j)) - b - 1 + \\+
		& \frac{v_j}{CSp_{\bm{a}^{(i)},t_i}(\bm{\alpha}_j,-1)} = 0
		\quad j=1,\dots, M,
		\end{split}
		\end{equation}		
		\begin{equation}
		\sum_{k=1}^{M} (u_k - v_k) = 0.
		\end{equation}
	\end{subequations}
	Note that \eqref{eq:system1} is a system with $2M + 1$ equations, linear in the $2M + 1$ unknowns $\{u_k,v_k,b\}_{k=1}^{k=M}$ and therefore has finite solution. In particular, we have
	\begin{equation}
	\label{eq:wSolution}
	\bm{w}^T\bm{w} =  \sum_{k=1}^{M} \sum_{h=1}^{M} k(\bm{\alpha}_k,\bm{\alpha}_h) (v_kv_h + u_ku_h -2 v_ku_h),
	\end{equation}
	where we used the fact that the kernel function
$
	k(\bm{\alpha}_k,\bm{\alpha}_h) \triangleq \phi(\bm{\alpha}_k) \phi(\bm{\alpha}_h)^T
$
	 is symmetric \wrt its inputs. 	We conclude that $\bm{w}$ has a finite norm since the right hand side of \eqref{eq:wSolution} is a finite sum.

%\bibliographystyle{IEEEtran}
%\bibliography{bibliography.bib}
\renewcommand*{\bibfont}{\footnotesize}

\printbibliography

\begin{comment}


\clearpage
\section*{Answer to Reviewers' Comments}
\section*{Reviewer: 1}

~

\setstretch{1.0}

\begin{framed}
 {\bf Rev: Positives:

- Classic hypothesis test is added on with machine learning algorithms, which bring novel ideas to the field.

- Some theories are also derived for the proposed algorithms.

- Numerical parts are solid and have many interesting insights. 

- The citations are sufficient. But there are many recent related work with machine learning in detection.
}
\end{framed}

\setstretch{1.5}

{\bf Ans:} We would like to thank you for your positive comments. We have addressed all the issues, updated the manuscript, and provided here a point-to-point response. In addition, as per request of other reviewers, we have rewritten the numerical results by 
\begin{itemize}
    \item including a comparison with existing technique that estimates the user position in order to perform \ac{irlv} (see Section~\ref{seccomp} and Fig.s \ref{fig:kf10-5} and \ref{fig:kf10Oc});
    \item adding a configuration with 10 \acp{ap} (instead of just one configuration with 5 \acp{ap} of the previous manuscript), in order to obtain lower MD and FA probabilities.
\end{itemize}


\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
{\bf Rev: The machine learning part looks trivial and too classic. Much more advance schemes are available everyday on the market.}
\end{framed}
 
\setstretch{1.5}

{\bf Ans:} We agree with you that various solutions have been considered in the literature for classification. We decided to focus on two classical approaches (namely \ac{svm} and \ac{nn}) since the structure of the addressed problem as well as the type of the input is simple and we focus on the received signal power at various access points. Moreover, the main intent of the paper is to establish a connection between the machine learning approach, to be used when statistics of input data in the two hypotheses is not known a priori, and the Neyman-Pearson test, to be used when the statistics is known. In this respect, the presented theoretical results fill this gap and are actually applicable to more complex scenarios. Indeed, as we consider the neural network as a generic parametric function, %whose parameters are updated using specific target function, 
our results extend also to deep learning solutions.

In order to make this point more clear, we have updated the Introduction, by extending the literature survey and adding the following sentence:
\begin{quote}
    "\revp{rev11a}"
\end{quote}

Moreover, we have added the following sentence after Corollary 1, to indicate that it also pertains deep-learning NNs:
\begin{quote}
    "\revp{rev11b}"
\end{quote}
 
Lastly, numerical results have been revised in order to include the performance of more complex scenarios using more \acp{ap} (thus increasing the input size of the machine) and deep-learning \acp{nn}. 

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Theorem 1 looks too obvious.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Although Theorem 1 (Corollary 1 in the new version of the manuscript) largely relies on an existing result that connects the MLP to the Bayes optimal discriminant function, it is not so common in the ML literature to frame classification as a hypothesis testing problem and investigate the connection between ML solutions and the Neyman-Pearson test. We believe that this is the contribution of Theorem 1 as well as the other theorems of the manuscript that extend this result to various SVM solutions. Following your advice, in the revised manuscript we have briefly recalled the result of \cite{Ruck-90} and reduced to the minimum the derivations for the proof of Theorem 1, which is now presented as a corollary of the result of \cite{Ruck-90}.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Neural networks in Figure 2 [figure has been removed in the new version] are fully connected and kind of shallow.}
\end{framed}

\setstretch{1.5}
{\bf Ans:}  We thank you for your comment. Unfortunately due to space limitation we decided to remove former Fig. 2 from the new version of the manuscript. However, we revised the description of the AE as follows:
\begin{quote}
    "\revp{deep ae}"
\end{quote}
 
In the numerical results, we still use a fully connected NN, since the number of input in the considered scenario is small and tractable with this kind of networks.

% We would like to thank the reviewer for having indicated more complex solutions to our problem. \hl{NON CAPISCO} In this paper we do not consider convolutional autoencoders and hence we implemented networks with fully connected layers. We added a more general description of the AE in Section~\ref{sec:auto} : 
% \begin{quote}
%     "\revp{deep ae} \cite[Chapter 14]{goodfellow}.
%     \revp{deep ae2} \cite[Chapter 14]{goodfellow}."
    
% \end{quote}
 
\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Abstract sounds to stress something like the attacks, while in the main text, it is rarely mentioned and discussed.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thanks for your comment. Following also the advice of another reviewer and due to space limitation, we decided to remove the part on attacks from the revised manuscript. We have revised the abstract accordingly.


\clearpage 
\section*{Reviewer: 2}
~
\begin{framed}
\noindent{\bf Rev: Positives:
The authors provide model descriptions and include realistic effects like fading and shadowing. They consider multiple algorithms and compare them to the theoretical optimum. An attacker scenario is considered, too, where the location of the attacker is optimised. ML is shown to reduce the time to read a success with respect to random attacks.}
\end{framed}
\setstretch{1.5}
{\bf Ans:} We would like to thank you for your positive comments. We have addressed all the issues, updated the manuscript, and provided here a point-to-point response to your observations. 

\setstretch{1.0}

\begin{framed}
\noindent {\bf Rev:
There exist a large number of literature on location aware services in WiFi as well as cellular networks. It must be clearly described what the benefits of the proposed (simple and idealised hypothesis test approach) are.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We have carefully revised the literature according to your suggestion. Current literature can be classified into these two main categories:
\begin{itemize}
    \item Some works deal with the problem of comparing the current channel estimate with another single channel realization used as a reference and collected earlier. \ac{irlv} is different, since it aims at comparing the current channel estimate with many other channel realizations, one for each point in the region of interest. 
    \item Other works deal with the problem of a {\em specific} location verification, i.e., checking if the user is in a given position. In this case, the papers in literature suggest to i) convert attenuation measurements into distances with respect to reference points, ii) determine the user position, and iii) verify it. This approach can be extended to \ac{irlv}, and, in fact, we have included a comparison of this approach with our approaches in the revised manuscript (see  Section~\ref{seccomp}, and the response to your next question). However, this approach requires the a-priori knowledge of the relation between the measured physical quantity (e.g., the attenuation) and the distance. With realistic channel models, this relation is not fixed but depends on the position itself (e.g., conditions of line of sight or non-line of sight); therefore, this approach is not robust, as also shown by our results.
    \item Most papers assume either to have perfect distance estimates of the user with respect to reference points, or to know the statistics of the error on distance. However, in practical scenarios these assumptions are unrealistic.
\end{itemize}
Since most of the papers either consider other problems rather than \ac{irlv} (e.g., single location verification) or have too simplistic assumptions on the distance estimate (e.g., perfect estimates or known error statistics), we do not elaborate on them in our paper. However, following your advice, we have added a direct comparison in the revised manuscript with a technique presented in the literature.

About the benefits of the proposed \ac{ml} approach we recall:
\begin{enumerate}
    \item Robustness against uncertainties in the channel model: as the machine learns from collected data, it is agnostic of specific channel models, thus more robust to hardly predictable scenarios (LOS/no-LOS, shadowing parameters, interference, fading...).
    \item Asymptotic optimality: our paper stresses that, with a large training datasets, sufficiently complex machines, and convergence of the learning algorithm, the \ac{ml} approaches can achieve the performance of the optimal \ac{np} test. We agree with you that we consider idealized conditions for the theoretical results. However, we confirm by numerical results that the asymptotic results are achieved in (simple) testing scenarios where the \ac{np} test can be applied with a limited effort (in terms of training and complexity). Therefore, our results are promising also from an implementation perspective.
\end{enumerate}

In the revised version of the paper:
\begin{enumerate}
    \item We have added new references \cite{Baracca-12}, \cite{7398138}, \cite{singelee2005location}, \cite{song2008secure},  \cite{goldsmith2005}, \cite{bishop92}, \cite{guo2008novel}, \cite{Bianchini2014}, and \cite{MOMENTUM-D53};
    \item We have revised the introduction to better frame our work in the literature as follows:
    \begin{quote}
"\revp{rev2lit}\revp{rev3cit}\revp{rev2lit2}"
\end{quote} 
\item We have better highlighted the contribution of our paper and the differences with respect to the literature as follows:
\begin{quote}
"The contributions of this paper are summarized hereby:
\begin{enumerate}
    \item \uline{we propose physical-layer \ac{irlv} solutions based on \ac{ml} techniques that are suitable to operate with inaccurate estimates, even when their statistics are not known, thus being model-less;}
    \item \uline{we show that, in asymptotic training and complexity conditions, \ac{nn} and \acp{lssvm} at convergence achieve the error probabilities of the \ac{np} test, which is most powerful for a given significance level.}
\end{enumerate}
\revp{lit2}"
\end{quote} 
\end{enumerate}
 
\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf  Rev: In the numerical simulations a comparison with state of the art algorithms should be included.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for the suggestion. In the revised manuscript, we have included the description of the method presented in \cite{li2010security}, wherein the position of the user is first estimated and then compared with the region of interest. Still, the technique of \cite{li2010security} a) assumes to know the path-loss relation between attenuation and distance, which may be unrealistic, and b) is designed to confirm a specific position rather than asserting if the user is in a {\it region}. Therefore, we have extended \cite{li2010security} to perform \ac{irlv}. The resulting method is briefly described in Section~\ref{seccomp} as follows:
\begin{quote}
"\revp{literature_1} 
	\begin{align}
 \hat{\bm x}_{\rm UD} =  \underset{\bm x}{\arg \min} \sum_{n=1}^{N_{\rm AP}} \left(L(\bm{x},\bm{x}_{\rm AP}^{(n)}) - \hat{L}(\bm{x}_{\rm UD},\bm{x}_{\rm AP}^{(n)}) \right)^2,.
\end{align}
\revp{literature_2}

\revp{literature_3}"
\end{quote}


Moreover, Fig.s  \ref{fig:kf10-5} and \ref{fig:kf10Oc} now include the comparison with the model in the literature. We have added the following comments on the figures:  
\begin{itemize}
    \item Comment to Fig. \ref{fig:kf10-5}:
    \begin{quote}
        "\revp{revLI2a}" \\ ... \\ "\revp{revLI2b}" 
    \end{quote}

    \item Comment to Fig. \ref{fig:kf10Oc}:
    \begin{quote}
        "\revp{revLI3}"
    \end{quote}
\end{itemize}
Moreover, we have added the following comment to Fig. \ref{fig:Berlinnew}:
    \begin{quote}
        "\revp{revLI}"
    \end{quote}
\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The quality of the graphics could be improved.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for pointing out this issue. We have revised all the graphics in the paper and improved their quality.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The asymptotic results are only available for very idealised cases.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Following your advice 
\begin{enumerate}
    \item  we have revised the case studies by adding more realistic features and providing closed-form expressions for the \acp{llr} used in the \ac{np} test;
    \item we have added performance results obtained from experimental data as per your request;
    \item we have presented results (without comparison with the \ac{np} test) for channels  including a) path loss with LOS/non-LOS characteristics, b) spatially correlated shadowing, and c) fading, i.e., in accordance with the most detailed models in the literature. 
\end{enumerate}
In particular, about point 1), we have revised the entire Section~\ref{sec:los} in order to include more realistic scenarios and show the effect of different channel parameters on the \ac{irlv} performance, writing:
\begin{quote}
"\revp{simpleScen}"
\end{quote}
Then, we derive closed-form expressions of the \ac{llr} in both scenarios (see Appendix \ref{sec:llrDer}).

In Section \ref{sec:numRes}, performance results are reported for the new scenarios, confirming that both \acp{nn} and \ac{svm} match the performance of the \ac{np} test. In particular, we write:
\begin{quote}
    "\revp{numResSimplScen} \revp{numResSimplScen2}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
An overall framework/unified model is missing. The impact of the paper would be much larger if the model-less learning based approach is tested with real experimental data.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} The proposed \ac{ml} solutions operate with any channel feature, and the comparative analysis on their asymptotic behaviour with respect to \ac{np} test holds irrespective of the input model. Moreover, the \ac{ml} approach is model-less by nature, as no assumption is done on the structure/model of the input. In this sense, the details for the channel model of Section~II only show the complexity of the \ac{irlv} problem and are used to obtain numerical results in realistic conditions. However, we do not use the specific model of Section~II for the analysis described in the rest of the paper. We appreciate your advice of supporting the validity of the result with real data, therefore in order to strengthen the fact that our approach is general and not related to a specific model, we report performance results obtained by  applying the \ac{ml} \ac{irlv} techniques also on experimental data in the revised manuscript.

In particular:
\begin{itemize}
    \item we have added the following sentence in Section~ \ref{sec:intro}:
\begin{quote}
"\revp{framework1}"
\end{quote}
\item we have added the following sentence in Section~\ref{sec:irlvML}: 
\begin{quote}
"\revp{framework2}"
\end{quote}
\item we have added performance results on experimental data in Fig. \ref{fig:Berlinnew} with the following comment:
\begin{quote}
	"\revp{Berlin} \revp{revLI}"
\end{quote}
\end{itemize}
 
\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The security attack by choosing locations is not properly modelled and does not contain a complete analysis and assessment. Either elaborate or do not include. If the security attack is included, please modify the title accordingly.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Following your advice and due to space limitation we decided to remove the part on the attacks from the revised manuscript.


% We agree with you that the part on security attack was confusing. We have revised it by focusing on a specific attack and describing it more clearly in a point-by-point procedure, as detailed in a reply to your observation in page \pageref{MLattackissue} of this document. Since the contribution is limited we do not think that it should be further highlighted in the title. We only modified it from "Machine Learning for In-Region Location Verification in Wireless Networks" to "Machine Learning IN In-Region Location Verification FOR Wireless Networks"; in this way, machine learning is now intended to be used more generally in this field (i.e. also for attack purposes) rather than only FOR the verification part. Moreover, we have reduced the relevance on the attack model in the Abstract, which now reads as follows:
% %We have revised the abstract to avoid misunderstanding about the attacks. It now reads as follows:
% \begin{quote}
%     "\revp{rev14}"
% \end{quote}
% Moreover, we have also modified the Introduction by writing
% \begin{quote}
%     "\revp{rev14b}"
% \end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
There are a number of typos and English grammar mistakes. The paper should be carefully proofread.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for pointing out this issue. We have carefully revised the paper to amend typos and grammar mistakes.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Most applications are from the WiFi or IoT area. Why the paper then studies the cellular setup?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We agree with your observation: location verification is of high interest for WiFi and IoT. We have revised the manuscript accordingly: as our approach is general, we now do not mention a specific cellular setup, and we also replaced the acronym UE (user equipment) with the acronym UD (user device) to avoid reference to cellular systems. The considered channel model is very general and covers frequencies of WLANs and IoT. Moreover we added the following sentence in Section~II:
\begin{quote}
    "\revp{WiFi2}"
\end{quote}
Lastly, most numerical results are obtained from a 2~GHz frequency that well fits WLAN applications, while the newly inserted results from experimental data are referring to GSM frequencies, which can refer for example to a cellular IoT.


\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
If books are referenced, please include page or section or Theorem numbers for easier reference.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for the suggestion. We revised the manuscript in order to include chapter numbers for the cited books.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
In the introduction, there are no SoA references for the security attacks including models and countermeasures.}
\end{framed}
\setstretch{1.5}
{\bf Ans:} We have clarified the SoA on attacks in location verification systems, and we have added a paragraph in the Introduction, which reads:
\begin{quote}
"\revp{attack1}"
\end{quote}


\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Fig. 1 [figure removed in the revised manuscript] is not adding any real value. Please add more information like showing the variables such as regions A0 and A1 and the channel parameters.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Due to space limitation, we have decided to remove former Fig. 1 as it did not add much information.
\setstretch{1.0}

\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Justify and motivate why only the receive power and not the phase is used for hypothesis test.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} The received power was considered only as an example of channel feature that can be exploited for \ac{irlv}. There are definitely other options, as the phase or the wideband impulse response, that can be used for localization. In order to make this point clearer, we have added the following sentence in Section~II:
\begin{quote}
    "\revp{revPHASE}"
\end{quote}
\setstretch{1.0}



\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Provide a reference for the chosen shadowing correlation model below (4) [in-line equation in pg. 5 of the revised paper].}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We have added the reference to \cite[Chapter 2.7]{goldsmith2005} after the description of the shadowing correlation.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Explain how to choose the parameter Lambda in (6) [(\ref{eq:oneClassDec}) in the revised paper]}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for pointing out this issue. We have clarified this point adding a reference to the standard \ac{np} test design in the following sentence in Section~\ref{sec:auth}
\begin{quote}
"\revp{lambda}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Provide more details on $\zeta(\rho)$ below (8) [equation removed in the revised manuscript] and its operational meaning.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} In order to provide more realistic scenarios, we have replaced the example you mentioned in the new manuscript with two new scenarios where the channel is affected by path-loss, fading and uncorrelated shadowing (see the answer to one of your previous questions). Therefore, we do not use anymore parameter $\zeta(\rho)$. 

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The example closes with equation (11): How does the test function look like? What are the insights from this example?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We decided not to include the plot for the test functions (\ref{eq:llr1}), (\ref{eq:llr2}) and (\ref{eq:llr3}), as we already have many figures and they do not provide much additional insight to the problem. We also revised the example, by including more complex scenarios. The reason of the example is to show the complexity of determining analytically the \ac{llr}, as a motivation for the \ac{ml} approach.. In order to clarify this, we added in Section~\ref{sec:los}:
\begin{quote}
"\revp{llrComp}"
\end{quote}


\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Section~III, explicitly state that you apply supervised learning.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for the suggestion. We have added the following sentence in Section \ref{sec:irlvML}:
\begin{quote}
"\revp{supervised}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Below (13) [(\ref{testfunNN}) in the revised manuscripts], is $\lambda$ optimised with ML, too?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} The parameter $\lambda$ must be chosen to guarantee the desired \ac{fa} probability. In order to clarify this point, we have added the following sentence in Section~\ref{sec:nn}:
\begin{quote}
"\revp{lambdaNN}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Theorem 1 [now Corollary 1] is basically a Corollary from [18] [now \cite{Ruck-90}].}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Following your suggestion, we have reported the theorem by \cite{Ruck-90} and denoted former Theorem 1 as a corollary.
\setstretch{1.0}


\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
From the flow of the paper, it is not clear, why the section on NN CE Design is needed. }
\end{framed}
\setstretch{1.5}
{\bf Ans:} The \ac{nn} can be designed according to many loss functions: we have considered the widely used \ac{mse} and \ac{ce} functions and shown with two different theorems that with both choices the \ac{nn} achieves performance of the \ac{np} test. 

In order to clarify why both \ac{mse} and \ac{ce} loss functions are considered for \acp{nn}, we have added the following sentences:
\begin{itemize}
    \item in Section~ \ref{sec:nn}:
\begin{quote}
"\revp{ceNeeded}"
\end{quote}
\item in Section~\ref{sec: mse_train}
\begin{quote}
"\revp{ceNeeded2}"
\end{quote}
\item in Section~\ref{sec: ce_train}
\begin{quote}
"\revp{ceNeeded3} \cite[Chapter~5.2]{Bishop2006}."
\end{quote}
\end{itemize}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Furthermore, sections D and E on SVM should be merged.}
\end{framed}
\setstretch{1.5}
{\bf Ans:} We have merged Sections D and E on \ac{svm}, as you suggested.


\setstretch{1.0}
\vspace{5mm} %5mm vertical space

\begin{framed}
\noindent {\bf Rev:
In Theorem 3 and following, the assumption of perfect training (reaching a global optimum) should be justified. Lemma 1 alone is not sufficient.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} In Theorem 3, we analyze the function obtained by SVM when it converges to the global optimum. We agree with you that, in general, this requires a very large training dataset, although this condition alone does not ensure convergence to the optimum. In order to make this point clearer, we have rewritten the hypothesis of Theorem 3 as follows:
\begin{quote}
    "\revp{revGO}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The phrase "parameter" is first used explicitly in Sec. 3-E without introducing it. However, it is implicitly used earlier when the activation function in NNs and kernel function in SVMs are described as being "fixed" (which refers to being a hyperparameter).}
\end{framed}

\setstretch{1.5}
{\bf Ans}: We thank the reviewer for pointing out the issue. We have dropped the adjective {\it fixed} in favour of clearer statements in Section~\ref{sec:nn} and \ref{sec:svm}, which now reads as:
\begin{quote}
	"\revp{hyper1}"
\end{quote}
and
\begin{quote}
	"\revp{hyper2}"
\end{quote}
We have also dropped the term {\it hyper-parameter} and substituted it directly with its definition. We have modified another paragraph in Section \ref{sec:svm} which now reads:
 \begin{quote}
 	"\revp{hyper3}"
 \end{quote} 

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Section~IV switches to a new model where data is only collected within region A0. This is not clear and also not justified.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} In Section~\ref{sec:OneClass}, the new model collects data uniquely from region $\mathcal{A}_0$ in the training phase and considers \ac{ml} classifiers still able to distinguish between two classes. Hence, samples are collected from $\mathcal{A}_0$ during the training phase and from both $\mathcal{A}_0$ and $\mathcal{A}_1$ during the testing phase. The reason for this choice is that the area $\mathcal{A}_1$ can be large or not well defined, and it may be complicated to collect enough training samples from this area. Therefore, a simple approach with a smaller known set is of interest. 
In order to clarify this aspect, we have added in Section~\ref{sec:OneClass}:
\begin{quote}
"\revp{oneClass}"
\end{quote}
The motivation of this choice has been discussed in Section~\ref{sec:OneClass} as follows:
\begin{quote}
"\revp{revOC}"
\end{quote}


\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
In the AE architecture, the operational meaning and benefits of the low dimensional hidden layer are not clearly derived. Furthermore, the linear activation is not motivated.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} As \acp{ae} are well known architectures, an in-depth explanation of the low dimensionality of the hidden layers is beyond the scope of this paper. The same observation holds for the choice of the linear activation function at the output layer, which is a common choice according to \cite[Chapter 14]{goodfellow}. In order to support the reader, we have added the following sentence in Section~\ref{sec:auto}:

\begin{quote}
    "For an in depth description of the \ac{ae} architecture \cite[Chapter 14]{goodfellow}."
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The resulting IRLV test function is the simple MSE thresholding.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We fully agree with you that the resulting test function is the simple \ac{mse} thresholding. In order to include your observation, we have added the following sentence in Section \ref{sec:auto}:

\begin{quote}
    "\revp{mseThresholding}"
\end{quote}

\setstretch{1.0}
\begin{framed}
\noindent {\bf Rev:
The section on the ML-based attack strategies does not have a clear model and the interaction between system and attacker are correctly detailed. It seems a non-cooperative game model could fit here.}
\end{framed}
\setstretch{1.5}
{\bf Ans:} According to your suggestion, and due to space limitation, we have removed this subsection on ML-based attacks and the associated numerical results.

% \label{MLattackissue} Thank you for your observation. The description of the attack in the previous manuscript version was confusing, as it was  mentioning various strategies. We have completely rewritten Section~\ref{sec:attack}, focusing on one specific attack, and stressing its motivation, while only hinting to other possible strategies left for future work. The new section reads as follows:
% \begin{quote}
%  \hl{***}   "\revp{sezattack}
% \begin{enumerate}
%     \item The attacker visits $N$  points spread uniformly at random outside $\mathcal A_0$. From each point it collects the attenuation vector and performs the attack. If any of the attacks is successful, the procedure is stopped.
%     \item If none of the $N$ attacks is successful, the attenuation vectors are used to train a one-class classifier.
%     \item The attacker picks a new position uniformly at random outside $\mathcal A_0$ and feeds its attenuation vector to the trained classifier.
%     \item A vector classified into the class it is discarded, and the procedure goes back to point 3). Otherwise, an attack is performed from the selected position.
%     \item If the attack is successful, the procedure is stopped. Otherwise, the attenuation vector is used as further training input of the one-class classifier and the procedure goes back to point 3).
% \end{enumerate}
% \revp{sezattack2} 
% \end{quote}


\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Reason for using Eq. (38) [equation removed in the revised manuscript] as activation function for the output layer is missing, especially since it is not a common choice for an activation function. Motivate the design choices!}
\end{framed}
\setstretch{1.5}


{\bf Ans:} 
Thanks for having highlighted this issue. We have carefully revised both \ac{mlp} and AE design choices, and now we use common activation functions from the literature. In particular, in Section~\ref{sec:numRes} we write:
\begin{quote}
    "\revp{activation}"    
\end{quote}

In Section~\ref{sec:numResOneClass} we specify:
\begin{quote}
"\revp{designAE}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Why not using more hidden layers to improve performance?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} In the revised manuscript, both the feedforward \acp{nn} and the \ac{ae} have been extended to include multiple hidden layers in order to improve the system performance as you suggested. Results are reported in Section~\ref{sec:numRes}.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
A illustration of the considered layout in Section~V-A might be helpful.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for the suggestion. We have added Fig. \ref{fig:simpScen} in Section~\ref{sec:los} to illustrate the scenario where the \ac{np} framework has been applied. The numerical results for this scenario are still reported in Section~\ref{sec:singleAp}. 

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
In the assessment of Fig 3 [Fig. \ref{fig:ceVSnp} in the revised paper], the advantage of NN versus N-P should be clarified, too, since they perform equally (bad).}
\end{framed}

\setstretch{1.5}
{\bf Ans:} According to your comment, we have modified Section \ref{sec:los} including more realistic scenarios with uncorrelated shadowing and fading, and we have derived the closed form solutions for the \ac{llr} (in Appendix \ref{sec:llrDer}) in order to compare the \ac{np} and \ac{ml} frameworks. In order to assess the advantages of the \ac{ml} framework with respect to the \ac{np} one, we have added the following sentence in Section~\ref{sec:los}:
\begin{quote}
"\revp{llrComp}"
\end{quote}
Then, we have investigated via simulation the effects of the channel parameters (path loss coefficient and shadowing standard deviation) on the \ac{irlv} performance in Section \ref{sec:singleAp}, and we have improved them with respect to the previous version of the paper. Furthermore, all numerical results in Section \ref{sec:numRes} have been revised with the improved version of the system, which attains better classification performance.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The scenario in Fig. 4 is not well motivated. Why should the region A0 be outside the two main streets?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} There is no special reason for positioning area $\mathcal A_0$ outside the two streets, except for considering it inside a building (e.g., an office). In order to clarify this point, we have added the following sentence in Section~\ref{sec:singleAp}:
\begin{quote}
"\revp{building}"
\end{quote}

Moreover, in the revised paper, we have considered also another position of the \ac{roi} with $d_1 = 100$~m, $d_2 = 255$~m, and $\beta_1 = \beta_2 = 150$~m, i.e., the \ac{roi}  is still positioned in the south-west corner, but it also includes the crossroad and $\rm AP_8$ (see Fig. \ref{fig:mBS}). We have added Fig. \ref{fig:kf1_newArea} that has been commented as follows:
\begin{quote}
"\revp{revnewarea}

\revp{newarea2}"
\end{quote}
In the new version, we have also considered different numbers of \acp{ap}, namely 1, 5, and 10, in order to provide a more complete set of results. Still, our results are to be considered only exemplary and do not aim at exploring the performance in a comprehensive way, which is left to experimental studies to be conducted in specific scenarios of interest.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The evaluation in the end of Sec V-B sounds contradictory. First, it is said that "[...] for small S, performance get slightly worse as $k_f$ grows.". Second, at the end of the evaluation, it is stated that "[...] in practical situations where the points for training may be limited, it may be advantageous to collect more fading realization per location.". Another way of saying this would be that for small S ("limited number of training points"), the number of $k_f$ should be increased ("collect more fading realizations per location"). However, this is contradictory to the first statement, that the performance decreases with increasing $k_f$ for small S.
- The considered layout in Section~V-C is unclear.
}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for your note. Indeed, we have revised our approach in the presence of fading. Now, we average the $k_f$ fading realizations and give the resulting average as input to the learning machines. In particular, we have described the fading average in Section~\ref{sec:auth} as:
\begin{quote}
"\revp{avg_1}"
\end{quote}
The sentence mentioned in the revision has been replaced by the following comment on Fig. \ref{fig:kf10-5}:
\begin{quote}
    "\revp{rev2fad}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The conclusions from the numerical simulations (last paragraph before Section~VI) are very specific and contain mainly numerical evidence from the chose numerical scenarios.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We agree with you that those considerations did not add much to the already discussed numerical results. In the revised version of the manuscript, we have removed the paragraph.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
In the references: check capitalised letters in [14], [20]. Check author names in [16].}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for pointing out the mistakes. We have carefully revised the reference section. 
\vspace{5mm} %5mm vertical space


\clearpage


\section*{Reviewer 3}
\setstretch{1.0}
\begin{framed}
\noindent {\bf Rev: Positives: This paper proposes machine learning based in-region location verification scheme, which uses neural networks (NNs) or SVM to learn the channel features of the region of interest without knowing the channel parameters. Numerical results show that this scheme achieves low miss detection rate. The theoretic study of the proposed scheme is reasonable.
}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We would like to thank you for your positive comments. We have addressed all the issues, updated the manuscript, and provided here a point-to-point response to your observations. 

\setstretch{1.0}
\begin{framed}
\noindent {\bf Rev:
The references of the work can be further enhanced and the model descriptions are not always comprehensive. Please explain the numerical results for more details. For example, please add the benchmark scheme to convince readers. In addition, the presentation can be further improved and the complexity of the proposed scheme should be provided.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We would like to thank your for your useful suggestions. We have carefully revised the paper according to your indications. We have carried out an in-depth revision of the numerical result section, improved the presentation, compared our solutions with existing ones, and assessed the complexity of the proposed approach.

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Please compare the proposed scheme with other existing schemes.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Thank you for the suggestion. In the revised manuscript, we have included the description of the method presented in \cite{li2010security}, wherein first the position of the user is estimated and then compared with the area of interest. Still, the technique of \cite{li2010security} a) assumes to know the path-loss relation between attenuation and distance, which may be unrealistic, and b) is designed to confirm a specific position rather than asserting if the user is in a {\it region}. Therefore, we have extended of \cite{li2010security} to perform \ac{irlv}. The resulting method is briefly described in Section~\ref{seccomp} as follows:
\begin{quote}
"\revp{literature_1} 
	\begin{align}
 \hat{\bm x}_{\rm UD} =  \underset{\bm x}{\arg \min} \sum_{n=1}^{N_{\rm AP}} \left(L(\bm{x},\bm{x}_{\rm AP}^{(n)}) - \hat{L}(\bm{x}_{\rm UD},\bm{x}_{\rm AP}^{(n)}) \right)^2,.
\end{align}
\revp{literature_2}
\revp{literature_3}"
\end{quote}
Moreover, Fig.s  \ref{fig:kf10-5} and \ref{fig:kf10Oc} now include the comparison with the model in the literature. We have added the following comments in the figures:  
\begin{itemize}
    \item Comment to Fig. \ref{fig:kf10-5} :
    \begin{quote}
        "\revp{revLI2a}" \\ ... \\ "\revp{revLI2b}" 
    \end{quote}
    \item Comment to Fig. \ref{fig:kf10Oc}:
    \begin{quote}
        "\revp{revLI3}"
    \end{quote}
    \end{itemize}
Moreover, we added the following comment to Fig. \ref{fig:Berlinnew}:
    \begin{quote}
        "\revp{revLI}"
    \end{quote}



\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
Proof that this proposed scheme has robust against the channel fading. In other words, could you please provide some numerical results to support the robust of this scheme?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Please note that our considered channel model already included fading. Indeed, Fig.s \ref{fig:kf1}, \ref{fig:kf1_newArea}, \ref{fig:kf10-5}, \ref{fig:kf1Oc}, and \ref{fig:kf10Oc} all include fading effect. Moreover, we have also considered a refinement of our approach, explicitly targeting the adverse effect of fading, wherein the learning machines are fed with averages of attenuation vectors over multiple fading realizations. By choosing the number of averaged realizations, we can understand the relevance of averaging fading, taking into account that having multiple realizations of attenuation vectors may not always be possibile and takes additional time. In order to make this point clearer, we have added the following sentences in Section~\ref{sec:auth}:
\begin{quote}
 "\revp{avg_1}
\end{quote}
Furthermore, we have revised Section \ref{sec:los} to include uncorrelated shadowing and fading.

In section \ref{sec:singleAp}, we have added the following sentence:

\begin{quote}
    "\revp{numResSimplScen4}"
\end{quote}
% In Section \ref{sec:numRes}, we have added the following sentence:

% \begin{quote}
%     "\revp{revLI2a}"
% \end{quote}
In Section \ref{sec:numResOneClass}, we have added the following sentence:

\begin{quote}
    "\revp{fadingRes}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
What are the computation complexity of the two machine learning methods (i.e., neural networks (NNs) and SVM)?}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We have added Section~\ref{sec:comp} showing the computational complexity of the two machine learning methods. The section reads as follows:
\begin{quote}
"\revp{comp1} 

\revp{comp2}

\revp{comp3}"
\end{quote}

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
The results in terms of the miss detection rate and the false alarm rate in Fig. 3 [Fig. \ref{fig:ceVSnp} in the revised paper] are not practical. Please explain.}
\end{framed}

\setstretch{1.5}
{\bf Ans:} Based on your comments, we have revised Fig. \ref{fig:ceVSnp} and the relative theoretical part in Section~\ref{sec:los}. The new model also includes uncorrelated shadowing and fading effects. Error probabilities are now lower, while still confirming the equivalence between the \ac{np} test and \ac{ml} classifiers. Furthermore, we have improved the performance of the overall system when considering correlated shadowing for both two-classes and one-class classifiers, by adding more layers to the \ac{nn} and considering a larger number of \acp{ap}.

\vspace{5mm} %5mm vertical space

\setstretch{1.0}
\vspace{5mm} %5mm vertical space
\begin{framed}
\noindent {\bf Rev:
A couple of papers are worth citing:

(1). Physical layer authentication over MIMO fading wiretap channels, IEEE Trans. Wireless Communications, 2012.

(2). PHY-layer spoofing detection with reinforcement learning in wireless networks, IEEE Trans. Vehicular Technology,2016.
}
\end{framed}

\setstretch{1.5}
{\bf Ans:} We now reference both papers in the Introduction, within the following sentence:
\begin{quote}
    "\revp{rev3cit}"
\end{quote}
\end{comment}
\end{document}
